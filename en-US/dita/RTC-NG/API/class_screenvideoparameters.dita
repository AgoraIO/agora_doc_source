<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="class_screenvideoparameters">
    <title><ph keyref="ScreenVideoParameters"/></title>
    <shortdesc id="short"><ph id="shortdesc">The video configuration for the shared screen stream.</ph></shortdesc>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">  public static class VideoCaptureParameters {
        public int bitrate = 0;
        public int framerate = 15;
        public int width = 1280;
        public int height = 720;
        public int contentHint = Constants.SCREEN_CAPTURE_CONTENT_HINT_MOTION;

    @CalledByNative("VideoCaptureParameters")
    public int getBitrate() {
      return bitrate;
    }

    @CalledByNative("VideoCaptureParameters")
    public int getFramerate() {
      return framerate;
    }

    @CalledByNative("VideoCaptureParameters")
    public int getWidth() {
      return width;
    }

    @CalledByNative("VideoCaptureParameters")
    public int getHeight() {
      return height;
    }

    @CalledByNative("VideoCaptureParameters")
    public int getContentHint() {
      return contentHint;
    }

    @Override
    public String toString() {
      return "VideoCaptureParameters{"
          + "bitrate=" + bitrate + ", framerate=" + framerate + ", width=" + width
          + ", height=" + height + ", contentHint=" + contentHint + '}';
    }
  }
</codeblock>
            <codeblock props="ios" outputclass="language-objectivec">__attribute__((visibility("default"))) @interface AgoraScreenVideoParameters : NSObject

@property(assign, nonatomic) CGSize dimensions;
@property(assign, nonatomic) AgoraVideoFrameRate frameRate;
@property(assign, nonatomic) NSInteger bitrate;
@property(assign, nonatomic) AgoraVideoContentHint contentHint;

@end
</codeblock>
            <codeblock props="cpp unreal" outputclass="language-cpp">struct ScreenVideoParameters {
    VideoDimensions dimensions;
    int frameRate = 15;
     int bitrate;
    VIDEO_CONTENT_HINT contentHint = VIDEO_CONTENT_HINT::CONTENT_HINT_MOTION;

  ScreenVideoParameters() : dimensions(1280, 720) {}
};
</codeblock>
         <codeblock props="bp" outputclass="language-cpp">USTRUCT(BlueprintType)
struct FScreenVideoParameters {

	GENERATED_BODY()

	FVideoDimensions dimensions;

	int frameRate = 15;

	int bitrate;

	EVIDEO_CONTENT_HINT contentHint = EVIDEO_CONTENT_HINT::CONTENT_HINT_MOTION;

};</codeblock>
            <codeblock props="electron" outputclass="language-typescript">export class ScreenVideoParameters {
  
  dimensions?: VideoDimensions;
  
  frameRate?: number;
  
  bitrate?: number;
  
  contentHint?: VideoContentHint;
}</codeblock>
            <codeblock props="unity cs" outputclass="language-csharp">public class ScreenVideoParameters
    {
        public VideoDimensions dimensions { set; get; }

        public int frameRate { set; get; }

        public int bitrate { set; get; }

        public VIDEO_CONTENT_HINT contentHint = VIDEO_CONTENT_HINT.CONTENT_HINT_MOTION;

        public ScreenVideoParameters()
        {
            dimensions = new VideoDimensions(1280, 720);
            frameRate = 15;
        }
    };</codeblock>
            <codeblock props="rn" outputclass="language-typescript">export class ScreenVideoParameters {
  
  dimensions?: VideoDimensions;
  
  frameRate?: number;
  
  bitrate?: number;
  
  contentHint?: VideoContentHint;
}</codeblock>
            <codeblock props="flutter" outputclass="language-dart">class ScreenVideoParameters {
  const ScreenVideoParameters(
      {this.dimensions, this.frameRate, this.bitrate, this.contentHint});
 
  @JsonKey(name: 'dimensions')
  final VideoDimensions? dimensions;
  @JsonKey(name: 'frameRate')
  final int? frameRate;
  @JsonKey(name: 'bitrate')
  final int? bitrate;
  @JsonKey(name: 'contentHint')
  final VideoContentHint? contentHint;
  factory ScreenVideoParameters.fromJson(Map&lt;String, dynamic> json) =>
      _$ScreenVideoParametersFromJson(json);
  Map&lt;String, dynamic> toJson() => _$ScreenVideoParametersToJson(this);
}</codeblock>            
            <codeblock props="reserve" outputclass="language-cpp"></codeblock></p>
        </section>
        <section id="detailed_desc">
            <p props="android hmos">Only available for scenarios where <parmname>captureVideo</parmname> is <codeph><ph keyref="true"/></codeph>.</p>
        </section>
        <section id="parameters">
            <title><text conref="../conref/conref_api_metadata.dita#conref_api_metadata/property"/></title>
            <parml>
            <plentry props="ios cpp unreal bp electron unity rn flutter cs">
                <pt>dimensions</pt>
                <pd>The video encoding dimension. The default value is 1280 × 720.</pd>
                <pd>If the aspect ratio of <parmname>dimensions</parmname> is different from that of the screen, the SDK adjusts the video encoding resolution according to the following rules (take the<parmname> dimensions</parmname> of 1280 × 720 as an example):<ul>
                    <li>When the width and height of the screen are both lower than those of <parmname>dimensions</parmname>, the SDK uses the resolution of the screen for video encoding. For example, if the screen is 640 × 360, the SDK uses 640 × 360 for video encoding.</li>
                    <li>When either the width or height of the screen is higher than that of <parmname>dimensions</parmname>, the SDK uses the maximum values that do not exceed those of <parmname>dimensions</parmname> while maintaining the aspect ratio of the screen for video encoding. For example, if the screen is 2000 × 1500, the SDK uses 960 × 720 for video encoding.</li>
                    </ul>
                    <note>
                    <ul>
                    <li>The billing for the screen sharing stream is based on the value of <parmname>dimensions</parmname>. When you do not pass in a value, Agora bills you at 1280 × 720; when you pass in a value, Agora bills you at that value.</li>
                    <li>The value of this parameter does not indicate the orientation mode of the output video. For how to set the video orientation, see <xref keyref="ORIENTATION_MODE"/>.</li>
                    <li>Whether the 720p resolution or above can be supported depends on the device. If the device cannot support 720p, the frame rate will be lower than the set value.</li>
                    </ul> </note>
                    <note>When setting the encoding resolution in the scenario of sharing documents (<ph keyref="SCREEN_SCENARIO_DOCUMENT"/>), choose one of the following two methods:<ul>
                      <li>If you require the best image quality, it is recommended to set the encoding resolution to be the same as the capture resolution.</li>
                      <li>If you wish to achieve a relative balance between image quality, bandwidth, and system performance, then:<ul>
                          <li>When the capture resolution is greater than 1920 × 1080, it is recommended that the encoding resolution is not less than 1920 × 1080.</li>
                          <li>When the capture resolution is less than 1920 × 1080, it is recommended that the encoding resolution is not less than 1280 × 720.</li>
                          </ul></li>
                      </ul></note>
                    </pd>
            </plentry>
            <plentry props="android hmos">
                <pt>width</pt>
                <pd>The width (px) of the video encoding resolution. The default value is 1280. If the aspect ratio of width to height is different from that of the screen, the SDK adjusts the video encoding resolution according to the following rules (take width × height of 1280 × 720 as an example):<ul>
                    <li>When the width and height of the screen are both lower than those of dimensions, the SDK uses the resolution of the screen for video encoding. For example, if the screen is 640 × 360, the SDK uses 640 × 360 for video encoding.</li>
                    <li>When either the width or height of the screen is higher than that of dimensions, the SDK uses the maximum values that do not exceed those of dimensions while maintaining the aspect ratio of the screen for video encoding. For example, if the screen is 2000 × 1500, the SDK uses 960 × 720 for video encoding.</li>
                    </ul>
                    <note>
                    <ul>
                    <li>The billing for the screen sharing stream is based on the value of dimensions. When you do not pass in a value, Agora bills you at 1280 × 720; when you pass in a value, Agora bills you at that value.</li>
                    <li>The value of this parameter does not indicate the orientation mode of the output video. For how to set the video orientation, see <xref keyref="ORIENTATION_MODE"/>.</li>
                    <li>Whether the 720p resolution or above can be supported depends on the device. If the device cannot support 720p, the frame rate will be lower than the set value.</li>
                    </ul> </note>
                    <note>When setting the encoding resolution in the scenario of sharing documents (<ph keyref="SCREEN_SCENARIO_DOCUMENT"/>), choose one of the following two methods:<ul>
                      <li>If you require the best image quality, it is recommended to set the encoding resolution to be the same as the capture resolution.</li>
                      <li>If you wish to achieve a relative balance between image quality, bandwidth, and system performance, then:<ul>
                          <li>When the capture resolution is greater than 1920 × 1080, it is recommended that the encoding resolution is not less than 1920 × 1080.</li>
                          <li>When the capture resolution is less than 1920 × 1080, it is recommended that the encoding resolution is not less than 1280 × 720.</li>
                          </ul></li>
                      </ul></note>
                    </pd>
            </plentry>
            <plentry props="android hmos">
                <pt>height</pt>
                <pd>The height (px) of the video encoding resolution. The default value is 720. If the aspect ratio of width to height is different from that of the screen, the SDK adjusts the video encoding resolution according to the following rules (take width × height of 1280 × 720 as an example):<ul>
                    <li>When the width and height of the screen are both lower than those of dimensions, the SDK uses the resolution of the screen for video encoding. For example, if the screen is 640 × 360, the SDK uses 640 × 360 for video encoding.</li>
                    <li>When either the width or height of the screen is higher than that of dimensions, the SDK uses the maximum values that do not exceed those of dimensions while maintaining the aspect ratio of the screen for video encoding. For example, if the screen is 2000 × 1500, the SDK uses 960 × 720 for video encoding.</li>
                    </ul>
                    <note>
                    <ul>
                    <li>The billing for the screen sharing stream is based on the value of dimensions. When you do not pass in a value, Agora bills you at 1280 × 720; when you pass in a value, Agora bills you at that value.</li>
                    <li>The value of this parameter does not indicate the orientation mode of the output video. For how to set the video orientation, see <xref keyref="ORIENTATION_MODE"/>.</li>
                    <li>Whether the 720p resolution or above can be supported depends on the device. If the device cannot support 720p, the frame rate will be lower than the set value.</li>
                    </ul> </note> 
                    <note>When setting the encoding resolution in the scenario of sharing documents (<ph keyref="SCREEN_SCENARIO_DOCUMENT"/>), choose one of the following two methods:<ul>
                      <li>If you require the best image quality, it is recommended to set the encoding resolution to be the same as the capture resolution.</li>
                      <li>If you wish to achieve a relative balance between image quality, bandwidth, and system performance, then:<ul>
                          <li>When the capture resolution is greater than 1920 × 1080, it is recommended that the encoding resolution is not less than 1920 × 1080.</li>
                          <li>When the capture resolution is less than 1920 × 1080, it is recommended that the encoding resolution is not less than 1280 × 720.</li>
                          </ul></li>
                      </ul></note>
                    </pd>
            </plentry>
            <plentry>
                <pt props="android hmos">frameRate</pt>
                <pt props="ios cpp unreal bp electron unity rn flutter cs">frameRate</pt>
                <pd>The video encoding frame rate (fps). The default value is 15.</pd>
            </plentry>
            <plentry>
                <pt>bitrate</pt>
                <pd>The video encoding bitrate (Kbps).</pd>
            </plentry>
            <plentry>
                <pt>contentHint</pt>
                <pd><ph>The content hint for screen sharing. </ph><ph props="cpp unreal bp ios">See <xref keyref="VIDEO_CONTENT_HINT"/>.</ph><ul props="android hmos">
                    <li><ph keyref="CONTENT_HINT_NONE"/>(0): (Default) No content hint.</li>
                    <li><ph keyref="CONTENT_HINT_MOTION"/>(1): Motion-intensive content. Choose this option if you prefer smoothness or when you are sharing a video clip, movie, or video game.</li>
                    <li><ph keyref="CONTENT_HINT_DETAILS"/>(2): Motionless content. Choose this option if you prefer sharpness or when you are sharing a picture, PowerPoint slides, or texts.</li>
                    </ul></pd>
            </plentry>
            </parml> </section>
    </refbody>
</reference>
