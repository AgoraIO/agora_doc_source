<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="class_remotevideostats">
    <title><ph keyref="RemoteVideoStats" /></title>
    <shortdesc id="short"><ph id="shortdesc">Statistics of the remote video stream.</ph></shortdesc>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">public static class RemoteVideoStats {
    public int uid;
    public int delay;
    public int width;
    public int height;
    public int receivedBitrate;
    public int decoderOutputFrameRate;
    public int rendererOutputFrameRate;
    public int frameLossRate;
    public int packetLossRate;
    public int rxStreamType;
    public int totalFrozenTime;
    public int frozenRate;
    public int avSyncTimeMs;
    public long totalActiveTime;
    public long publishDuration;
    public int superResolutionType;
  }</codeblock>
            <codeblock props="ios mac" outputclass="language-objectivec">__attribute__((visibility("default"))) @interface AgoraRtcRemoteVideoStats : NSObject
@property(assign, nonatomic) NSUInteger uid;
@property(assign, nonatomic) NSUInteger delay __deprecated;
@property(assign, nonatomic) NSUInteger width;
@property(assign, nonatomic) NSUInteger height;
@property(assign, nonatomic) NSUInteger receivedBitrate;
@property(assign, nonatomic) NSUInteger receivedFrameRate;
@property(assign, nonatomic) AgoraVideoStreamType rxStreamType;
@property(assign, nonatomic) NSInteger decoderOutputFrameRate;
@property(assign, nonatomic) NSInteger rendererOutputFrameRate;
@property(assign, nonatomic) NSInteger frameLossRate;
@property(assign, nonatomic) NSInteger packetLossRate;
@property(assign, nonatomic) NSInteger totalFrozenTime;
@property(assign, nonatomic) NSInteger frozenRate;
@property(assign, nonatomic) NSUInteger totalActiveTime;
@property(assign, nonatomic) NSInteger publishDuration;
@property(assign, nonatomic) NSInteger avSyncTimeMs;
@property(assign, nonatomic) NSInteger superResolutionType;
@end</codeblock>
            <codeblock props="cpp" outputclass="language-cpp">struct RemoteVideoStats {
  uid_t uid;
  int delay;
  int width;
  int height;
  int receivedBitrate;
  int decoderOutputFrameRate;
  int rendererOutputFrameRate;
  int frameLossRate;
  int packetLossRate;
  VIDEO_STREAM_TYPE rxStreamType;
  int totalFrozenTime;
  int frozenRate;
  int avSyncTimeMs;
  int totalActiveTime;
  int publishDuration;
  int superResolutionType;
};</codeblock>
            <codeblock props="electron" outputclass="language-typescript">export class RemoteVideoStats {

  uid?: number;

  delay?: number;

  width?: number;

  height?: number;

  receivedBitrate?: number;

  decoderOutputFrameRate?: number;

  rendererOutputFrameRate?: number;

  frameLossRate?: number;

  packetLossRate?: number;

  rxStreamType?: VideoStreamType;

  totalFrozenTime?: number;

  frozenRate?: number;

  avSyncTimeMs?: number;

  totalActiveTime?: number;

  publishDuration?: number;

  superResolutionType?: number;
}</codeblock>
            <codeblock props="unity" outputclass="language-csharp">public class RemoteVideoStats
    {
        public uint uid { set; get; }
        public int delay { set; get; }
        public int width { set; get; }
        public int height { set; get; }
        public int receivedBitrate { set; get; }
        public int decoderOutputFrameRate { set; get; }
        public int rendererOutputFrameRate { set; get; }
        public int frameLossRate { set; get; }
        public int packetLossRate { set; get; }
        public VIDEO_STREAM_TYPE rxStreamType { set; get; }
        public int totalFrozenTime { set; get; }
        public int frozenRate { set; get; }
        public int avSyncTimeMs { set; get; }
        public int totalActiveTime { set; get; }
        public int publishDuration { set; get; }
        public int superResolutionType { set; get; }
    }</codeblock>
            <codeblock props="rn" outputclass="language-typescript">export class RemoteVideoStats {

  uid?: number;

  delay?: number;

  width?: number;

  height?: number;

  receivedBitrate?: number;

  decoderOutputFrameRate?: number;

  rendererOutputFrameRate?: number;

  frameLossRate?: number;

  packetLossRate?: number;

  rxStreamType?: VideoStreamType;

  totalFrozenTime?: number;

  frozenRate?: number;

  avSyncTimeMs?: number;

  totalActiveTime?: number;

  publishDuration?: number;

  superResolutionType?: number;
}</codeblock>
            <codeblock props="flutter" outputclass="language-dart">class RemoteVideoStats {
  const RemoteVideoStats(
      {this.uid,
      this.delay,
      this.width,
      this.height,
      this.receivedBitrate,
      this.decoderOutputFrameRate,
      this.rendererOutputFrameRate,
      this.frameLossRate,
      this.packetLossRate,
      this.rxStreamType,
      this.totalFrozenTime,
      this.frozenRate,
      this.avSyncTimeMs,
      this.totalActiveTime,
      this.publishDuration,
      this.superResolutionType});

  @JsonKey(name: 'uid')
  final int? uid;
  @JsonKey(name: 'delay')
  final int? delay;
  @JsonKey(name: 'width')
  final int? width;
  @JsonKey(name: 'height')
  final int? height;
  @JsonKey(name: 'receivedBitrate')
  final int? receivedBitrate;
  @JsonKey(name: 'decoderOutputFrameRate')
  final int? decoderOutputFrameRate;
  @JsonKey(name: 'rendererOutputFrameRate')
  final int? rendererOutputFrameRate;
  @JsonKey(name: 'frameLossRate')
  final int? frameLossRate;
  @JsonKey(name: 'packetLossRate')
  final int? packetLossRate;
  @JsonKey(name: 'rxStreamType')
  final VideoStreamType? rxStreamType;
  @JsonKey(name: 'totalFrozenTime')
  final int? totalFrozenTime;
  @JsonKey(name: 'frozenRate')
  final int? frozenRate;
  @JsonKey(name: 'avSyncTimeMs')
  final int? avSyncTimeMs;
  @JsonKey(name: 'totalActiveTime')
  final int? totalActiveTime;
  @JsonKey(name: 'publishDuration')
  final int? publishDuration;
  @JsonKey(name: 'superResolutionType')
  final int? superResolutionType;
  factory RemoteVideoStats.fromJson(Map&lt;String, dynamic&gt; json) =&gt;
      _$RemoteVideoStatsFromJson(json);
  Map&lt;String, dynamic&gt; toJson() =&gt; _$RemoteVideoStatsToJson(this);
}</codeblock>            
            <codeblock props="reserve" outputclass="language-cpp" /></p>
        </section>
        <section id="parameters">
            <title><text conref="../conref/conref_api_metadata.dita#conref_api_metadata/property" /></title>
            <parml>
            <plentry>
                <pt>uid</pt>
                <pd>The user ID of the remote user sending the video stream.</pd>
            </plentry>
            <plentry>
                <pt>delay</pt>
                <pd>
                    <dl outputclass="deprecated">
                    <dlentry>
                        <dt>Deprecated:</dt>
                        <dd>In scenarios where audio and video are synchronized, you can get the video delay data from <parmname>networkTransportDelay</parmname> and <parmname>jitterBufferDelay</parmname> in <xref keyref="RemoteAudioStats" />.</dd>
                    </dlentry>
                    </dl>
                    <p>The video delay (ms).</p>
                </pd>
            </plentry>
            <plentry>
                <pt>width</pt>
                <pd>The width (pixels) of the video.</pd>
            </plentry>
            <plentry>
                <pt>height</pt>
                <pd>The height (pixels) of the video.</pd>
            </plentry>
            <plentry>
                <pt>receivedBitrate</pt>
                <pd>The bitrate (Kbps) of the remote video received since the last count.</pd>
            </plentry>
            <plentry props="ios mac">
                <pt>receivedFramerate</pt>
                <pd>The frame rate (Kbps) received since the last count.</pd>
            </plentry>
            <plentry>
                <pt>decoderOutputFrameRate</pt>
                <pd>The frame rate (fps) of decoding the remote video.</pd>
            </plentry>
            <plentry>
                <pt>rendererOutputFrameRate</pt>
                <pd>The frame rate (fps) of rendering the remote video.</pd>
            </plentry>
            <plentry>
                <pt>frameLossRate</pt>
                <pd>The packet loss rate (%) of the remote video.</pd>
            </plentry>
            <plentry>
                <pt>packetLossRate</pt>
                <pd>The packet loss rate (%) of the remote video after using the anti-packet-loss technology.</pd>
            </plentry>
            <plentry>
                <pt>rxStreamType</pt>
                <pd><ph>The type of the video stream. </ph><ph props="ios mac cpp unity rn electron flutter">See <xref keyref="VIDEO_STREAM_TYPE" />.</ph><p props="android">
                    <ul>
                    <li><ph keyref="VIDEO_STREAM_HIGH" />(0): High-quality stream, that is, a high-resolution and high-bitrate video stream.</li>
                    <li><ph keyref="VIDEO_STREAM_LOW" />(1): Low-quality stream, that is, a low-resolution and low-bitrate video stream.</li>
                    </ul> </p>
                </pd>
            </plentry>
            <plentry>
                <pt>totalFrozenTime</pt>
                <pd>The total freeze time (ms) of the remote video stream after the remote user joins the channel. In a video session where the frame rate is set to no less than 5 fps, video freeze occurs when the time interval between two adjacent renderable video frames is more than 500 ms.</pd>
            </plentry>
            <plentry>
                <pt>frozenRate</pt>
                <pd>The total video freeze time as a percentage (%) of the total time the video is available. The video is considered available as long as that the remote user neither stops sending the video stream nor disables the video module after joining the channel.</pd>
            </plentry>
            <plentry>
                <pt>totalActiveTime</pt>
                <pd>
                    <p>The total active time (ms) of the video.</p>
                    <p>As long as the remote user or host neither stops sending the video stream nor disables the video module after joining the channel, the video is available.</p>
                </pd>
            </plentry>
            <plentry>
                <pt>publishDuration</pt>
                <pd>
                    <p>The total duration (ms) of the remote video stream.</p>
                </pd>
            </plentry>
            <plentry>
                <pt>superResolutionType</pt>
                <pd>The state of super resolution:<ul>
                    <li>&gt;0: Super resolution is enabled.</li>
                    <li>=0: Super resolution is not enabled.</li>
                    </ul> </pd>
            </plentry>
            <plentry>
                <pt>avSyncTimeMs</pt>
                <pd>The amount of time (ms) that the audio is ahead of the video.<note type="attention">If this value is negative, the audio is lagging behind the video.</note></pd>
            </plentry>
            </parml> </section>
    </refbody>
</reference>