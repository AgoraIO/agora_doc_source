<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="api_irtcengine_setvideoscenario">
    <title><ph keyref="setVideoScenario"/></title>
    <shortdesc id="short"><ph id="shortdesc">Sets video application scenarios.</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="setVideoScenario"/>
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">public abstract int setVideoScenario(Constants.VideoScenario scenarioType);</codeblock>
            <codeblock props="hmos" outputclass="language-arkts"></codeblock>
            <codeblock props="ios mac" outputclass="language-objectivec">- (int)setVideoScenario:(AgoraApplicationScenarioType)scenarioType NS_SWIFT_NAME(setVideoScenario(_:));</codeblock>
            <codeblock props="cpp unreal" outputclass="language-cpp">virtual int setVideoScenario(VIDEO_APPLICATION_SCENARIO_TYPE scenarioType) = 0;</codeblock>
         <codeblock props="bp" outputclass="language-cpp">UFUNCTION(BlueprintCallable, Category = &quot;Agora|RtcEngineProxy&quot;)
	int SetVideoScenario(EVIDEO_APPLICATION_SCENARIO_TYPE scenarioType);</codeblock>
            <codeblock props="electron" outputclass="language-typescript">abstract setVideoScenario(scenarioType: VideoApplicationScenarioType): number;</codeblock>
            <codeblock props="unity cs" outputclass="language-csharp">public abstract int SetVideoScenario(VIDEO_APPLICATION_SCENARIO_TYPE scenarioType);</codeblock>
            <codeblock props="rn" outputclass="language-typescript">abstract setVideoScenario(scenarioType: VideoApplicationScenarioType): number;</codeblock>
            <codeblock props="flutter" outputclass="language-dart">Future&lt;void> setVideoScenario(VideoApplicationScenarioType scenarioType);</codeblock> </p>
        </section>
        <section id="detailed_desc">
            <title>Details</title>
            <dl outputclass="since">
            <dlentry props="native">
                <dt>Since</dt>
                <dd>v4.2.0</dd>
            </dlentry>
            </dl>
            <p>After successfully calling this method, the SDK will automatically enable the best practice strategies and adjust key performance metrics based on the specified scenario, to optimize the video experience.</p>
            <note type="attention">Call this method before joining a channel.</note>
        </section>
        <section id="parameters">
            <title>Parameters</title>
            <parml>
            <plentry>
                <pt>scenarioType</pt>
                <pd>The type of video application scenario. See <xref keyref="VIDEO_APPLICATION_SCENARIO_TYPE"/>.<p id="meeting"><apiname keyref="APPLICATION_SCENARIO_MEETING"/> (1) is suitable for meeting scenarios. The SDK automatically enables the following strategies:<ul>
                        <li>In meeting scenarios where low-quality video streams are required to have a high bitrate, the SDK automatically enables multiple technologies used to deal with network congestions, to enhance the performance of the low-quality streams and to ensure the smooth reception by subscribers.</li>
                        <li>The SDK monitors the number of subscribers to the high-quality video stream in real time and dynamically adjusts its configuration based on the number of subscribers.<ul>
                            <li>If nobody subscribers to the high-quality stream, the SDK automatically reduces its bitrate and frame rate to save upstream bandwidth.</li>
                            <li>If someone subscribes to the high-quality stream, the SDK resets the high-quality stream to the <xref keyref="VideoEncoderConfiguration"/> configuration used in the most recent calling of <xref keyref="setVideoEncoderConfiguration"/>. If no configuration has been set by the user previously, the following values are used:<ul props="cpp unreal bp flutter unity">
                                <li>Resolution: (Windows and macOS) 1280 × 720; (Android and iOS) 960 × 540</li>
                                <li>Frame rate: 15 fps</li>
                                <li>Bitrate: (Windows and macOS) 1600 Kbps; (Android and iOS) 1000 Kbps</li>
                                </ul>
                                <ul props="android ios rn">
                                <li>Resolution: 960 × 540</li>
                                <li>Frame rate: 15 fps</li>
                                <li>Bitrate: 1000 Kbps</li>
                                </ul>
                                <ul props="mac electron cs">
                                <li>Resolution: 1280 × 720</li>
                                <li>Frame rate: 15 fps</li>
                                <li>Bitrate: 1600 Kbps</li>
                                </ul>
                            </li></ul>
                        </li>
                        <li>The SDK monitors the number of subscribers to the low-quality video stream in real time and dynamically enables or disables it based on the number of subscribers.<note>If the user has called <xref keyref="setDualStreamMode2"/> to set that never send low-quality video stream (<apiname keyref="DISABLE_SIMULCAST_STREAM"/>), the dynamic adjustment of the low-quality stream in meeting scenarios will not take effect.</note><ul>
                            <li>If nobody subscribes to the low-quality stream, the SDK automatically disables it to save upstream bandwidth.</li>
                            <li>If someone subscribes to the low-quality stream, the SDK enables the low-quality stream and resets it to the <xref keyref="SimulcastStreamConfig"/> configuration used in the most recent calling of <apiname keyref="setDualStreamMode2"/>. If no configuration has been set by the user previously, the following values are used:<ul>
                                <li>Resolution: 480 × 272</li>
                                <li>Frame rate: 15 fps</li>
                                <li>Bitrate: 500 Kbps</li>
                                </ul>
                            </li></ul>
                        </li>
                    </ul>
                </p>
                <p id="1v1"><apiname keyref="APPLICATION_SCENARIO_1V1"/> (2) is suitable for 1v1 video call scenarios. To meet the requirements for low latency and high-quality video in this scenario, the SDK optimizes its strategies, improving performance in terms of video quality, first frame rendering, latency on mid-to-low-end devices, and smoothness under weak network conditions.</p>
                </pd>
            </plentry>
            </parml>
        </section>
        <section id="return_values">
            <title><ph keyref="return-section-title"/></title>
            <p props="flutter">When the method call succeeds, there is no return value; when fails, the <xref keyref="AgoraRtcException"/> exception is thrown. You need to catch the exception and handle it accordingly. <ph props="cn">See <xref keyref="error-code-link"/> for details and resolution suggestions.</ph></p>
            <ul props="native unreal bp electron unity cs rn">
            <li>0: Success.</li>
            <li>&lt; 0: Failure. <ph props="cn">See <xref keyref="error-code-link"/> for details and resolution suggestions.</ph><ul>
            <li>-1: A general error occurs (no specified reason).</li>
            <li>-4: Video application scenarios are not supported. Possible reasons include that you use the Voice SDK instead of the Video SDK.</li>
            <li>-7: The <apiname keyref="IRtcEngine" /> object has not been initialized. You need to initialize the <apiname keyref="IRtcEngine" /> object before calling this method.</li>
            </ul>
            </li>
            </ul>
        </section>
    </refbody>
</reference>
