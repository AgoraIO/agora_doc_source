<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="api_irtcengine_startrhythmplayer">
    <title><ph keyref="startRhythmPlayer" /></title>
    <shortdesc id="short"><ph id="shortdesc">Enables the virtual metronome.</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="startRhythmPlayer" />
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">public abstract int startRhythmPlayer(
    String sound1, String sound2, AgoraRhythmPlayerConfig config);</codeblock>
            <codeblock props="ios" outputclass="language-objectivec">- (int)startRhythmPlayer:(NSString * _Nonnull)sound1 sound2:(NSString * _Nonnull)sound2 config:(AgoraRhythmPlayerConfig *  _Nullable)config;</codeblock>
            <codeblock props="cpp" outputclass="language-cpp">virtual int startRhythmPlayer(const char* sound1, const char* sound2, const AgoraRhythmPlayerConfig&amp; config) = 0;</codeblock>
            <codeblock props="electron" outputclass="language-typescript">abstract startRhythmPlayer(
    sound1: string,
    sound2: string,
    config: AgoraRhythmPlayerConfig
  ): number;</codeblock>
            <codeblock props="unity cs" outputclass="language-csharp">public abstract int StartRhythmPlayer(string sound1, string sound2, AgoraRhythmPlayerConfig config);</codeblock>
            <codeblock props="rn" outputclass="language-typescript">abstract startRhythmPlayer(
  sound1: string,
  sound2: string,
  config: AgoraRhythmPlayerConfig
): number;</codeblock>
            <codeblock props="flutter" outputclass="language-dart">Future&lt;void&gt; startRhythmPlayer(
      {required String sound1,
      required String sound2,
      required AgoraRhythmPlayerConfig config});</codeblock>
            <codeblock props="reserve" outputclass="language-cpp" /></p>
        </section>
        <section id="detailed_desc">
            <title>Details</title>
            <p>In music education, physical education and other scenarios, teachers usually need to use a metronome so that students can practice with the correct beat. The meter is composed of a downbeat and upbeats. The first beat of each measure is called a downbeat, and the rest are called upbeats.</p>
            <p>In this method, you need to set the file path of the upbeat and downbeat, the number of beats per measure, the beat speed, and whether to send the sound of the metronome to remote users.</p>
            <p>After successfully calling this method, the SDK triggers the <xref keyref="onRhythmPlayerStateChanged" /> callback locally to report the status of the virtual metronome.</p>
            <note type="attention" id="rhythm_play">
            <ul>
            <li props="cpp unity flutter cs">This method is for Android and iOS only.</li>
            <li>After enabling the virtual metronome, the SDK plays the specified audio effect file from the beginning, and controls the playback duration of each file according to <parmname>beatsPerMinute </parmname> you set in <xref keyref="AgoraRhythmPlayerConfig" />. For example, if you set <parmname>beatsPerMinute</parmname> as <codeph>60</codeph>, the SDK plays one beat every second. If the file duration exceeds the beat duration, the SDK only plays the audio within the beat duration.</li>
            <li>By default, the sound of the virtual metronome is published in the channel. If you do not want the sound to be heard by the remote users, you can set <parmname>publishRhythmPlayerTrack</parmname> in <xref keyref="ChannelMediaOptions" /> as <codeph><ph keyref="false" /></codeph>.</li>
            </ul></note> </section>
        <section id="parameters">
            <title>Parameters</title>
            <parml>
            <plentry>
                <pt>sound1</pt>
                <pd>The absolute path or URL address (including the filename extensions) of the file for the downbeat. For example, <codeph><ph keyref="filePath-example" /></codeph>. For the audio file formats supported by this method, see <xref keyref="audio-format">What formats of audio files does the Agora RTC SDK support</xref>.</pd>
            </plentry>
            <plentry>
                <pt>sound2</pt>
                <pd>The absolute path or URL address (including the filename extensions) of the file for the upbeats. For example, <codeph><ph keyref="filePath-example" /></codeph>. For the audio file formats supported by this method, see <xref keyref="audio-format">What formats of audio files does the Agora RTC SDK support</xref>.</pd>
            </plentry>
            <plentry>
                <pt>config</pt>
                <pd>The metronome configuration. See <xref keyref="AgoraRhythmPlayerConfig" />.</pd>
            </plentry>
            </parml> </section>
        <section id="return_values">
            <title><ph keyref="return-section-title" /></title>
            <p props="flutter">When the method call succeeds, there is no return value; when fails, the <xref keyref="AgoraRtcException" /> exception is thrown; and you need to catch the exception and handle it accordingly.</p>
            <ul>
            <li props="native rn unity cs">0: Success.</li>
            <li>&lt; 0: Failure.<ul>
                <li>-22: Cannot find audio effect files. Please set the correct paths for <parmname>sound1</parmname> and <parmname>sound2</parmname>.</li>
                </ul></li>
            </ul> </section>
    </refbody>
</reference>