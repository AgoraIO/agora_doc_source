<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="class_channelmediaoptions">
    <title> <ph keyref="ChannelMediaOptions" /> </title>
    <shortdesc id="short"><ph id="shortdesc">The channel media options.</ph></shortdesc>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">public class ChannelMediaOptions {
  public Boolean publishCameraTrack;
  public Boolean publishScreenCaptureVideo;
  public Boolean publishScreenCaptureAudio;
  public Boolean publishCustomAudioTrack;
  public Boolean publishDirectCustomAudioTrack;
  public Boolean publishCustomVideoTrack;
  public Boolean publishEncodedVideoTrack;
  public Boolean publishMediaPlayerAudioTrack;
  public Boolean publishMediaPlayerVideoTrack;
  public Boolean publishRhythmPlayerTrack;
  public Integer publishMediaPlayerId;
  public Boolean publishMicrophoneTrack;
  public Boolean autoSubscribeAudio;
  public Boolean autoSubscribeVideo;
  public Boolean enableAudioRecordingOrPlayout;
  public Integer clientRoleType;
  public Integer audienceLatencyLevel;
  public Integer defaultVideoStreamType;
  public Integer channelProfile;
  public Integer audioDelayMs;
  public Integer mediaPlayerAudioDelayMs;
  public String token;
  public Boolean enableBuiltInMediaEncryption;
  public Integer publishCustomAudioSourceId;
  public Integer customVideoTrackId;
  public Boolean isAudioFilterable;
  public Boolean isInteractiveAudience;</codeblock>
            <codeblock props="ios mac" outputclass="language-objectivec">__attribute__((visibility("default"))) @interface AgoraRtcChannelMediaOptions : NSObject
@property(assign, nonatomic) BOOL publishCameraTrack;
@property(assign, nonatomic) BOOL publishSecondaryCameraTrack;
@property(assign, nonatomic) BOOL publishMicrophoneTrack;
#if TARGET_OS_IPHONE
@property(assign, nonatomic) BOOL publishScreenCaptureVideo;
@property(assign, nonatomic) BOOL publishScreenCaptureAudio;
#elif TARGET_OS_MAC
@property(assign, nonatomic) BOOL publishScreenTrack;
@property(assign, nonatomic) BOOL publishSecondaryScreenTrack;
#endif
@property(assign, nonatomic) BOOL publishCustomAudioTrack;
@property(assign, nonatomic) NSInteger publishCustomAudioSourceId;
@property(assign, nonatomic) BOOL publishCustomAudioTrackEnableAec;
@property(assign, nonatomic) BOOL  publishDirectCustomAudioTrack;

@property(assign, nonatomic) BOOL publishCustomVideoTrack;
@property(assign, nonatomic) BOOL publishEncodedVideoTrack;
@property(assign, nonatomic) BOOL publishMediaPlayerAudioTrack;
@property(assign, nonatomic) BOOL publishMediaPlayerVideoTrack;
@property(assign, nonatomic) BOOL publishTrancodedVideoTrack;
@property(assign, nonatomic) BOOL autoSubscribeAudio;
@property(assign, nonatomic) BOOL autoSubscribeVideo;
@property(assign, nonatomic) BOOL enableAudioRecordingOrPlayout;
@property(assign, nonatomic) NSInteger publishMediaPlayerId;
@property(assign, nonatomic) AgoraClientRole clientRoleType;
@property(assign, nonatomic) AgoraAudienceLatencyLevelType audienceLatencyLevel;
@property(assign, nonatomic) AgoraVideoStreamType defaultVideoStreamType;
@property(assign, nonatomic) AgoraChannelProfile channelProfile;
@property(assign, nonatomic) NSInteger mediaPlayerAudioDelayMs;
@property(copy, nonatomic) NSString * _Nullable token;
@property(assign, nonatomic) BOOL enableBuiltInMediaEncryption;

@property(assign, nonatomic) BOOL publishRhythmPlayerTrack;
@property(assign, nonatomic) BOOL isInteractiveAudience;

@property(assign, nonatomic) NSInteger customVideoTrackId;

@property(assign, nonatomic) BOOL isAudioFilterable;

@end</codeblock>
            <codeblock props="cpp" outputclass="language-cpp">struct ChannelMediaOptions {
  Optional&lt;bool&gt; publishCameraTrack;
  Optional&lt;bool&gt; publishSecondaryCameraTrack;
  Optional&lt;bool&gt; publishMicrophoneTrack;

  #if defined(__ANDROID__) || (defined(TARGET_OS_IPHONE) &amp;&amp; TARGET_OS_IPHONE)
  Optional&lt;bool&gt; publishScreenCaptureVideo;
  Optional&lt;bool&gt; publishScreenCaptureAudio;
  #else
  Optional&lt;bool&gt; publishScreenTrack;
  Optional&lt;bool&gt; publishSecondaryScreenTrack;
  #endif

  Optional&lt;bool&gt; publishCustomAudioTrack;
  Optional&lt;int&gt; publishCustomAudioSourceId;
  Optional&lt;bool&gt; publishCustomAudioTrackEnableAec;
  Optional&lt;bool&gt; publishDirectCustomAudioTrack;
  Optional&lt;bool&gt; publishCustomVideoTrack;
  Optional&lt;bool&gt; publishEncodedVideoTrack;
  Optional&lt;bool&gt; publishMediaPlayerAudioTrack;
  Optional&lt;bool&gt; publishMediaPlayerVideoTrack;
  Optional&lt;bool&gt; publishTrancodedVideoTrack;
  Optional&lt;bool&gt; autoSubscribeAudio;
  Optional&lt;bool&gt; autoSubscribeVideo;
  Optional&lt;bool&gt; enableAudioRecordingOrPlayout;
  Optional&lt;int&gt; publishMediaPlayerId;
  Optional&lt;CLIENT_ROLE_TYPE&gt; clientRoleType;
  Optional&lt;AUDIENCE_LATENCY_LEVEL_TYPE&gt; audienceLatencyLevel;
  Optional&lt;VIDEO_STREAM_TYPE&gt; defaultVideoStreamType;
  Optional&lt;CHANNEL_PROFILE_TYPE&gt; channelProfile;
  Optional&lt;int&gt; audioDelayMs;
  Optional&lt;int&gt; mediaPlayerAudioDelayMs;
  Optional&lt;const char*&gt; token;
  Optional&lt;bool&gt; enableBuiltInMediaEncryption;
  Optional&lt;bool&gt; publishRhythmPlayerTrack;
  Optional&lt;bool&gt; isInteractiveAudience;

  Optional&lt;video_track_id_t&gt; customVideoTrackId;

  Optional&lt;bool&gt; isAudioFilterable;

  ChannelMediaOptions() {}
  ~ChannelMediaOptions() {}</codeblock>
            <codeblock props="electron" outputclass="language-typescript">export class ChannelMediaOptions {

  publishCameraTrack?: boolean;

  publishSecondaryCameraTrack?: boolean;

  publishMicrophoneTrack?: boolean;

  publishScreenCaptureVideo?: boolean;

  publishScreenCaptureAudio?: boolean;

  publishScreenTrack?: boolean;

  publishSecondaryScreenTrack?: boolean;

  publishCustomAudioTrack?: boolean;

  publishCustomAudioSourceId?: number;

  publishCustomAudioTrackEnableAec?: boolean;

  publishDirectCustomAudioTrack?: boolean;

  publishCustomVideoTrack?: boolean;

  publishEncodedVideoTrack?: boolean;

  publishMediaPlayerAudioTrack?: boolean;

  publishMediaPlayerVideoTrack?: boolean;

  publishTrancodedVideoTrack?: boolean;

  autoSubscribeAudio?: boolean;

  autoSubscribeVideo?: boolean;

  enableAudioRecordingOrPlayout?: boolean;

  publishMediaPlayerId?: number;

  clientRoleType?: ClientRoleType;

  audienceLatencyLevel?: AudienceLatencyLevelType;

  defaultVideoStreamType?: VideoStreamType;

  channelProfile?: ChannelProfileType;

  audioDelayMs?: number;

  mediaPlayerAudioDelayMs?: number;

  token?: string;

  enableBuiltInMediaEncryption?: boolean;

  publishRhythmPlayerTrack?: boolean;

  isInteractiveAudience?: boolean;

  customVideoTrackId?: number;

  isAudioFilterable?: boolean;
}</codeblock>
            <codeblock props="unity" outputclass="language-csharp">public class ChannelMediaOptions : OptionalJsonParse
      {
          public Optional&lt;bool&gt; publishCameraTrack = new Optional&lt;bool&gt;();
          public Optional&lt;bool&gt; publishSecondaryCameraTrack = new Optional&lt;bool&gt;();
          public Optional&lt;bool&gt; publishMicrophoneTrack = new Optional&lt;bool&gt;();
          public Optional&lt;bool&gt; publishScreenCaptureVideo = new Optional&lt;bool&gt;();
          public Optional&lt;bool&gt; publishScreenCaptureAudio = new Optional&lt;bool&gt;();
          public Optional&lt;bool&gt; publishScreenTrack = new Optional&lt;bool&gt;();
          public Optional&lt;bool&gt; publishSecondaryScreenTrack = new Optional&lt;bool&gt;();
          public Optional&lt;bool&gt; publishCustomAudioTrack = new Optional&lt;bool&gt;();
          public Optional&lt;int&gt; publishCustomAudioSourceId = new Optional&lt;int&gt;();
          public Optional&lt;bool&gt; publishCustomAudioTrackEnableAec = new Optional&lt;bool&gt;();
          public Optional&lt;bool&gt; publishDirectCustomAudioTrack = new Optional&lt;bool&gt;();
          public Optional&lt;bool&gt; publishCustomVideoTrack = new Optional&lt;bool&gt;();
          public Optional&lt;bool&gt; publishEncodedVideoTrack = new Optional&lt;bool&gt;();
          public Optional&lt;bool&gt; publishMediaPlayerAudioTrack = new Optional&lt;bool&gt;();
          public Optional&lt;bool&gt; publishMediaPlayerVideoTrack = new Optional&lt;bool&gt;();
          public Optional&lt;bool&gt; publishTrancodedVideoTrack = new Optional&lt;bool&gt;();
          public Optional&lt;bool&gt; autoSubscribeAudio = new Optional&lt;bool&gt;();
          public Optional&lt;bool&gt; autoSubscribeVideo = new Optional&lt;bool&gt;();
          public Optional&lt;bool&gt; enableAudioRecordingOrPlayout = new Optional&lt;bool&gt;();
          public Optional&lt;int&gt; publishMediaPlayerId = new Optional&lt;int&gt;();
          public Optional&lt;CLIENT_ROLE_TYPE&gt; clientRoleType = new Optional&lt;CLIENT_ROLE_TYPE&gt;();
          public Optional&lt;AUDIENCE_LATENCY_LEVEL_TYPE&gt; audienceLatencyLevel = new Optional&lt;AUDIENCE_LATENCY_LEVEL_TYPE&gt;();
          public Optional&lt;VIDEO_STREAM_TYPE&gt; defaultVideoStreamType = new Optional&lt;VIDEO_STREAM_TYPE&gt;();
          public Optional&lt;CHANNEL_PROFILE_TYPE&gt; channelProfile = new Optional&lt;CHANNEL_PROFILE_TYPE&gt;();
          public Optional&lt;int&gt; audioDelayMs = new Optional&lt;int&gt;();
          public Optional&lt;int&gt; mediaPlayerAudioDelayMs = new Optional&lt;int&gt;();
          public Optional&lt;string&gt; token = new Optional&lt;string&gt;();
          public Optional&lt;bool&gt; publishRhythmPlayerTrack = new Optional&lt;bool&gt;();
          public Optional&lt;bool&gt; isInteractiveAudience = new Optional&lt;bool&gt;();
          public Optional&lt;video_track_id_t&gt; customVideoTrackId = new Optional&lt;video_track_id_t&gt;();
          public Optional&lt;bool&gt; isAudioFilterable = new Optional&lt;bool&gt;();

       }</codeblock>
            <codeblock props="rn" outputclass="language-typescript">export class ChannelMediaOptions {

  publishCameraTrack?: boolean;

  publishSecondaryCameraTrack?: boolean;

  publishMicrophoneTrack?: boolean;

  publishScreenCaptureVideo?: boolean;

  publishScreenCaptureAudio?: boolean;

  publishScreenTrack?: boolean;

  publishSecondaryScreenTrack?: boolean;

  publishCustomAudioTrack?: boolean;

  publishCustomAudioSourceId?: number;

  publishCustomAudioTrackEnableAec?: boolean;

  publishDirectCustomAudioTrack?: boolean;

  publishCustomVideoTrack?: boolean;

  publishEncodedVideoTrack?: boolean;

  publishMediaPlayerAudioTrack?: boolean;

  publishMediaPlayerVideoTrack?: boolean;

  publishTrancodedVideoTrack?: boolean;

  autoSubscribeAudio?: boolean;

  autoSubscribeVideo?: boolean;

  enableAudioRecordingOrPlayout?: boolean;

  publishMediaPlayerId?: number;

  clientRoleType?: ClientRoleType;

  audienceLatencyLevel?: AudienceLatencyLevelType;

  defaultVideoStreamType?: VideoStreamType;

  channelProfile?: ChannelProfileType;

  audioDelayMs?: number;

  mediaPlayerAudioDelayMs?: number;

  token?: string;

  enableBuiltInMediaEncryption?: boolean;

  publishRhythmPlayerTrack?: boolean;

  isInteractiveAudience?: boolean;

  customVideoTrackId?: number;

  isAudioFilterable?: boolean;
}</codeblock>
            <codeblock props="flutter" outputclass="language-dart">class ChannelMediaOptions {
  const ChannelMediaOptions(
      {this.publishCameraTrack,
      this.publishSecondaryCameraTrack,
      this.publishMicrophoneTrack,
      this.publishScreenCaptureVideo,
      this.publishScreenCaptureAudio,
      this.publishScreenTrack,
      this.publishSecondaryScreenTrack,
      this.publishCustomAudioTrack,
      this.publishCustomAudioSourceId,
      this.publishCustomAudioTrackEnableAec,
      this.publishDirectCustomAudioTrack,
      this.publishCustomAudioTrackAec,
      this.publishCustomVideoTrack,
      this.publishEncodedVideoTrack,
      this.publishMediaPlayerAudioTrack,
      this.publishMediaPlayerVideoTrack,
      this.publishTrancodedVideoTrack,
      this.autoSubscribeAudio,
      this.autoSubscribeVideo,
      this.enableAudioRecordingOrPlayout,
      this.publishMediaPlayerId,
      this.clientRoleType,
      this.audienceLatencyLevel,
      this.defaultVideoStreamType,
      this.channelProfile,
      this.audioDelayMs,
      this.mediaPlayerAudioDelayMs,
      this.token,
      this.enableBuiltInMediaEncryption,
      this.publishRhythmPlayerTrack,
      this.isInteractiveAudience,
      this.customVideoTrackId,
      this.isAudioFilterable});

  @JsonKey(name: 'publishCameraTrack')
  final bool? publishCameraTrack;

  @JsonKey(name: 'publishSecondaryCameraTrack')
  final bool? publishSecondaryCameraTrack;

  @JsonKey(name: 'publishMicrophoneTrack')
  final bool? publishMicrophoneTrack;

  @JsonKey(name: 'publishScreenCaptureVideo')
  final bool? publishScreenCaptureVideo;

  @JsonKey(name: 'publishScreenCaptureAudio')
  final bool? publishScreenCaptureAudio;

  @JsonKey(name: 'publishScreenTrack')
  final bool? publishScreenTrack;

  @JsonKey(name: 'publishSecondaryScreenTrack')
  final bool? publishSecondaryScreenTrack;

  @JsonKey(name: 'publishCustomAudioTrack')
  final bool? publishCustomAudioTrack;

  @JsonKey(name: 'publishCustomAudioSourceId')
  final int? publishCustomAudioSourceId;

  @JsonKey(name: 'publishCustomAudioTrackEnableAec')
  final bool? publishCustomAudioTrackEnableAec;

  @JsonKey(name: 'publishDirectCustomAudioTrack')
  final bool? publishDirectCustomAudioTrack;

  @JsonKey(name: 'publishCustomAudioTrackAec')
  final bool? publishCustomAudioTrackAec;

  @JsonKey(name: 'publishCustomVideoTrack')
  final bool? publishCustomVideoTrack;

  @JsonKey(name: 'publishEncodedVideoTrack')
  final bool? publishEncodedVideoTrack;

  @JsonKey(name: 'publishMediaPlayerAudioTrack')
  final bool? publishMediaPlayerAudioTrack;

  @JsonKey(name: 'publishMediaPlayerVideoTrack')
  final bool? publishMediaPlayerVideoTrack;

  @JsonKey(name: 'publishTrancodedVideoTrack')
  final bool? publishTrancodedVideoTrack;

  @JsonKey(name: 'autoSubscribeAudio')
  final bool? autoSubscribeAudio;

  @JsonKey(name: 'autoSubscribeVideo')
  final bool? autoSubscribeVideo;

  @JsonKey(name: 'enableAudioRecordingOrPlayout')
  final bool? enableAudioRecordingOrPlayout;

  @JsonKey(name: 'publishMediaPlayerId')
  final int? publishMediaPlayerId;

  @JsonKey(name: 'clientRoleType')
  final ClientRoleType? clientRoleType;

  @JsonKey(name: 'audienceLatencyLevel')
  final AudienceLatencyLevelType? audienceLatencyLevel;

  @JsonKey(name: 'defaultVideoStreamType')
  final VideoStreamType? defaultVideoStreamType;

  @JsonKey(name: 'channelProfile')
  final ChannelProfileType? channelProfile;

  @JsonKey(name: 'audioDelayMs')
  final int? audioDelayMs;

  @JsonKey(name: 'mediaPlayerAudioDelayMs')
  final int? mediaPlayerAudioDelayMs;

  @JsonKey(name: 'token')
  final String? token;

  @JsonKey(name: 'enableBuiltInMediaEncryption')
  final bool? enableBuiltInMediaEncryption;

  @JsonKey(name: 'publishRhythmPlayerTrack')
  final bool? publishRhythmPlayerTrack;

  @JsonKey(name: 'isInteractiveAudience')
  final bool? isInteractiveAudience;

  @JsonKey(name: 'customVideoTrackId')
  final int? customVideoTrackId;

  @JsonKey(name: 'isAudioFilterable')
  final bool? isAudioFilterable;

  factory ChannelMediaOptions.fromJson(Map&lt;String, dynamic&gt; json) =&gt;
      _$ChannelMediaOptionsFromJson(json);

  Map&lt;String, dynamic&gt; toJson() =&gt; _$ChannelMediaOptionsToJson(this);
}</codeblock>            
            <codeblock props="reserve" outputclass="language-cpp" /></p>
        </section>
        <section id="detailed_desc">Agora supports publishing multiple audio streams and one video stream at the same time and in the same <xref keyref="RtcConnection" />. For example, <parmname>publishMicrophoneTrack</parmname>, <parmname>publishAudioTrack</parmname>, <parmname>publishCustomAudioTrack</parmname>, and <parmname>publishMediaPlayerAudioTrack</parmname> can be set as <codeph><ph keyref="true" /></codeph> at the same time, but only one of <parmname>publishCameraTrack</parmname>, <parmname props="android ios">publishScreenCaptureVideo</parmname><parmname props="mac cpp framework">publishScreenTrack</parmname>, <parmname>publishCustomVideoTrack</parmname>, or <parmname>publishEncodedVideoTrack</parmname> can be set as <codeph><ph keyref="true" /></codeph>.</section>
        <section id="parameters">
            <title><text conref="../conref/conref_api_metadata.dita#conref_api_metadata/property" /></title>
            <parml>
            <plentry>
                <pt>publishCameraTrack</pt>
                <pd>Whether to publish the video captured by the camera:<ul id="ul_vx5_np5_3qb">
                    <li><codeph><ph keyref="true" /></codeph>: (Default) Publish the video captured by the camera.</li>
                    <li><codeph><ph keyref="false" /></codeph>: Do not publish the video captured by the camera.</li>
                    </ul></pd>
            </plentry>
            <plentry>
                <pt>publishMicrophoneTrack</pt>
                <pd>Whether to publish the audio captured by the microphone:<ul>
                    <li><codeph><ph keyref="true" /></codeph>: (Default) Publish the audio captured by the microphone.</li>
                    <li><codeph><ph keyref="false" /></codeph>: Do not publish the audio captured by the microphone.</li>
                </ul></pd>
                <pd props="native unity rn electron">
                    <note type="note">As of v4.0.0, the parameter name is changed from <parmname>publishAudioTrack</parmname> to <parmname>publishMicrophoneTrack</parmname>.</note>
                </pd>
                <pd props="flutter">
                    <note type="note">As of v4.0.0, the parameter name is changed from <parmname>publishAudioTrack</parmname> to <parmname>publishMicrophoneTrack</parmname>.</note>
                </pd>
            </plentry>
            <plentry props="cpp unity flutter rn electron">
                <pt>publishSecondaryCameraTrack</pt>
                <pd>Whether to publish the video captured by the second camera:<ul>
                    <li><codeph><ph keyref="true" /></codeph>: Publish the video captured by the second camera.</li>
                    <li><codeph><ph keyref="false" /></codeph>: (Default) Do not publish the video captured by the second camera.</li>
                    </ul></pd>
            </plentry>
            <plentry>
                <pt props="android ios">publishScreenCaptureVideo</pt>
                <pt props="mac cpp framework">publishScreenTrack</pt>
                <pd>
                    <p>Whether to publish the video captured from the screen:<ul>
                    <li><codeph><ph keyref="true" /></codeph>: Publish the video captured from the screen.</li>
                    <li><codeph><ph keyref="false" /></codeph>: (Default) Do not publish the video captured from the screen.</li>
                    </ul></p>
                    <p><note type="note" props="android ios">Since v4.0.0, the parameter name has been changed from <parmname>publishScreenTrack</parmname> to <parmname>publishScreenCaptureVideo</parmname>.</note></p>
                </pd>
            </plentry>
            <plentry props="cpp unity flutter rn electron">
                <pt>publishScreenCaptureVideo</pt>
                <pd>
                    <p>Whether to publish the video captured from the screen:<ul>
                    <li><codeph><ph keyref="true" /></codeph>: Publish the video captured from the screen.</li>
                    <li><codeph><ph keyref="false" /></codeph>: (Default) Do not publish the video captured from the screen.</li>
                    </ul></p>
                    <p><note type="attention" props="cpp unity flutter rn electron">This parameter applies to Android and iOS only.</note></p> </pd>
            </plentry>
            <plentry props="android ios cpp framework">
                <pt>publishScreenCaptureAudio</pt>
                <pd>
                    <p>Whether to publish the audio captured from the screen:<ul>
                    <li><codeph><ph keyref="true" /></codeph>: Publish the audio captured from the screen.</li>
                    <li><codeph><ph keyref="false" /></codeph>: (Default) Do not publish the audio captured from the screen.</li>
                    </ul></p>
                    <p>
                    <note type="attention" props="cpp unity flutter rn electron">This parameter applies to Android and iOS only.</note></p>
                </pd>
            </plentry>
            <plentry props="cpp unity flutter rn electron">
                <pt>publishSecondaryScreenTrack</pt>
                <pd>Whether to publish the video captured from the second screen:<ul>
                    <li><codeph><ph keyref="true" /></codeph>: Publish the video captured from the second screen.</li>
                    <li><codeph><ph keyref="false" /></codeph>: (Default) Do not publish the video captured from the second screen.</li>
                    </ul>
                </pd>
            </plentry>
            <plentry props="cpp unity flutter rn electron">
                <pt>publishTrancodedVideoTrack</pt>
                <pd>Whether to publish the local transcoded video:<ul>
                    <li><codeph><ph keyref="true" /></codeph>: Publish the local transcoded video.</li>
                    <li><codeph><ph keyref="false" /></codeph>: (Default) Do not publish the local transcoded video.</li>
                    </ul></pd>
            </plentry>
            <plentry>
                <pt>publishCustomAudioTrack</pt>
                <pd>Whether to publish the audio captured from a custom source:<ul>
                    <li><codeph><ph keyref="true" /></codeph>: Publish the audio captured from the custom source.</li>
                    <li><codeph><ph keyref="false" /></codeph>: (Default) Do not publish the audio captured from the custom source.</li>
                    </ul></pd>
            </plentry>
            <plentry>
                <pt>publishCustomAudioSourceId</pt>
                <pd>The ID of the custom audio source to publish. The default value is 0.<p>If you have set <parmname>sourceNumber</parmname> in <xref keyref="setExternalAudioSource2" /> to a value greater than 1, the SDK creates the corresponding number of custom audio tracks and assigns an ID to each audio track, starting from 0.</p>
                </pd>
            </plentry>
            <plentry props="cpp unity flutter rn electron">
                <pt>publishCustomAudioTrackEnableAec</pt>
                <pd>Whether to enable AEC when publishing the audio captured from a custom source:<ul>
                    <li><codeph><ph keyref="true" /></codeph>: Enable AEC when publishing the audio captured from the custom source.</li>
                    <li><codeph><ph keyref="false" /></codeph>: (Default) Do not enable AEC when publishing the audio captured from the custom source.</li>
                    </ul></pd>
            </plentry>
            <plentry>
                <pt>publishCustomVideoTrack</pt>
                <pd>Whether to publish the video captured from a custom source:<ul>
                    <li><codeph><ph keyref="true" /></codeph>: Publish the video captured from the custom source.</li>
                    <li><codeph><ph keyref="false" /></codeph>: (Default) Do not publish the video captured from the custom source.</li>
                    </ul></pd>
            </plentry>
            <plentry>
                <pt>publishEncodedVideoTrack</pt>
                <pd>Whether to publish the encoded video:<ul id="ul_ljg_4q5_3qb">
                    <li><codeph><ph keyref="true" /></codeph>: Publish the encoded video.</li>
                    <li><codeph><ph keyref="false" /></codeph>: (Default) Do not publish the encoded video.</li>
                    </ul></pd>
            </plentry>
            <plentry>
                <pt>publishMediaPlayerAudioTrack</pt>
                <pd>Whether to publish the audio from the media player:<ul id="ul_gr3_rq5_3qb">
                    <li><codeph><ph keyref="true" /></codeph>: Publish the audio from the media player.</li>
                    <li><codeph><ph keyref="false" /></codeph>: (Default) Do not publish the audio from the media player.</li>
                    </ul></pd>
            </plentry>
            <plentry>
                <pt>publishMediaPlayerVideoTrack</pt>
                <pd>Whether to publish the video from the media player:<ul id="ul_gtd_tq5_3qb">
                    <li><codeph><ph keyref="true" /></codeph>: Publish the video from the media player.</li>
                    <li><codeph><ph keyref="false" /></codeph>: (Default) Do not publish the video from the media player.</li>
                    </ul></pd>
            </plentry>
            <plentry>
                <pt>autoSubscribeAudio</pt>
                <pd>Whether to automatically subscribe to all remote audio streams when the user joins a channel:<ul id="ul_gxf_vq5_3qb">
                    <li><codeph><ph keyref="true" /></codeph>: (Default) Automatically subscribe to all remote audio streams.</li>
                    <li><codeph><ph keyref="false" /></codeph>: Do not automatically subscribe to any remote audio streams.</li>
                    </ul> </pd>
            </plentry>
            <plentry>
                <pt>autoSubscribeVideo</pt>
                <pd>Whether to automatically subscribe to all remote video streams when the user joins the channel:<ul id="ul_gfh_xq5_3qb">
                    <li><codeph><ph keyref="true" /></codeph>: (Default) Automatically subscribe to all remote video streams.</li>
                    <li><codeph><ph keyref="false" /></codeph>: Do not automatically subscribe to any remote video streams.</li>
                    </ul> </pd>
            </plentry>
            <plentry>
                <pt>enableAudioRecordingOrPlayout</pt>
                <pd>Whether to enable audio capturing or playback:<ul>
                    <li><codeph><ph keyref="true" /></codeph>: (Default) Enable audio capturing or playback.</li>
                    <li><codeph><ph keyref="false" /> </codeph>: Do not enable audio capturing or playback.</li>
                    </ul> </pd>
            </plentry>
            <plentry>
                <pt>publishMediaPlayerId</pt>
                <pd>The ID of the media player to be published. The default value is 0.</pd>
            </plentry>
            <plentry props="native unity">
                <pt>clientRoleType</pt>
                <pd conkeyref="setClientRole1/clientrole" />
            </plentry>
            <plentry props="rn electron flutter">
                <pt>clientRoleType</pt>
                <pd>The user role. See <xref keyref="CLIENT_ROLE_TYPE" />.</pd>
            </plentry>
            <plentry conkeyref="ClientRoleOptions/audiencelatencylevel">
                <pt />
                <pd />
            </plentry>
            <plentry>
                <pt>defaultVideoStreamType</pt>
                <pd conkeyref="setRemoteDefaultVideoStreamType/defaultstreamtype" />
            </plentry>
            <plentry>
                <pt>channelProfile</pt>
                <pd conkeyref="setChannelProfile/channelprofiletype" />
            </plentry>
            <plentry props="hide">
                <pt>audioDelayMs</pt>
                <pd>
                    <p>The delay in milliseconds for sending audio frames. This is used for explicit control of A/V sync.</p>
                    <p>To switch off the delay, set the value to 0.</p>
                </pd>
            </plentry>
            <plentry props="hide">
                <pt>publishCustomAudioTrackAec</pt>
                <pd>Whether to publish audio frames processed by an external echo cancellation module.<ul>
                    <li><codeph><ph keyref="true" /></codeph>: Publish audio frames processed by the external echo cancellation module.</li>
                    <li><codeph><ph keyref="false" /></codeph>: Do not publish to publish audio frames processed by the external echo cancellation module.</li>
                    </ul> </pd>
            </plentry>
            <plentry>
                <pt>token</pt>
                <pd>
                    <p>(Optional) The token generated on your server for authentication. See <xref keyref="guide-token" props="native">Authenticate Your Users with Token</xref>.</p>
                    <note type="caution">
                    <ul>
                    <li>This parameter takes effect only when calling <xref keyref="updateChannelMediaOptions" /> or <xref keyref="updateChannelMediaOptionsEx" />.</li>
                    <li>Ensure that the App ID, channel name, and user name used for creating the token are the same as those used by the <xref keyref="initialize" /> method for initializing the RTC engine, and those used by the <xref keyref="joinChannel2" /> and <xref keyref="joinChannelEx" /> methods for joining the channel.</li>
                    </ul></note></pd>
            </plentry>
            <plentry props="hide">
                <pt>startPreview</pt>
                <pd>Whether to automatically start the preview when joining a channel:<ul>
                    <li><codeph><ph keyref="true" /></codeph>: (Default) Automatically start the preview. Ensure that you have called the <xref keyref="setupLocalVideo" /> method to set the local video property; otherwise, the preview is not enabled.</li>
                    <li><codeph><ph keyref="false" /></codeph>: Do not automatically start the preview.</li>
                    </ul></pd>
            </plentry>
            <plentry>
                <pt>publishRhythmPlayerTrack</pt>
                <pd>Whether to publish the sound of a metronome to remote users:<ul>
                    <li><codeph><ph keyref="true" /></codeph>: (Default) Publish the sound of the metronome. Both the local user and remote users can hear the metronome.</li>
                    <li><codeph><ph keyref="false" /></codeph>: Do not publish the sound of the metronome. Only the local user can hear the metronome.</li>
                    </ul></pd>
            </plentry>
            <plentry>
                <pt>isInteractiveAudience</pt>
                <pd>Whether to enable interactive mode:<ul>
                    <li><codeph><ph keyref="true" /></codeph>: Enable interactive mode. Once this mode is enabled and the user role is set as audience, the user can receive remote video streams with low latency.</li>
                    <li><codeph><ph keyref="false" /></codeph>: (Default) Do not enable interactive mode. If this mode is disabled, the user receives the remote video streams in default settings.</li>
                    </ul>
                    <note type="attention">
                    <ul>
                    <li>This parameter only applies to scenarios involving cohosting across channels. The cohosts need to call the <xref keyref="joinChannelEx" /> method to join the other host's channel as an audience member, and set <parmname>isInteractiveAudience</parmname> to <codeph><ph keyref="true" /></codeph>.</li>
                    <li>This parameter takes effect only when the user role is <apiname keyref="CLIENT_ROLE_AUDIENCE" />.</li>
                    </ul> </note> </pd>
            </plentry>
            <plentry id="customvideotrackid">
                <pt>customVideoTrackId</pt>
                <pd>The video track ID returned by calling the <xref keyref="createCustomVideoTrack" /> method. The default value is 0.</pd>
            </plentry>
            <plentry>
                <pt>isAudioFilterable</pt>
                <pd>Whether the audio stream being published is filtered according to the volume algorithm:<ul>
                    <li><codeph><ph keyref="true" /></codeph>: (Default) The audio stream is filtered. If the audio stream filter is not enabled, this setting does not takes effect.</li>
                    <li><codeph><ph keyref="false" /></codeph>: The audio stream is not filtered.</li>
                    </ul>
                    <note type="attention">If you need to enable this function, contact <xref keyref="mailto-link" />.</note></pd>
            </plentry>
            </parml> </section>
    </refbody>
</reference>