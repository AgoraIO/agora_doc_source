<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="callback_irtcengineeventhandler_onfacepositionchanged">
    <title><ph keyref="onFacePositionChanged" /></title>
    <shortdesc id="short"><ph id="shortdesc">Reports the face detection result of the local user.</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="onFacePositionChanged" />
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">public void onFacePositionChanged(
                int imageWidth, int imageHeight, AgoraFacePositionInfo[] faceRectArr) {}</codeblock>
            <codeblock props="ios mac" outputclass="language-objectivec">- (void)rtcEngine:(AgoraRtcEngineKit* _Nonnull)engine facePositionDidChangeWidth:(int)width previewHeight:(int)height faces:(NSArray&lt;AgoraFacePositionInfo*&gt;* _Nullable)faces NS_SWIFT_NAME(rtcEngine(_:facePositionDidChangeWidth:previewHeight:faces:));</codeblock>
            <codeblock props="cpp unreal" outputclass="language-cpp">virtual void onFacePositionChanged(int imageWidth, int imageHeight,
                const Rectangle* vecRectangle, const int* vecDistance,
                int numFaces) {
                (void) imageWidth;
                (void) imageHeight;
                (void) vecRectangle;
                (void) vecDistance;
                (void) numFaces;
                }</codeblock>
         <codeblock props="bp" outputclass="language-cpp">DECLARE_DYNAMIC_MULTICAST_DELEGATE_FiveParams(FOnFacePositionChanged, int, imageWidth, int, imageHeight, FRectangle, vecRectangle, TArray&lt;int&gt;, vecDistance, int, numFaces);</codeblock>
            <codeblock props="electron" outputclass="language-typescript">  onFacePositionChanged?(
    imageWidth: number,
    imageHeight: number,
    vecRectangle: Rectangle,
    vecDistance: number,
    numFaces: number
  ): void;</codeblock>
            <codeblock props="unity cs" outputclass="language-csharp">public virtual void OnFacePositionChanged(int imageWidth, int imageHeight, Rectangle vecRectangle, int[] vecDistance, int numFaces) {}</codeblock>
            <codeblock props="rn" outputclass="language-typescript">  onFacePositionChanged?(
    imageWidth: number,
    imageHeight: number,
    vecRectangle: Rectangle,
    vecDistance: number,
    numFaces: number
  ): void;</codeblock>
            <codeblock props="flutter" outputclass="language-dart">final void Function(int imageWidth, int imageHeight, Rectangle vecRectangle,
      int vecDistance, int numFaces)? onFacePositionChanged;</codeblock>
            <codeblock props="reserve" outputclass="language-cpp"></codeblock></p>
        </section>
        <section id="detailed_desc">
            <p>Once you enable face detection by calling <xref keyref="enableFaceDetection" /><codeph>(<ph keyref="true" />)</codeph>, you can get the following information on the local user in real-time:<ul>
            <li>The width and height of the local video.</li>
            <li>The position of the human face in the local view.</li>
            <li>The distance between the human face and the screen.</li>
            </ul> </p>
            <p>This value is based on the fitting calculation of the local video size and the position of the human face.</p>
            <note type="attention">
            <ul>
            <li props="cpp unreal bp unity flutter cs">This callback is for Android and iOS only.</li>
            <li>When it is detected that the face in front of the camera disappears, the callback will be triggered immediately. When no human face is detected, the frequency of this callback to be triggered wil be decreased to reduce power consumption on the local device.</li>
            <li>The SDK stops triggering this callback when a human face is in close proximity to the screen.</li>
            <li props="cpp unreal bp android flutter">On Android, the value of distance reported in this callback may be slightly different from the actual <parmname>distance</parmname>. Therefore, Agora does not recommend using it for accurate calculation.</li>
            </ul> </note> </section>
        <section id="parameters">
            <title><ph keyref="callback-section-title" /></title>
            <parml>
            <plentry conkeyref="onJoinChannelSuccess/engine" props="ios mac">
                <pt />
                <pd />
            </plentry>
            <plentry>
                <pt props="android cpp unreal bp unity electron rn flutter cs">imageWidth</pt>
                <pt props="ios mac">width</pt>
                <pd>The width (px) of the video image captured by the local camera.</pd>
            </plentry>
            <plentry>
                <pt props="android cpp unreal bp unity flutter rn electron cs">imageHeight</pt>
                <pt props="ios mac">height</pt>
                <pd>The height (px) of the video image captured by the local camera.</pd>
            </plentry>
            <plentry props="android ios mac">
                <pt props="android">faceRectArr</pt>
                <pt props="ios mac">faces</pt>
                <pd>Information of the detected face. See <xref keyref="AgoraFacePositionInfo" />. The number of <apiname keyref="AgoraFacePositionInfo" /> array reported in this callback is based on the faces detected. The length of the array can be 0, which means that no human face is detected in front of the camera.</pd>
            </plentry>
            <plentry props="cpp unreal bp unity flutter rn electron cs">
                <pt>vecRectangle</pt>
                <pd props="cpp unreal bp">
                    <p>An array of <parmname>numFaces</parmname>, representing the detected face information:<ul>
                    <li><codeph>x</codeph>: The x-coordinate (px) of the human face in the local view. Taking the top left corner of the view as the origin, the x-coordinate represents the horizontal position of the human face relative to the origin.</li>
                    <li><codeph>y</codeph>: The y-coordinate (px) of the human face in the local view. Taking the top left corner of the view as the origin, the y-coordinate represents the vertical position of the human face relative to the origin.</li>
                    <li><codeph>width</codeph>: The width (px) of the human face in the captured view.</li>
                    <li><codeph>height</codeph>: The height (px) of the human face in the captured view.</li>
                    </ul> </p>
                </pd>
                <pd props="unity flutter rn electron cs">The information of the detected human face. See <xref keyref="Rectangle" />.</pd>
            </plentry>
            <plentry props="cpp unreal bp unity flutter rn electron cs">
                <pt>vecDistance</pt>
                <pd props="cpp unreal bp">An array of <parmname>numFaces</parmname>, representing the distance (cm) between a face and the device screen.</pd>
                <pd props="unity flutter rn electron cs">The distance between the human face and the device screen (cm).</pd>
            </plentry>
            <plentry props="cpp unreal bp unity flutter rn electron cs">
                <pt>numFaces</pt>
                <pd>The number of faces detected. If the value is 0, it means that no human face is detected.</pd>
            </plentry>
            </parml> </section>
    </refbody>
</reference>