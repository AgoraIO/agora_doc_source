<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="api_irtcengine_setavsyncsource">
    <title> <ph keyref="setAVSyncSource" /> </title>
    <shortdesc id="short"><ph id="shortdesc">Sets the pitch of the local music file.</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="setAVSyncSource" />
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">public abstract int setAVSyncSource(String channelId, int uid);</codeblock>
            <codeblock props="ios mac" outputclass="language-objectivec">- (int) setAVSyncSource:(NSString* _Nonnull)channelId uid:(NSUInteger)uid;</codeblock>
            <codeblock props="cpp unreal bp" outputclass="language-cpp">virtual int setAVSyncSource(const char* channelId, uid_t uid) = 0;</codeblock>
            <codeblock props="electron" outputclass="language-typescript">abstract setAVSyncSource(channelId: string, uid: number): number;</codeblock>
            <codeblock props="unity cs" outputclass="language-csharp">public abstract int SetAVSyncSource(string channelId, uint uid);</codeblock>
            <codeblock props="rn" outputclass="language-typescript">abstract setAVSyncSource(channelId: string, uid: number): number;</codeblock>
            <codeblock props="flutter" outputclass="language-dart">Future&lt;void&gt; setAVSyncSource({required String channelId, required int uid});</codeblock>
            <codeblock props="reserve" outputclass="language-cpp" /></p>
        </section>
        <section id="detailed_desc">
            <title>Details</title>
            <p>The same user may use two devices to send audio and video streams respectively. In order to ensure the time synchronization of the audio and video heard and seen by the receiver, you can call this method on the video sender and pass in the user ID and channel name of the audio sender. The SDK automatically adjusts the sent video stream based on the timestamp of the sent audio stream to ensure that even when the uplink network conditions of the two senders are inconsistent (such as using Wi-Fi and 4G networks respectively), the received audio and video are time-synchronized.</p>
            <note type="attention">Agora recommends that you call this method before joining a channel.</note> </section>
        <section id="parameters">
            <title>Parameters</title>
            <parml>
            <plentry>
                <pt>channelId</pt>
                <pd>The channel name that identifies the channel where the audio sender is located.</pd>
            </plentry>
            <plentry>
                <pt>uid</pt>
                <pd>The user ID of the audio sender.</pd>
            </plentry>
            </parml> </section>
        <section id="return_values">
            <title><ph keyref="return-section-title" /></title>
            <p props="flutter">When the method call succeeds, there is no return value; when fails, the <xref keyref="AgoraRtcException" /> exception is thrown; and you need to catch the exception and handle it accordingly.</p>
            <ul>
            <li props="native unreal bp unity rn electron cs">0: Success.</li>
            <li>&lt; 0: Failure.</li>
            </ul> </section>
    </refbody>
</reference>