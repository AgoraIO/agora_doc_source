<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="api_irtcengine_pullaudioframe2">
    <title><ph keyref="pullAudioFrame2" /></title>
    <shortdesc id="short"><ph id="shortdesc">Pulls the remote audio data.</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="pullAudioFrame2" />
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">public abstract int pullPlaybackAudioFrame(ByteBuffer data, int lengthInByte);</codeblock>
            <codeblock props="ios mac" outputclass="language-objectivec" />
            <codeblock props="cpp" outputclass="language-cpp" />
            <codeblock props="electron" outputclass="language-typescript" />
            <codeblock props="unity" outputclass="language-csharp" />
            <codeblock props="rn" outputclass="language-typescript" />
           <codeblock props="flutter" outputclass="language-dart" /> 
            <codeblock props="reserve" outputclass="language-cpp" /></p>
        </section>
        <section id="detailed_desc">
            <p>Before calling this method, call the <codeph><xref keyref="setExternalAudioSink" />(<parmname>enabled</parmname>: <ph keyref="true" />)</codeph> method to notify the app to enable and set the external audio sink.</p>
            <p>After a successful method call, the app pulls the decoded and mixed audio data for playback.</p>
            <note type="attention">
            <ul>
            <li>Call this method after joining a channel.</li>
            <li>The difference between this method and the <apiname keyref="onPlaybackAudioFrame" /> callback is as follows:<ul>
                <li><apiname keyref="onPlaybackAudioFrame" />: The SDK sends the audio data to the app through this callback. Any delay in processing the audio frames may result in audio jitter.</li>
                <li><apiname keyref="pullAudioFrame" />: The app pulls the remote audio data. After setting the audio data parameters, the SDK adjusts the frame buffer and avoids problems caused by jitter in the external audio playback.</li>
                </ul></li>
            </ul> </note> </section>
        <section id="parameters">
            <title>Parameters</title>
            <parml>
            <plentry>
                <pt>data</pt>
                <pd>The remote audio data to be pulled. The data type is <codeph>ByteBuffer</codeph>.</pd>
            </plentry>
            <plentry>
                <pt>lengthInByte</pt>
                <pd>The length (in bytes) of the remote audio data. The value of this parameter is related to the audio duration,and the values of the <parmname>sampleRate</parmname> and <parmname>channels</parmname> parameters that you set in <apiname keyref="setExternalAudioSink" />. <parmname>lengthInByte</parmname> = <parmname>sampleRate</parmname>/1000 × 2 × <parmname>channels</parmname> × audio duration (ms).</pd>
            </plentry>
            </parml> </section>
        <section id="return_values">
            <title>Returns</title>
            <ul>
            <li>0: Success.</li>
            <li>&lt; 0: Failure.</li>
            </ul> </section>
    </refbody>
</reference>