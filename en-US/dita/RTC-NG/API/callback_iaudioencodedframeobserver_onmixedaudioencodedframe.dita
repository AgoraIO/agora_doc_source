<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="callback_iaudioencodedframeobserver_onmixedaudioencodedframe">
    <title><ph keyref="onMixedAudioEncodedFrame"/></title>
    <shortdesc id="short"><ph id="shortdesc">Gets the mixed and encoded audio data of the local and all remote users.</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="onMixedAudioEncodedFrame"/>
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">public abstract void onMixedAudioEncodedFrame(
      ByteBuffer buffer, int samplesPerChannel, int channels, int samplesPerSec, int codecType);</codeblock>
            <codeblock props="hmos" outputclass="language-arkts"></codeblock>
            <codeblock props="ios mac" outputclass="language-objectivec">- (void)onMixedEncodedAudioFrame:(NSData* _Nonnull)frameData info:(AgoraEncodedAudioFrameInfo* _Nonnull) info;</codeblock>
            <codeblock props="cpp unreal" outputclass="language-cpp">virtual void onMixedAudioEncodedFrame(const uint8_t* frameBuffer,  int length, const EncodedAudioFrameInfo&amp; audioEncodedFrameInfo) = 0;</codeblock>
         <codeblock props="bp" outputclass="language-cpp">DECLARE_DYNAMIC_MULTICAST_DELEGATE_ThreeParams(FOnMixedAudioEncodedFrame, const TArray&lt;int64&gt;, frameBuffer, int, length, const FEncodedAudioFrameInfo&amp;, audioEncodedFrameInfo);</codeblock>
            <codeblock props="electron" outputclass="language-typescript">onMixedAudioEncodedFrame?(
    frameBuffer: Uint8Array,
    length: number,
    audioEncodedFrameInfo: EncodedAudioFrameInfo
  ): void;</codeblock>
            <codeblock props="unity cs" outputclass="language-csharp">public virtual void OnMixedAudioEncodedFrame(IntPtr frameBufferPtr, int length,
                                                    EncodedAudioFrameInfo audioEncodedFrameInfo)
        {

        }</codeblock>
            <codeblock props="rn" outputclass="language-typescript">onMixedAudioEncodedFrame?(
    frameBuffer: Uint8Array,
    length: number,
    audioEncodedFrameInfo: EncodedAudioFrameInfo
  ): void;</codeblock>
            <codeblock props="flutter" outputclass="language-dart">final void Function(Uint8List frameBuffer, int length,
      EncodedAudioFrameInfo audioEncodedFrameInfo)? onMixedAudioEncodedFrame;</codeblock>
            <codeblock props="reserve" outputclass="language-cpp"></codeblock></p>
        </section>
        <section id="detailed_desc">
            <p>After calling <xref keyref="registerAudioEncodedFrameObserver"/> and setting the audio profile as <ph keyref="AUDIO_ENCODED_FRAME_OBSERVER_POSITION_MIXED"/>, you can get the mixed and encoded audio data of the local and all remote users through this callback.</p>
        </section>
        <section id="parameters" conkeyref="onRecordAudioEncodedFrame/parameters"/>
    </refbody>
</reference>
