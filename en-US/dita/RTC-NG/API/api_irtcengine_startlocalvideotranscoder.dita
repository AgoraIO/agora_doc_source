<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="api_irtcengine_startlocalvideotranscoder">
    <title><ph keyref="startLocalVideoTranscoder" /></title>
    <shortdesc id="short"><ph id="shortdesc">Starts the local video mixing.</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="startLocalVideoTranscoder" />
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">public abstract int startLocalVideoTranscoder(LocalTranscoderConfiguration config);</codeblock>
            <codeblock props="ios mac" outputclass="language-objectivec">- (int)startLocalVideoTranscoder:(AgoraLocalTranscoderConfiguration* _Nonnull)config NS_SWIFT_NAME(startLocalVideoTranscoder(_:));</codeblock>
            <codeblock props="cpp unreal" outputclass="language-cpp">virtual int startLocalVideoTranscoder(const LocalTranscoderConfiguration&amp; config) = 0;
</codeblock>
         <codeblock props="bp" outputclass="language-cpp">UFUNCTION(BlueprintCallable, Category = &quot;Agora|RtcEngineProxy&quot;)
	int StartLocalVideoTranscoder(const FLocalTranscoderConfiguration&amp; config);</codeblock>
            <codeblock props="electron" outputclass="language-typescript">abstract startLocalVideoTranscoder(
    config: LocalTranscoderConfiguration
  ): number;</codeblock>
            <codeblock props="unity cs" outputclass="language-csharp">public abstract int StartLocalVideoTranscoder(LocalTranscoderConfiguration config);</codeblock>
            <codeblock props="rn" outputclass="language-typescript">abstract startLocalVideoTranscoder(
    config: LocalTranscoderConfiguration
  ): number;</codeblock>
            <codeblock props="flutter" outputclass="language-dart">Future&lt;void&gt; startLocalVideoTranscoder(LocalTranscoderConfiguration config);</codeblock>
            <codeblock props="reserve" outputclass="language-cpp"></codeblock></p>
        </section>
        <section id="detailed_desc" deliveryTarget="details" otherprops="no-title">
            <p>After calling this method, you can merge multiple video streams into one video stream locally. For example, you can merge the video streams captured by the camera, screen sharing, media player, remote video, video files, images, etc. into one video stream, and then publish the mixed video stream to the channel.</p>
        </section>
        <section id="scenario" deliveryTarget="details">
        <title>Applicable scenarios</title>
        <p>You can enable the local video mixing function in scenarios such as remote conferences, live streaming, and online education, which allows users to view and manage multiple videos more conveniently, and supports portrait-in-picture effect and other functions.</p>
        <p>The following is a typical use case for implementing the portrait-in-picture effect:<ol>
                <li>Call <xref keyref="enableVirtualBackground"/>, and set the custom background image to <apiname keyref="BACKGROUND_NONE"/>, that is, separate the portrait and the background in the video captured by the camera.</li>
                <li>Call <xref props="cpp unreal bp mac unity cs flutter electron" keyref="startScreenCapture2"/><xref props="ios android rn" keyref="startScreenCapture"/> to start capturing the screen sharing video stream.</li>
                <li>Call this method and set the video source for capturing portraits as one of the video sources participating in the local video mixing, picture-in-picture of the portrait can be achived in the mixed video.</li>
                </ol></p>
        </section>
        <section id="timing" deliveryTarget="details">
            <title>Call timing</title>
            <ul>
                <li>If you need to mix the locally collected video streams, you need to call this method after <xref keyref="startCameraCapture"/> or <xref props="cpp unreal bp mac unity cs flutter electron" keyref="startScreenCapture2"/><xref props="ios android rn" keyref="startScreenCapture"/>.</li> 
                <li>If you want to publish the mixed video stream to the channel, you need to set <parmname>publishTranscodedVideoTrack</parmname> in <xref keyref="ChannelMediaOptions"/> to <codeph><ph keyref="true"/></codeph> when calling <xref keyref="joinChannel2"/> or <xref keyref="updateChannelMediaOptions"/>.</li>
            </ul>
        </section>
        <section id="restriction" deliveryTarget="details">
            <title>Restrictions</title>
            <ul>
                <li>Local video mixing requires more CPU resources. Therefore, Agora recommends enabling this function on devices with higher performance.</li>
                <li>If you need to mix locally captured video streams, the SDK supports the following capture combinations:<ul>
                    <li props="cpp unreal bp electron unity cs flutter">On the Windows platform, it supports up to 4 video streams captured by cameras + 4 screen sharing streams.</li>
                    <li props="cpp unreal bp mac unity electron flutter">On the macOS platform, it supports up to 4 video streams captured by cameras + 1 screen sharing stream.</li>
                    <li props="cpp unreal bp unity rn flutter">On Android and iOS platforms, it supports video streams captured by up to 2 cameras (the device itself needs to support dual cameras or supports external cameras) + 1 screen sharing stream.</li>
                    <li props="android">On the Android platform, it supports up to 2 video streams captured by cameras (the device itself needs to support dual cameras or support external cameras) + 1 screen sharing stream.</li>
                    <li props="ios">On the iOS platform, it supports up to 2 video streams captured by cameras (the device itself needs to support dual cameras or support external cameras) + 1 screen sharing stream.</li></ul></li>
                    <li>When configuring the local video mixing, it is necessary to ensure that the layer number of the video stream capturing the portrait is greater than the layer number of the screen sharing stream. Otherwise, the portrait will be covered by the screen sharing and will not be displayed in the final mixed video stream.</li>
            </ul>
        </section>
        <section id="related" deliveryTarget="details">
            <title>Related callbacks</title>
            <p>When you fail to call this method, the SDK triggers the <xref keyref="onLocalVideoTranscoderError"/> callback to report the reason.</p>
        </section>
        <section id="parameters" deliveryTarget="details">
            <title>Parameters</title>
            <parml>
            <plentry>
                <pt>config</pt>
                <pd>Configuration of the local video mixing, see <xref keyref="LocalTranscoderConfiguration" />.<note type="attention"><ul>
                <li>The maximum resolution of each video stream participating in the local video mixing is 4096 × 2160. If this limit is exceeded, video mixing does not take effect.</li>
                <li>The maximum resolution of the mixed video stream is 4096 × 2160.</li></ul></note></pd>
            </plentry>
            </parml> </section>
        <section id="return_values">
            <title><ph keyref="return-section-title"/></title>
            <p props="flutter">When the method call succeeds, there is no return value; when fails, the <xref keyref="AgoraRtcException"/> exception is thrown. You need to catch the exception and handle it accordingly. <ph props="cn">See <xref keyref="error-code-link"/> for details and resolution suggestions.</ph></p>
            <ul props="native unreal bp electron unity cs rn">
            <li>0: Success.</li>
            <li>&lt; 0: Failure. <ph props="cn">See <xref keyref="error-code-link"/> for details and resolution suggestions.</ph></li>
            </ul> </section>
    </refbody>
</reference>
