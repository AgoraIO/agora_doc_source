<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="callback_ivideoframeobserver_onpreencodescreenvideoframe">
    <title><ph keyref="onPreEncodeScreenVideoFrame" /></title>
    <shortdesc id="short"><ph id="shortdesc">Gets the video data captured from the screen before encoding.</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="onPreEncodeScreenVideoFrame" />
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
                <codeblock props="android" outputclass="language-java">boolean onPreEncodeScreenVideoFrame(VideoFrame videoFrame);</codeblock>
                <codeblock props="ios mac">- (BOOL)onPreEncodeScreenVideoFrame:(AgoraOutputVideoFrame * _Nonnull)videoFrame;</codeblock>
                <codeblock props="cpp" outputclass="language-cpp">virtual bool onPreEncodeScreenVideoFrame(VideoFrame&amp; videoFrame) = 0;</codeblock>
                <codeblock props="unity" outputclass="language-csharp" />
                <codeblock props="electron" outputclass="language-typescript">  onPreEncodeScreenVideoFrame?(videoFrame: VideoFrame): boolean;</codeblock>
                <codeblock props="unity" outputclass="language-csharp" />
                <codeblock props="rn" outputclass="language-typescript">  onPreEncodeScreenVideoFrame?(videoFrame: VideoFrame): boolean;</codeblock>
                <codeblock props="flutter" outputclass="language-dart">final void Function(VideoFrame videoFrame)? onPreEncodeScreenVideoFrame;</codeblock>
            </p>
        </section>
        <section id="detailed_desc">
            <p>After you successfully register the video frame observer, the SDK triggers this callback each time it receives a video frame. In this callback, you can get the video data captured from the screen before encoding and then process the data according to your particular scenarios.</p>
            <p props="native unity electron">After processing, you can send the processed video data back to the SDK in this callback.</p>
            <note type="attention" props="native unity electron rn">
                <ul>
                    <li props="native unity">To get the video data captured from the second screen before encoding, you need to set <apiname keyref="POSITION_PRE_ENCODER" /> (1 &lt;&lt; 2) as a frame position through <xref keyref="getObservedFramePosition" />.</li>
                    <li>The video data that this callback gets has been preprocessed, with its content cropped and rotated, and the image enhanced.</li>
                    <li>This callback does not support sending processed RGBA video data back to the SDK.</li>
                </ul>
            </note>
            <note type="attention" props="flutter">Due to the limitations of Flutter, this callback does not support sending processed video data back to the SDK.</note>
        </section>
        <section id="parameters">
            <title>Parameters</title>
            <parml>
                <plentry conkeyref="onCaptureVideoFrame/videoframe">
                    <pt />
                    <pd />
                </plentry>
            </parml>
        </section>
        <section id="return_values">
            <title><ph keyref="return-section-title"/></title>
            <p props="flutter">When the method call succeeds, there is no return value; when fails, the <xref keyref="AgoraRtcException"/> exception is thrown; you need to catch the exception and handle it accordingly.</p>
            <p conkeyref="onCaptureVideoFrame/return" props="native electron unity rn"/>
        </section>
    </refbody>
</reference>