<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="api_irtcengine_setrecordingaudioframeparameters">
    <title><ph keyref="setRecordingAudioFrameParameters"/></title>
    <shortdesc id="short"><ph id="shortdesc" props="cpp">Sets the format of the captured raw audio data.</ph><ph id="shortdesc" props="android">Sets the format of the captured raw audio data.</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="setRecordingAudioFrameParameters"/>
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
                <codeblock props="cpp" outputclass="language-cpp">virtual int setRecordingAudioFrameParameters(int sampleRate, int channel, RAW_AUDIO_FRAME_OP_MODE_TYPE mode, int samplesPerCall) = 0;</codeblock>
                <codeblock props="android" outputclass="language-java">public abstract int setRecordingAudioFrameParameters(int sampleRate, int channel, int mode, int samplesPerCall);</codeblock>
            </p>
        </section>
        <section id="detailed_desc" deliveryTarget="details" otherprops="no-title">
            <p props="cpp"><xref keyref="setRecordingAudioFrameParameters"/> calculates the sampling interval based on <codeph>samplesPerCall</codeph>, <codeph>sampleRate</codeph>, and <codeph>channel</codeph>. Sampling interval (in seconds) = <codeph>samplesPerCall</codeph> / (<codeph>sampleRate</codeph> × <codeph>channel</codeph>). Make sure the interval is ≥ 0.01 seconds. The SDK triggers the <xref keyref="onRecordAudioFrame_IAudioFrameObserverBase"/> callback based on this interval.</p>
            <p props="android">The SDK calculates the sampling interval based on the <codeph>samplesPerCall</codeph>, <codeph>sampleRate</codeph>, and <codeph>channel</codeph> parameters. Sampling interval (in seconds) = <codeph>samplesPerCall</codeph> / (<codeph>sampleRate</codeph> × <codeph>channel</codeph>). Ensure the sampling interval is ≥ 0.01 seconds. The SDK triggers the <xref keyref="onRecordAudioFrame"/> callback based on the sampling interval.</p>
        </section>
        <section id="timing" deliveryTarget="details" props="android cpp">
            <title>Timing</title>
            <p props="cpp">Call this method before joining a channel.</p>
            <p props="android">Call this method before joining a channel.</p>
        </section>
        <section id="parameters" deliveryTarget="details" props="android cpp">
            <title>Parameters</title>
            <parml>
                <plentry props="cpp">
                    <pt>sampleRate</pt>
                    <pd>The sampling rate returned in the callback. Can be set to 8000, 16000, 32000, 44100, or 48000 (Hz).</pd>
                </plentry>
                <plentry props="cpp">
                    <pt>channel</pt>
                    <pd>Number of audio channels. Can be set to:
                        <ul>
                            <li>1: Mono.</li>
                            <li>2: Stereo.</li>
                        </ul>
                    </pd>
                </plentry>
                <plentry props="cpp">
                    <pt>mode</pt>
                    <pd>The usage mode of the audio frame. See <xref keyref="RAW_AUDIO_FRAME_OP_MODE_TYPE"/>.</pd>
                </plentry>
                <plentry props="cpp">
                    <pt>samplesPerCall</pt>
                    <pd>The number of samples per callback, e.g., 1024 for media streaming.</pd>
                </plentry>
                <plentry props="android">
                    <pt>sampleRate</pt>
                    <pd>The sampling rate returned in the callback. Can be set to 8000, 16000, 32000, 44100, or 48000 Hz.</pd>
                </plentry>
                <plentry props="android">
                    <pt>channel</pt>
                    <pd>Number of audio channels:
                        <ul>
                            <li>1: Mono.</li>
                            <li>2: Stereo.</li>
                        </ul>
                    </pd>
                </plentry>
                <plentry props="android">
                    <pt>mode</pt>
                    <pd>Usage mode of the audio frame:
                        <ul>
                            <li>0: Read-only mode. For example, the user retrieves data via the Agora SDK and pushes RTMP or RTMPS streams.</li>
                            <li>2: Read-write mode. The user reads data from <xref keyref="AudioFrame"/>, modifies it, and plays it back. For example, the user has a custom audio effects module and performs voice preprocessing such as voice changing.</li>
                        </ul>
                    </pd>
                </plentry>
                <plentry props="android">
                    <pt>samplesPerCall</pt>
                    <pd>Number of samples per call, e.g., 1024 for media streaming.</pd>
                </plentry>
            </parml>
        </section>
        <section id="return_values" props="android cpp">
            <title>Return Values</title>
            <p props="cpp">
                <ul>
                    <li>0: Success.</li>
                    <li>&lt; 0: Failure.</li>
                </ul>
            </p>
            <p props="android">
                <ul>
                    <li>0: Success.</li>
                    <li>&lt; 0: Failure.</li>
                </ul>
            </p>
        </section>
    </refbody>
</reference>