<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="api_iaudioframeobserver_getobservedaudioframeposition">
    <title><ph keyref="getObservedAudioFramePosition"/></title>
    <shortdesc id="short"><ph id="shortdesc" props="android">Sets the audio data observation position.</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="getObservedAudioFramePosition"/>
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
                <codeblock props="android" outputclass="language-java">@CalledByNative public abstract int getObservedAudioFramePosition();</codeblock>
            </p>
        </section>
        <section id="detailed_desc" deliveryTarget="details" otherprops="no-title">
            <p props="android">After successfully registering the audio frame observer, the SDK calls this callback at each specific audio frame processing node to determine whether to trigger the following callbacks:
                <ul>
                    <li><xref keyref="onRecordAudioFrame"/></li>
                    <li><xref keyref="onPlaybackAudioFrame"/></li>
                    <li><xref keyref="onPlaybackAudioFrameBeforeMixing"/></li>
                    <li><xref keyref="onMixedAudioFrame"/></li>
                    <li><xref keyref="onEarMonitoringAudioFrame"/></li>
                </ul><ph>You can set one or more positions to observe by modifying the return value of <xref keyref="getObservedAudioFramePosition"/> according to your scenario needs.</ph><ph>To observe multiple positions, use the | (bitwise OR) operator. To conserve system resources, it is recommended to minimize the number of observed frame positions.</ph></p>
        </section>
        <section id="return_values" props="android">
            <title>Return Values</title>
            <p props="android">Returns a bitmask to set observation positions. The possible values are:
                <ul>
                    <li><codeph>POSITION_PLAYBACK</codeph> (0x0001): Observes the playback audio after mixing from all remote users, corresponding to the <xref keyref="onPlaybackAudioFrame"/> callback.</li>
                    <li><codeph>POSITION_RECORD</codeph> (0x0002): Observes the audio captured by the local user, corresponding to the <xref keyref="onRecordAudioFrame"/> callback.</li>
                    <li><codeph>POSITION_MIXED</codeph> (0x0004): Observes the playback audio after mixing the local user and all remote users, corresponding to the <xref keyref="onMixedAudioFrame"/> callback.</li>
                    <li><codeph>POSITION_BEFORE_MIXING</codeph> (0x0008): Observes the audio of a single remote user before mixing, corresponding to the <xref keyref="onPlaybackAudioFrameBeforeMixing"/> callback.</li>
                    <li><codeph>POSITION_EAR_MONITORING</codeph> (0x0010): Observes the local user's in-ear monitoring audio, corresponding to the <xref keyref="onEarMonitoringAudioFrame"/> callback.</li>
                </ul>
            </p>
        </section>
    </refbody>
</reference>