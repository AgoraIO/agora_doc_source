<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="callback_iaudioframeobserver_onearmonitoringaudioframe">
    <title><ph keyref="onEarMonitoringAudioFrame"/></title>
    <shortdesc id="short"><ph id="shortdesc" props="android">Callback for ear monitoring audio frames.</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="onEarMonitoringAudioFrame"/>
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
                <codeblock props="android" outputclass="language-java">public abstract boolean onEarMonitoringAudioFrame(int type, int samplesPerChannel, int bytesPerSample, int channels, int samplesPerSec, ByteBuffer buffer, long renderTimeMs, int avsync_type);</codeblock>
            </p>
        </section>
        <section id="detailed_desc" deliveryTarget="details" otherprops="no-title">
            <p props="android">This callback is used to retrieve ear monitoring audio data. To ensure the retrieved data meets expectations, Agora recommends setting the audio data format using one of the following methods:
                <ul>
                    <li>Method 1: Call <xref keyref="setEarMonitoringAudioFrameParameters"/> to set the audio data format, then call <xref keyref="registerAudioFrameObserver"/> to register the audio frame observer. The SDK will calculate the sampling interval based on the set parameters and trigger the <xref keyref="onEarMonitoringAudioFrame"/> callback accordingly.</li>
                    <li>Method 2: After calling <xref keyref="registerAudioFrameObserver"/> to register the audio frame observer, set the audio data format in the return value of <xref keyref="getObservedAudioFramePosition"/>. The SDK will then calculate the sampling interval based on the return value of <xref keyref="getEarMonitoringAudioParams"/> and trigger the <xref keyref="onEarMonitoringAudioFrame"/> callback accordingly.</li>
                </ul>
            </p>
            <note props="android">Method 1 takes precedence over Method 2. If you use Method 1 to set the audio data format, the settings in Method 2 will be ignored.</note>
        </section>
        <section id="parameters" deliveryTarget="details" props="android">
            <title>Parameters</title>
            <parml>
                <plentry props="android">
                    <pt>type</pt>
                    <pd>Audio frame type.</pd>
                </plentry>
                <plentry props="android">
                    <pt>samplesPerChannel</pt>
                    <pd>Number of samples per channel.</pd>
                </plentry>
                <plentry props="android">
                    <pt>bytesPerSample</pt>
                    <pd>Number of bytes per audio sample. For example, each PCM audio sample typically occupies 16 bits (2 bytes).</pd>
                </plentry>
                <plentry props="android">
                    <pt>channels</pt>
                    <pd>Number of channels:
                        <ul>
                            <li>1: Mono.</li>
                            <li>2: Stereo. If stereo, the data is in interleaved format.</li>
                        </ul>
                    </pd>
                </plentry>
                <plentry props="android">
                    <pt>samplesPerSec</pt>
                    <pd>Recording sample rate (Hz).</pd>
                </plentry>
                <plentry props="android">
                    <pt>buffer</pt>
                    <pd>Audio buffer. Buffer size = <codeph>samplesPerChannel</codeph> × <codeph>channels</codeph> × <codeph>bytesPerSample</codeph>. See <codeph>ByteBuffer</codeph>.</pd>
                </plentry>
                <plentry props="android">
                    <pt>renderTimeMs</pt>
                    <pd>Timestamp of the external audio frame (milliseconds). You can use this parameter to synchronize audio and video frames in scenarios such as using custom video sources.</pd>
                </plentry>
                <plentry props="android">
                    <pt>avsync_type</pt>
                    <pd>Reserved parameter.</pd>
                </plentry>
            </parml>
        </section>
        <section id="return_values" props="android">
            <title>Return Values</title>
            <p props="android">
                <ul>
                    <li><xref keyref="true"/>: Callback handled successfully.</li>
                    <li><xref keyref="false"/>: Callback handling failed.</li>
                </ul>
            </p>
        </section>
    </refbody>
</reference>