<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="api_irtcengine_setaudioprofile">
    <title><ph keyref="setAudioProfile"/></title>
    <shortdesc id="short"><ph id="shortdesc" props="electron">Sets the audio encoding profile and audio scenario.</ph><ph id="shortdesc" props="rn">Sets the audio encoding profile and scenario.</ph><ph id="shortdesc" props="flutter">Sets the audio encoding profile and audio scenario.</ph><ph id="shortdesc" props="unity">Sets the audio encoding profile and scenario.</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="setAudioProfile"/>
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
                <codeblock props="electron" outputclass="language-typescript">abstract setAudioProfile(
    profile: AudioProfileType,
    scenario?: AudioScenarioType
  ): number;</codeblock>
                <codeblock props="rn" outputclass="language-typescript">abstract setAudioProfile(
    profile: AudioProfileType,
    scenario?: AudioScenarioType
  ): number;</codeblock>
                <codeblock props="flutter" outputclass="language-dart">Future&lt;void&gt; setAudioProfile(
    {required AudioProfileType profile,
    AudioScenarioType scenario = AudioScenarioType.audioScenarioDefault});</codeblock>
                <codeblock props="unity" outputclass="language-csharp">public abstract int SetAudioProfile(AUDIO_PROFILE_TYPE profile, AUDIO_SCENARIO_TYPE scenario);</codeblock>
            </p>
        </section>
        <section id="detailed_desc" deliveryTarget="details" otherprops="no-title">
            <dl outputclass="deprecated">
                <dlentry props="unity">
                    <dt>Deprecated</dt>
                    <dd>Deprecated: This method is deprecated. To set the audio encoding profile, use <xref keyref="setAudioProfile2"/>; to set the audio scenario, use <xref keyref="setAudioScenario"/>.</dd>
                </dlentry>
            </dl>
            <note props="rn">Due to iOS system limitations, some audio routes cannot be recognized in the communication volume mode. Therefore, if you need to use an external sound card, we recommend setting the audio scenario to the high-quality scenario <codeph>AudioScenarioGameStreaming</codeph>(3). In this scenario, the SDK switches to media volume to avoid the issue.</note>
            <note props="flutter">Due to iOS system limitations, some audio routes cannot be recognized in communication volume mode. Therefore, if you need to use an external sound card, it is recommended to set the audio scenario to the high-quality scenario <codeph>audioScenarioGameStreaming</codeph>(3). In this scenario, the SDK switches to media volume to avoid the issue.</note>
            <note props="unity">Due to iOS system limitations, some audio routes cannot be recognized in the call volume mode. Therefore, if you want to use an external sound card, it is recommended to set the audio scenario to the high-quality scenario <codeph>AUDIO_SCENARIO_GAME_STREAMING</codeph>(3). In this scenario, the SDK switches to media volume to avoid the issue.</note>
        </section>
        <section id="scenario" deliveryTarget="details">
            <title>Scenario</title>
            <p>This method applies to various audio scenarios. You can choose as needed. For example, in scenarios that require high audio quality such as music education, it is recommended to set <codeph>profile</codeph> to <codeph>AudioProfileMusicHighQuality</codeph> (4) and <codeph>scenario</codeph> to <codeph>AudioScenarioGameStreaming</codeph> (3).</p>
        </section>
        <section id="timing" deliveryTarget="details" props="electron flutter rn unity">
            <title>Timing</title>
            <p props="electron">You can call this method before or after joining a channel.</p>
            <p props="rn">You can call this method before or after joining a channel.</p>
            <p props="flutter">This method can be called before or after joining a channel.</p>
            <p props="unity">You can call this method before or after joining a channel.</p>
        </section>
        <section id="parameters" deliveryTarget="details" props="electron flutter rn unity">
            <title>Parameters</title>
            <parml>
                <plentry props="electron">
                    <pt>profile</pt>
                    <pd>The audio encoding profile, including sample rate, bitrate, encoding mode, and the number of channels. See <xref keyref="AUDIO_PROFILE_TYPE"/>.</pd>
                </plentry>
                <plentry props="electron">
                    <pt>scenario</pt>
                    <pd>The audio scenario. The volume type of the device varies depending on the audio scenario.
See <xref keyref="AUDIO_SCENARIO_TYPE"/>.</pd>
                </plentry>
                <plentry props="rn">
                    <pt>profile</pt>
                    <pd>The audio encoding profile, including sample rate, bitrate, encoding mode, and the number of channels. See <xref keyref="AUDIO_PROFILE_TYPE"/>.</pd>
                </plentry>
                <plentry props="rn">
                    <pt>scenario</pt>
                    <pd>The audio scenario. The volume type of the device varies depending on the audio scenario.
See <xref keyref="AUDIO_SCENARIO_TYPE"/>.</pd>
                </plentry>
                <plentry props="flutter">
                    <pt>profile</pt>
                    <pd>Audio encoding profile, including sample rate, bitrate, encoding mode, and number of channels. See <xref keyref="AUDIO_PROFILE_TYPE"/>.</pd>
                </plentry>
                <plentry props="flutter">
                    <pt>scenario</pt>
                    <pd>Audio scenario. The device volume type varies under different audio scenarios.
See <xref keyref="AUDIO_SCENARIO_TYPE"/>.</pd>
                </plentry>
                <plentry props="unity">
                    <pt>profile</pt>
                    <pd>The audio encoding profile, including sample rate, bitrate, encoding mode, and number of channels. See <xref keyref="AUDIO_PROFILE_TYPE"/>.</pd>
                </plentry>
                <plentry props="unity">
                    <pt>scenario</pt>
                    <pd>The audio scenario. The volume type of the device varies by scenario.
See <xref keyref="AUDIO_SCENARIO_TYPE"/>.</pd>
                </plentry>
            </parml>
        </section>
        <section id="return_values" props="electron flutter rn unity">
            <title>Return Values</title>
            <p props="electron">
                <ul>
                    <li>0: Success.</li>
                    <li>&lt; 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.</li>
                </ul>
            </p>
            <p props="rn">
                <ul>
                    <li>0: Success.</li>
                    <li>&lt; 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.</li>
                </ul>
            </p>
            <p props="flutter">When the method call succeeds, there is no return value; when fails, the <xref keyref="AgoraRtcException"/> exception is thrown. You need to catch the exception and handle it accordingly. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.</p>
            <p props="unity">
                <ul>
                    <li>0: Success.</li>
                    <li>&lt; 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.</li>
                </ul>
            </p>
        </section>
    </refbody>
</reference>