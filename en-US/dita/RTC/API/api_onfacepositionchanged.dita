<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="api_onfacepositionchanged">
    <title><ph keyref="onFacePositionChanged"/></title>
    <shortdesc id="short"><ph id="shortdesc">Reports the face detection result of the local user.</ph></shortdesc>
    <prolog>
        <metadata>
   <keywords>
       <indexterm keyref="onFacePositionChanged" />
   </keywords>
        </metadata>
    </prolog>
    <refbody><section id="prototype">
        <p outputclass="codeblock">
                <codeblock props="android" outputclass="language-java">public void onFacePositionChanged( int imageWidth, int imageHeight, AgoraFacePositionInfo[] faceRectArr) {}</codeblock>
                <codeblock props="ios mac" outputclass="language-objectivec"/>
                <codeblock props="windows" outputclass="language-cpp">virtual void onFacePositionChanged(int imageWidth, int imageHeight, Rectangle* vecRectangle, int* vecDistance, int numFaces){ (void)imageWidth; (void)imageHeight; (void)vecRectangle; (void)vecDistance; (void)numFaces; }</codeblock>
                <codeblock props="electron" outputclass="language-typescript"/>
                <codeblock props="unity" outputclass="language-csharp"/>
                <codeblock props="rn" outputclass="language-typescript"/>
                <codeblock props="flutter" outputclass="language-dart"/>
        </p>
        </section>
        <section id="detailed_desc">
   
   <dl outputclass="since">
       <dlentry>
  <dt>Since</dt>
  <dd>v3.0.1</dd>
       </dlentry>
   </dl>
   <p>Once you enable face detection by calling <xref keyref="enableFaceDetection"/>(<ph keyref="true"/>), you can get the following information on the local user in real-time:<ul>
  <li>The width and height of the local video.</li>
  <li>The position of the human face in the local video.</li>
  <li>The distance between the human face and the screen.</li>
       </ul>
   </p>
   <p>The distance between the human face and the screen is based on the fitting calculation of the local video size and the position of the human face captured by the camera.</p>
   <note type="attention">
       <ul>
           <li>This callback is for Android and iOS only.</li>
  <li>If the SDK does not detect a face, it reduces the frequency of this callback to reduce power consumption on the local device.</li>
  <li>The SDK stops triggering this callback when a human face is in close proximity to the screen.</li>
  <li>On Android, the value of <parmname>distance</parmname> reported in this callback may be slightly different from the actual distance. Therefore, Agora does not recommend using it for accurate calculation.</li>
       </ul>
   </note>
        </section>
        <section id="parameters"><title>Parameter</title>
   <parml>
       <plentry conkeyref="onJoinChannelSuccess/engine" props="ios mac">
                  <pt/>
                  <pd/>
              </plentry>
       <plentry>
  <pt>imageWidth</pt>
  <pd>The width (px) of the video image captured by the local camera.</pd>
       </plentry>
       <plentry>
  <pt>imageHeight</pt>
  <pd>The height (px) of the video image captured by the local camera.</pd>
       </plentry>
       <plentry>
  <pt>vecRectangle</pt>
  <pd>
      <p>The position and size of the human face on the local video:<ul>
     <li><codeph>x</codeph>: The x coordinate (px) of the human face in the local video. Taking the top left corner of the captured video as the origin, the x coordinate represents the relative lateral displacement of the top left corner of the human face to the origin.</li>
     <li><codeph>y</codeph>: The y coordinate (px) of the human face in the local video. Taking the top left corner of the captured video as the origin, the y coordinate represents the relative longitudinal displacement of the top left corner of the human face to the origin.</li>
     <li><codeph>width</codeph>: The<codeph> width</codeph> (px) of the human face in the captured video.</li>
     <li><codeph>height</codeph>: The<codeph> height</codeph> (px) of the human face in the captured video.</li>
 </ul>
      </p>
  </pd>
       </plentry>
       <plentry>
  <pt>vecDistance</pt>
  <pd>The distance between the human face and the device screen (cm).</pd>
       </plentry>
       <plentry>
  <pt>numFaces</pt>
  <pd>The number of faces detected. If the value is 0, it means that no human face is detected.</pd>
       </plentry>
   </parml>
        </section>
    </refbody>
</reference>
