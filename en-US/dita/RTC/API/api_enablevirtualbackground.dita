<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="api_enablevirtualbackground">
    <title><ph keyref="enableVirtualBackground"/></title>
    <shortdesc id="short"><ph id="shortdesc">Enables/Disables the virtual background. (beta feature)</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="enableVirtualBackground"/>
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
                <codeblock props="android" outputclass="language-java"/>
                <codeblock props="ios mac" outputclass="language-objectivec"/>
                <codeblock props="windows" outputclass="language-cpp"/>
                <codeblock props="electron" outputclass="language-typescript"/>
                <codeblock props="unity" outputclass="language-csharp">public abstract int EnableVirtualBackground(bool enabled, VirtualBackgroundSource backgroundSource);</codeblock>
                <codeblock props="rn" outputclass="language-typescript"/>
                <codeblock props="flutter" outputclass="language-dart"/>
            </p>
        </section>
        <section id="detailed_desc">
            <dl outputclass="since">
                <dlentry>
                    <dt>Since</dt>
                    <dd>v3.5.0</dd>
                </dlentry>
            </dl>
            <p>After enabling the virtual background feature, you can replace the original background image of the local user with a custom background image. After the replacement, all users in the channel can see the custom background image. You can find out from the <xref keyref="onVirtualBackgroundSourceEnabled"/> callback
            whether virtual background is successfully enabled and the cause of any errors.</p>
            <note type="note"><ul>
                <li>Before calling this method, ensure that you have integrated the dynamic library.<ul>
                    <li props="android windows unity rn flutter">Android: <ph>libagora_segmentation_extension.so</ph></li>
                    <li props="ios windows unity rn flutter">iOS: <ph>AgoraVideoSegmentationExtension.xcframework</ph></li>
                    <li props="mac windows unity electron">macOS: <ph>AgoraVideoSegmentationExtension.framework</ph></li>
                    <li props="windows">Windows: <ph>libagora_segmentation_extension.dll</ph></li>
                </ul></li>
                <li>Call this method after  <xref keyref="enableVideo"/>.</li>
                <li>This function requires a high-performance device. Agora recommends that you use this function on devices with the following chips:<ul>
                    <li props="android unity windows rn flutter">Snapdragon 700 series 750G and later</li>
                    <li props="android unity windows rn flutter">Snapdragon 800 series 835 and later</li>
                    <li props="android unity windows rn flutter">Dimensity 700 series 720 and later</li>
                    <li props="android unity windows rn flutter">Kirin 800 series 810 and later</li>
                    <li props="android unity windows rn flutter">Kirin 900 series 980 and later</li>
                    <li props="mac windows unity electron">Devices with an i5 CPU and better</li>
                    <li props="ios windows unity rn flutter">Devices with an A9 chip and better, as follows:<ul>
                        <li>iPhone 6S and later</li>
                        <li>iPad Air 3rd generation and later</li>
                        <li>iPad 5th generation and later</li>
                        <li>iPad Pro 2nd generation and later</li>
                        <li>iPad mini 5th generation and later</li>
                    </ul></li>
                    <li>Agora recommends using one of the following solutions to solve this problem:Agora recommends that you use this function in scenarios that meet the following conditions:<ul>
                        <li>A high-definition camera device is used and the environment is uniformly lit.</li>
                        <li>There are few objects in the captured video. Portraits are half-length and unobstructed. Ensure that the background is a solid color that distinguishes from the color of the user&apos;s clothing.</li>
                    </ul></li>
                </ul></li>
                <li>The virtual background feature does not support video in the texture format or video obtained from custom video capture by the Push method.</li>
            </ul></note>
        </section>
        <section id="parameters"><title>Parameter</title>
            <parml>
                <plentry>
                    <pt>enabled</pt>
                    <pd>Whether to enable virtual background:<ul>
                        <li><ph keyref="true"/>: Enable virtual background.</li>
                        <li><ph keyref="false"/>: Do not enable virtual background.</li>
                    </ul></pd>
                </plentry>
                <plentry>
                    <pt>backgroundSource</pt>
                    <pd>The custom background image. See <xref keyref="VirtualBackgroundSource"/>.<note type="note">To adapt the resolution of the custom background image to that of the video captured by the SDK, the SDK scales and crops the custom background image while ensuring that the content of the custom background image is not distorted.</note></pd>
                </plentry>
            </parml>
        </section>
        <section id="return_values">
            <title>Returns</title>
            <ul>
                <li>0: Success.</li>
                <li>&lt; 0: Failure.</li>
            </ul>
        </section>
    </refbody>
</reference>
