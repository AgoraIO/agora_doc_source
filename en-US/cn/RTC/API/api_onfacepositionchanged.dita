<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="api_onfacepositionchanged">
    <title><ph keyref="onFacePositionChanged"/></title>
    <shortdesc id="short"><ph id="shortdesc">Reports the face detection result of the local user.</ph></shortdesc>
    <prolog>
        <metadata>
   <keywords>
       <indexterm keyref="onFacePositionChanged" />
   </keywords>
        </metadata>
    </prolog>
    <refbody><section id="prototype">
        
        <p conref="../conref/conref_rtc_api.dita#apidef/onFacePositionChanged"/>
        </section>
        <section id="detailed_desc">
   
   <dl outputclass="since">
       <dlentry>
  <dt>Since</dt>
  <dd>v3.0.1</dd>
       </dlentry>
   </dl>
   <p>After calling <xref keyref="enableFaceDetection"/>(<ph keyref="true"/>) to enable local face detection, you can use this callback to obtain the following face detection information in real time:<ul>
  <li>The width and height of the local video.</li>
  <li>The position of the human face in the local video.</li>
  <li>The distance between the human face and the screen.</li>
       </ul>
   </p>
   <p>This value is based on the fitting calculation of the local video size and the position of the human face.</p>
   <note outputclass="note">
       <ul>
           <li>This method is for Android and iOS only.</li>
  <li>If the SDK does not detect a face, it reduces the frequency of this callback to reduce power consumption on the local device.</li>
  <li>The SDK stops triggering this callback when a human face is in close proximity to the screen.</li>
  <li>On Android, the `<parmname>distance</parmname>` value reported in this callback may be slightly different from the actual <parmname>distance</parmname>. Therefore, Agora does not recommend using it for accurate calculation.</li>
       </ul>
   </note>
        </section>
        <section id="parameters"><title>Parameter</title>
   <parml>
       <plentry>
  <pt>imageWidth</pt>
  <pd>The width (px) of the video image captured by the local camera.</pd>
       </plentry>
       <plentry>
  <pt>imageHeight</pt>
  <pd>The height (px) of the video image captured by the local camera.</pd>
       </plentry>
       <plentry>
  <pt>vecRectangle</pt>
  <pd>
      <p>Face information detected:<ul>
     <li>`<codeph>x</codeph>`: The x coordinate (px) of the human face in the local video. Taking the top left corner of the captured video as the origin, the x coordinate represents the relative lateral displacement of the top left corner of the human face to the origin.</li>
     <li>`<codeph>y</codeph>`: The y coordinate (px) of the human face in the local video. Taking the top left corner of the captured video as the origin, the y coordinate represents the relative longitudinal displacement of the top left corner of the human face to the origin.</li>
     <li>`<codeph>width</codeph>`: The<codeph> width</codeph> (px) of the human face in the captured video.</li>
     <li>`<codeph>height</codeph>`: The<codeph> height</codeph> (px) of the human face in the captured video.</li>
 </ul>
      </p>
  </pd>
       </plentry>
       <plentry>
  <pt>vecDistance</pt>
  <pd>The distance between the human face and the device screen.</pd>
       </plentry>
       <plentry>
  <pt>numFaces</pt>
  <pd>The number of detected faces. If the value is 0, it means that no human face is detected.</pd>
       </plentry>
   </parml>
        </section>
    </refbody>
</reference>
