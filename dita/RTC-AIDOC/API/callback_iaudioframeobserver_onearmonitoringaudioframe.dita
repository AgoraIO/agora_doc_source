<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="callback_iaudioframeobserver_onearmonitoringaudioframe">
    <title><ph keyref="onEarMonitoringAudioFrame"/></title>
    <shortdesc id="short"><ph id="shortdesc">耳返音频帧回调。</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="onEarMonitoringAudioFrame"/>
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
                <codeblock props="ios" outputclass="language-objectivec">- (BOOL)onEarMonitoringAudioFrame:(AgoraAudioFrame* _Nonnull)frame NS_SWIFT_NAME(onEarMonitoringAudioFrame(_:));</codeblock>
                <codeblock props="android" outputclass="language-java">public abstract boolean onEarMonitoringAudioFrame(int type, int samplesPerChannel, int bytesPerSample, int channels, int samplesPerSec, ByteBuffer buffer, long renderTimeMs, int avsync_type);</codeblock>
                <codeblock props="mac" outputclass="language-objectivec">- (BOOL)onEarMonitoringAudioFrame:(AgoraAudioFrame* _Nonnull)frame NS_SWIFT_NAME(onEarMonitoringAudioFrame(_:));</codeblock>
            </p>
        </section>
        <section id="detailed_desc" deliveryTarget="details" otherprops="no-title" props="android ios mac">
            <p props="ios">为了确保你获取的耳返音频数据符合预期，声网建议你通过以下两种方式之一设置耳返音频数据格式：
                <ul>
                    <li>方法一：调用 <xref keyref="setEarMonitoringAudioFrameParameters"/> 设置音频数据格式，并调用 <xref keyref="registerAudioFrameObserver"/> 注册音频帧观察者对象。SDK 会根据设置的参数计算采样间隔，并按照采样间隔触发该回调。</li>
                    <li>方法二：调用 <xref keyref="registerAudioFrameObserver"/> 注册音频帧观察者对象，并在 <xref keyref="getObservedAudioFramePosition"/> 回调的返回值中设置音频数据格式。SDK 会根据 <xref keyref="getEarMonitoringAudioParams"/> 回调的返回值计算采样间隔，并按照采样间隔触发该回调。</li>
                </ul>
            </p>
            <p props="android">该回调用于获取耳返音频数据。为了确保获取的数据符合预期，声网建议你通过以下任一方式设置音频数据格式：
                <ul>
                    <li>方法一：调用 <xref keyref="setEarMonitoringAudioFrameParameters"/> 设置音频数据格式，并调用 <xref keyref="registerAudioFrameObserver2_IMediaPlayer"/> 注册音频帧观察者对象后，SDK 会根据设置的参数计算采样间隔，并按该间隔触发 <xref keyref="onEarMonitoringAudioFrame"/> 回调。</li>
                    <li>方法二：调用 <xref keyref="registerAudioFrameObserver2_IMediaPlayer"/> 注册音频帧观察者对象后，在 <xref keyref="getObservedAudioFramePosition"/> 的返回值中设置音频数据格式。然后 SDK 会根据 <xref keyref="getEarMonitoringAudioParams"/> 的返回值计算采样间隔，并按该间隔触发 <xref keyref="onEarMonitoringAudioFrame"/> 回调。</li>
                </ul>
            </p>
            <p props="mac">为了确保你获取的耳返音频数据符合预期，声网建议你通过以下两种方式之一设置耳返音频数据格式：
                <ul>
                    <li>方法一：调用 <xref keyref="setEarMonitoringAudioFrameParameters"/> 设置音频数据格式，并调用 <xref keyref="registerAudioFrameObserver"/> 注册音频帧观察者对象。SDK 会根据设置的参数计算采样间隔，并按照采样间隔触发该回调。</li>
                    <li>方法二：调用 <xref keyref="registerAudioFrameObserver"/> 注册音频帧观察者对象，并在 <xref keyref="getObservedAudioFramePosition"/> 回调的返回值中设置音频数据格式。SDK 会根据 <xref keyref="getEarMonitoringAudioParams"/> 回调的返回值计算采样间隔，并按照采样间隔触发该回调。</li>
                </ul>
            </p>
            <note props="ios">
                <ul>
                    <li>方法一的优先级高于方法二。如果使用方法一设置音频数据格式，则方法二的设置无效。</li>
                </ul>
            </note>
            <note props="android">方法一的优先级高于方法二。如果使用方法一设置音频数据格式，则方法二的设置无效。</note>
            <note props="mac">
                <ul>
                    <li>方法一的优先级高于方法二。如果使用方法一设置音频数据格式，则方法二的设置无效。</li>
                </ul>
            </note>
        </section>
        <section id="timing" deliveryTarget="details" props="ios mac">
            <title>触发时机</title>
            <p props="ios">该回调在采样间隔到达时被触发。</p>
            <p props="mac">该回调在采样间隔到达时被触发。</p>
        </section>
        <section id="restriction" deliveryTarget="details" props="android ios mac">
            <title>使用限制</title>
            <p props="ios">无。</p>
            <p props="android">无。</p>
            <p props="mac">无。</p>
        </section>
        <section id="parameters" deliveryTarget="details" props="android ios mac">
            <title>参数</title>
            <parml>
                <plentry props="ios">
                    <pt>frame</pt>
                    <pd>原始音频数据，详见 <xref keyref="AudioFrame"/>。</pd>
                </plentry>
                <plentry props="android">
                    <pt>type</pt>
                    <pd>音频帧类型。</pd>
                </plentry>
                <plentry props="android">
                    <pt>samplesPerChannel</pt>
                    <pd>每个声道中的采样点数。</pd>
                </plentry>
                <plentry props="android">
                    <pt>bytesPerSample</pt>
                    <pd>每个音频采样点的字节数。例如，每个 PCM 音频采样点通常占用 16 位（2 字节）。</pd>
                </plentry>
                <plentry props="android">
                    <pt>channels</pt>
                    <pd>声道数：
                        <ul>
                            <li>1：单声道。</li>
                            <li>2：立体声。若为立体声，数据为交错格式。</li>
                        </ul>
                    </pd>
                </plentry>
                <plentry props="android">
                    <pt>samplesPerSec</pt>
                    <pd>录音采样率（Hz）。</pd>
                </plentry>
                <plentry props="android">
                    <pt>buffer</pt>
                    <pd>音频缓冲区。缓冲区大小 = <codeph>samplesPerChannel</codeph> × <codeph>channels</codeph> × <codeph>bytesPerSample</codeph>。详见 <codeph>ByteBuffer</codeph>。</pd>
                </plentry>
                <plentry props="android">
                    <pt>renderTimeMs</pt>
                    <pd>外部音频帧的时间戳（毫秒）。你可以使用该参数在视频或音频相关场景中（包括使用自定义视频源的场景）实现音视频帧同步。</pd>
                </plentry>
                <plentry props="android">
                    <pt>avsync_type</pt>
                    <pd>预留参数。</pd>
                </plentry>
                <plentry props="mac">
                    <pt>frame</pt>
                    <pd>原始音频数据，详见 <xref keyref="AudioFrame"/>。</pd>
                </plentry>
            </parml>
        </section>
        <section id="return_values" props="android ios mac">
            <title>返回值</title>
            <p props="ios">
                <ul>
                    <li><xref keyref="true"/>：回调处理成功。</li>
                    <li><xref keyref="false"/>：回调处理失败。</li>
                </ul>
            </p>
            <p props="android">
                <ul>
                    <li><xref keyref="true"/>：回调处理成功。</li>
                    <li><xref keyref="false"/>：回调处理失败。</li>
                </ul>
            </p>
            <p props="mac">
                <ul>
                    <li><xref keyref="true"/>：回调处理成功。</li>
                    <li><xref keyref="false"/>：回调处理失败。</li>
                </ul>
            </p>
        </section>
    </refbody>
</reference>