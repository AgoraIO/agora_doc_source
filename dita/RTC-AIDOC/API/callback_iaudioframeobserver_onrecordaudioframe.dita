<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="callback_iaudioframeobserver_onrecordaudioframe">
    <title>
    <ph keyref="onRecordAudioFrame"/>
  </title>
    <shortdesc id="short">
    <ph id="shortdesc">获取采集到的音频帧回调。</ph>
  </shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="onRecordAudioFrame"/>
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
                <codeblock props="ios" outputclass="language-objectivec">- (BOOL)onRecordAudioFrame:(AgoraAudioFrame* _Nonnull)frame channelId:(NSString * _Nonnull)channelId  NS_SWIFT_NAME(onRecordAudioFrame(_:channelId:));</codeblock>
                <codeblock props="android" outputclass="language-java">public abstract boolean onRecordAudioFrame(String channelId, int type, int samplesPerChannel, int bytesPerSample, int channels, int samplesPerSec, ByteBuffer buffer, long renderTimeMs, int avsync_type);</codeblock>
                <codeblock props="mac" outputclass="language-objectivec">- (BOOL)onRecordAudioFrame:(AgoraAudioFrame* _Nonnull)frame channelId:(NSString * _Nonnull)channelId  NS_SWIFT_NAME(onRecordAudioFrame(_:channelId:));</codeblock>
            </p>
        </section>
        <section id="detailed_desc" deliveryTarget="details" otherprops="no-title" props="android ios mac">
            <p props="ios">你可以通过以下两种方式之一设置音频数据格式，以确保采集到的音频帧格式符合预期：
                <ul>
                    <li>方法一：调用 <xref keyref="setRecordingAudioFrameParameters"/> 设置音频数据格式，并调用 <xref keyref="registerAudioFrameObserver"/> 注册音频帧观察者对象。SDK 会根据设置的参数计算采样间隔，并按照采样间隔触发该回调。</li>
                    <li>方法二：调用 <xref keyref="registerAudioFrameObserver"/> 注册音频帧观察者对象，并在 <xref keyref="getObservedAudioFramePosition"/> 回调的返回值中设置音频数据格式。SDK 会根据 <xref keyref="getRecordAudioParams"/> 回调的返回值计算采样间隔，并按照采样间隔触发该回调。</li>
                </ul>
            </p>
            <p props="android">你可以通过以下两种方式之一设置音频数据格式：
                <ul>
                    <li>方法一：调用 <xref keyref="setRecordingAudioFrameParameters"/> 设置音频数据格式，并调用 <xref keyref="registerAudioFrameObserver2_IMediaPlayer"/> 注册音频帧观察者对象后，SDK 会根据方法中设置的参数计算采样间隔，并按照采样间隔触发该回调。</li>
                    <li>方法二：调用 <xref keyref="registerAudioFrameObserver2_IMediaPlayer"/> 注册音频帧观察者对象后，在 <xref keyref="getObservedAudioFramePosition"/> 回调的返回值中设置音频数据格式。SDK 会根据 <xref keyref="getRecordAudioParams"/> 回调的返回值计算采样间隔，并按照采样间隔触发该回调。</li>
                </ul>
            </p>
            <p props="mac">你可以通过以下两种方式之一设置音频数据格式，以确保采集到的音频帧格式符合预期：
                <ul>
                    <li>方法一：调用 <xref keyref="setRecordingAudioFrameParameters"/> 设置音频数据格式，并调用 <xref keyref="registerAudioFrameObserver"/> 注册音频帧观察者对象。SDK 会根据设置的参数计算采样间隔，并按照采样间隔触发该回调。</li>
                    <li>方法二：调用 <xref keyref="registerAudioFrameObserver"/> 注册音频帧观察者对象，并在 <xref keyref="getObservedAudioFramePosition"/> 回调的返回值中设置音频数据格式。SDK 会根据 <xref keyref="getRecordAudioParams"/> 回调的返回值计算采样间隔，并按照采样间隔触发该回调。</li>
                </ul>
            </p>
            <note props="ios"><xref keyref="setRecordingAudioFrameParameters"/> 的设置优先级高于 <xref keyref="getObservedAudioFramePosition"/> 和 <xref keyref="getRecordAudioParams"/> 的设置。如果使用方法一设置音频数据格式，则方法二的设置无效。</note>
            <note props="android"><xref keyref="setRecordingAudioFrameParameters"/> 的设置优先级高于 <xref keyref="getObservedAudioFramePosition"/>。如果使用方法一设置音频数据格式，则方法二的设置无效。</note>
            <note props="mac"><xref keyref="setRecordingAudioFrameParameters"/> 的设置优先级高于 <xref keyref="getObservedAudioFramePosition"/> 和 <xref keyref="getRecordAudioParams"/> 的设置。如果使用方法一设置音频数据格式，则方法二的设置无效。</note>
        </section>
        <section id="timing" deliveryTarget="details" props="ios mac">
            <title>触发时机</title>
            <p props="ios">该回调在采集到音频帧时被触发。</p>
            <p props="mac">该回调在采集到音频帧时被触发。</p>
        </section>
        <section id="restriction" deliveryTarget="details" props="android ios mac">
            <title>使用限制</title>
            <p props="ios">无。</p>
            <p props="android">无。</p>
            <p props="mac">无。</p>
        </section>
        <section id="parameters" deliveryTarget="details" props="android ios mac">
            <title>参数</title>
            <parml>
                <plentry props="ios">
                    <pt>frame</pt>
                    <pd>原始音频数据，详见 <xref keyref="AudioFrame"/>。</pd>
                </plentry>
                <plentry props="ios">
                    <pt>channelId</pt>
                    <pd>频道 ID。</pd>
                </plentry>
                <plentry props="android">
                    <pt>channelId</pt>
                    <pd>频道 ID。</pd>
                </plentry>
                <plentry props="android">
                    <pt>type</pt>
                    <pd>音频帧类型。</pd>
                </plentry>
                <plentry props="android">
                    <pt>samplesPerChannel</pt>
                    <pd>每个声道中的采样点数。</pd>
                </plentry>
                <plentry props="android">
                    <pt>bytesPerSample</pt>
                    <pd>每个音频采样的字节数。例如，每个 PCM 音频采样通常占用 16 位（2 字节）。</pd>
                </plentry>
                <plentry props="android">
                    <pt>channels</pt>
                    <pd>声道数：
                        <ul>
                            <li>1：单声道。</li>
                            <li>2：立体声。如果使用立体声，数据为交错排列。</li>
                        </ul>
                    </pd>
                </plentry>
                <plentry props="android">
                    <pt>samplesPerSec</pt>
                    <pd>录音采样率（Hz）。</pd>
                </plentry>
                <plentry props="android">
                    <pt>buffer</pt>
                    <pd>音频缓冲区。缓冲区大小 = <codeph>samplesPerChannel</codeph> × <codeph>channels</codeph> × <codeph>bytesPerSample</codeph>。</pd>
                </plentry>
                <plentry props="android">
                    <pt>renderTimeMs</pt>
                    <pd>外部音频帧的时间戳（毫秒）。你可以使用该参数在视频或音频相关场景中（包括使用外部视频源的场景）实现音视频帧同步。</pd>
                </plentry>
                <plentry props="android">
                    <pt>avsync_type</pt>
                    <pd>预留参数。</pd>
                </plentry>
                <plentry props="mac">
                    <pt>frame</pt>
                    <pd>原始音频数据，详见 <xref keyref="AudioFrame"/>。</pd>
                </plentry>
                <plentry props="mac">
                    <pt>channelId</pt>
                    <pd>频道 ID。</pd>
                </plentry>
            </parml>
        </section>
        <section id="return_values" props="android ios mac">
            <title>返回值</title>
            <p props="ios">
                <ul>
                    <li><xref keyref="true"/>：处理成功。</li>
                    <li><xref keyref="false"/>：处理失败。</li>
                </ul>
            </p>
            <p props="android">
                <ul>
                    <li><xref keyref="true"/>：回调处理成功。</li>
                    <li><xref keyref="false"/>：回调处理失败。</li>
                </ul>
            </p>
            <p props="mac">
                <ul>
                    <li><xref keyref="true"/>：处理成功。</li>
                    <li><xref keyref="false"/>：处理失败。</li>
                </ul>
            </p>
        </section>
    </refbody>
</reference>