<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="class_livetranscoding">
  <title> <ph keyref="LiveTranscoding"/> </title>
  <shortdesc id="short"> <ph id="shortdesc">旁路推流的转码属性。</ph> </shortdesc>
  <refbody>
    <section id="prototype">
      <p outputclass="codeblock">
      <codeblock props="android" outputclass="language-java">public class LiveTranscoding {
  public enum AudioSampleRateType {
    TYPE_32000(32000),
    TYPE_44100(44100),
    TYPE_48000(48000);
    private int value;
    private AudioSampleRateType(int v) {
      value = v;
    }
    public static int getValue(AudioSampleRateType type) {
      return type.value;
    }
  }
  public enum VideoCodecProfileType {
    BASELINE(66),
    MAIN(77),
    HIGH(100);
    private int value;
    private VideoCodecProfileType(int v) {
      value = v;
    }
    public static int getValue(VideoCodecProfileType type) {
      return type.value;
    }
  }
  public enum AudioCodecProfileType {
    LC_AAC(0),
    HE_AAC(1),
    HE_AAC(1);
    HE_AAC_V2(2);
    private int value;
    private AudioCodecProfileType(int v) {
      value = v;
    }
    public static int getValue(AudioCodecProfileType type) {
      return type.value;
    }
  }
  public enum VideoCodecType {
    H264(1),
    H265(2);
    private int value;
    private VideoCodecType(int v) {
      value = v;
    }
    public static int getValue(VideoCodecType type) {
      return type.value;
    }
  }
  public int width;
  public int height;
  public int videoBitrate;
  public int videoFramerate;
  public boolean lowLatency;
  @Deprecated public boolean lowLatency;
  public int videoGop;
  public AgoraImage watermark;
  private ArrayList&lt;AgoraImage&gt; watermarkList;
  public void addWatermark(AgoraImage watermark) {
    if (watermarkList == null) {
      watermarkList = new ArrayList&lt;AgoraImage&gt;();
    }
    watermarkList.add(watermark);
  }
  public boolean removeWatermark(AgoraImage watermark) {
    if (watermarkList == null) {
      return false;
    }
    return watermarkList.remove(watermark);
  }
  public ArrayList&lt;AgoraImage&gt; getWatermarkList() {
    return watermarkList;
  }
  public AgoraImage backgroundImage;
  private ArrayList&lt;AgoraImage&gt; backgroundImageList;
  public void addBackgroundImage(AgoraImage backgroundImage) {
    if (backgroundImageList == null) {
      backgroundImageList = new ArrayList&lt;AgoraImage&gt;();
    }
    backgroundImageList.add(backgroundImage);
  }
  public boolean removeBackgroundImage(AgoraImage backgroundImage) {
    if (backgroundImageList == null) {
      return false;
    }
    return backgroundImageList.remove(backgroundImage);
  }
  public ArrayList&lt;AgoraImage&gt; getBackgroundImageList() {
    return backgroundImageList;
  }
  public AudioSampleRateType audioSampleRate;
  public int audioBitrate;
  public int audioChannels;
  public AudioCodecProfileType audioCodecProfile;
  public VideoCodecProfileType videoCodecProfile;
  public VideoCodecType videoCodecType;
  @Deprecated public int userCount;
  @Deprecated public int backgroundColor;
  public String userConfigExtraInfo;
  public String metadata;
  @Deprecated public String metadata;
  private Map&lt;Integer, TranscodingUser&gt; transcodingUsers;
  private Map&lt;String, Boolean&gt; advancedFeatures;
  public void setAdvancedFeatures(String featureName, Boolean opened) {
    advancedFeatures.put(featureName, opened);
  }
  public Map&lt;String, Boolean&gt; getAdvancedFeatures() {
    return advancedFeatures;
  }
  public static class TranscodingUser {
    public int uid;
    public String userId;
    public String userId;
    public int x;
    public int y;
    public int width;
    public int height;
    public int zOrder;
    public float alpha;
    public int audioChannel;
    public TranscodingUser() {
      alpha = 1;
    }
  }
  public LiveTranscoding() {
    width = 360;
    height = 640;
    videoBitrate = 400;
    videoCodecProfile = VideoCodecProfileType.HIGH;
    videoCodecType = VideoCodecType.H264;
    videoGop = 30;
    videoFramerate = 15;
    watermark = new AgoraImage();
    backgroundImage = new AgoraImage();
    lowLatency = false;
    audioSampleRate = AudioSampleRateType.TYPE_44100;
    audioBitrate = 48;
    audioChannels = 1;
    audioCodecProfile = AudioCodecProfileType.LC_AAC;
    transcodingUsers = new HashMap&lt;&gt;();
    advancedFeatures = new HashMap&lt;&gt;();
    backgroundColor = 0xFF000000;
    userConfigExtraInfo = null;
    metadata = null;
  }
  public int addUser(TranscodingUser user) {
    if (user == null || user.uid == 0) {
      return -Constants.ERR_INVALID_ARGUMENT;
    }
    transcodingUsers.put(user.uid, user);
    userCount = transcodingUsers.size();
    return Constants.ERR_OK;
  }
  public final ArrayList&lt;TranscodingUser&gt; getUsers() {
    Collection&lt;TranscodingUser&gt; values = transcodingUsers.values();
    return new ArrayList&lt;&gt;(values);
  }
  public void setUsers(ArrayList&lt;TranscodingUser&gt; users) {
    transcodingUsers.clear();
    if (users != null) {
      for (TranscodingUser user : users) {
        transcodingUsers.put(user.uid, user);
      }
    }
    userCount = transcodingUsers.size();
  }
  public void setUsers(Map&lt;Integer, TranscodingUser&gt; users) {
    transcodingUsers.clear();
    if (users != null) {
      transcodingUsers.putAll(users);
    }
    userCount = transcodingUsers.size();
  }
  public int removeUser(int uid) {
    if (!transcodingUsers.containsKey(uid))
      return -Constants.ERR_INVALID_ARGUMENT;
    transcodingUsers.remove(uid);
    userCount = transcodingUsers.size();
    return Constants.ERR_OK;
  }
  public int getUserCount() {
    return transcodingUsers.size();
  }
  public int getBackgroundColor() {
    return this.backgroundColor;
  }
  public void setBackgroundColor(int color) {
    this.backgroundColor = color;
  }
  public void setBackgroundColor(int red, int green, int blue) {
    this.backgroundColor = (red &lt;&lt; 16) | (green &lt;&lt; 8) | (blue &lt;&lt; 0);
  }
  @Deprecated
  public int getRed() {
    return (backgroundColor &gt;&gt; 16) &amp; 0x0ff;
  }
  @Deprecated
  public int getGreen() {
    return (backgroundColor &gt;&gt; 8) &amp; 0x0ff;
  }
  @Deprecated
  public int getBlue() {
    return backgroundColor &amp; 0x0ff;
  }
  @Deprecated
  public void setRed(int red) {
    int green = getGreen();
    int blue = getBlue();
    this.backgroundColor = (red &lt;&lt; 16) | (green &lt;&lt; 8) | (blue &lt;&lt; 0);
  }
  @Deprecated
  public void setGreen(int green) {
    int red = getRed();
    int blue = getBlue();
    this.backgroundColor = (red &lt;&lt; 16) | (green &lt;&lt; 8) | (blue &lt;&lt; 0);
  }
  @Deprecated
  public void setBlue(int blue) {
    int red = getRed();
    int green = getGreen();
    this.backgroundColor = (red &lt;&lt; 16) | (green &lt;&lt; 8) | (blue &lt;&lt; 0);
  }
}</codeblock>
      <codeblock props="ios mac" outputclass="language-objectivec">__attribute__((visibility("default"))) @interface AgoraLiveTranscoding : NSObject

@property(assign, nonatomic) CGSize size;
@property(assign, nonatomic) NSInteger videoBitrate;
@property(assign, nonatomic) NSInteger videoFramerate;
@property(assign, nonatomic) BOOL lowLatency;
@property(assign, nonatomic) NSInteger videoGop;
@property(assign, nonatomic) AgoraVideoCodecProfileType videoCodecProfile;
@property(assign, nonatomic) AgoraVideoCodecTypeForStream videoCodecType;
@property(copy, nonatomic) NSArray&lt;AgoraLiveTranscodingUser *&gt; *_Nullable transcodingUsers;
@property(copy, nonatomic) NSString *_Nullable transcodingExtraInfo;
@property(strong, nonatomic) AgoraImage *_Nullable watermark;
@property (copy, nonatomic) NSArray&lt;AgoraImage *&gt; *_Nullable watermarkArray;
@property(strong, nonatomic) AgoraImage *_Nullable backgroundImage;
@property (copy, nonatomic) NSArray&lt;AgoraImage *&gt; *_Nullable backgroundImageArray;
@property(strong, nonatomic) COLOR_CLASS *_Nullable backgroundColor;
@property(assign, nonatomic) AgoraAudioSampleRateType audioSampleRate;
@property(assign, nonatomic) NSInteger audioBitrate;
@property(assign, nonatomic) NSInteger audioChannels;
@property(assign, nonatomic) AgoraAudioCodecProfileType audioCodecProfile;
+ (AgoraLiveTranscoding *_Nonnull)defaultTranscoding;
- (int)addUser:(AgoraLiveTranscodingUser *_Nonnull)user;
- (int)removeUser:(NSUInteger)uid;
- (void)setAdvancedFeatures:(NSString* _Nonnull)featureName opened:(BOOL)opened;
- (NSArray&lt;AgoraLiveStreamAdvancedFeature*&gt;* _Nullable)getAdvancedFeatures;
@end</codeblock>
      <codeblock props="cpp" outputclass="language-cpp">struct LiveTranscoding {
  int width;
  int height;
  int videoBitrate;
  int videoFramerate;
  bool lowLatency;
  int videoGop;
  VIDEO_CODEC_PROFILE_TYPE videoCodecProfile;
  unsigned int backgroundColor;
  VIDEO_CODEC_TYPE_FOR_STREAM videoCodecType;
  unsigned int userCount;
  TranscodingUser* transcodingUsers;
  const char* transcodingExtraInfo;
  const char* metadata;
  RtcImage* watermark;
  unsigned int watermarkCount;
  RtcImage* backgroundImage;
  unsigned int backgroundImageCount;
  AUDIO_SAMPLE_RATE_TYPE audioSampleRate;
  int audioBitrate;
  int audioChannels;
  AUDIO_CODEC_PROFILE_TYPE audioCodecProfile;
  LiveStreamAdvancedFeature* advancedFeatures;
  unsigned int advancedFeatureCount;
  LiveTranscoding() : width(360), height(640), videoBitrate(400), videoFramerate(15), lowLatency(false), videoGop(30), videoCodecProfile(VIDEO_CODEC_PROFILE_HIGH), backgroundColor(0x000000), videoCodecType(VIDEO_CODEC_H264_FOR_STREAM), userCount(0), transcodingUsers(NULL), transcodingExtraInfo(NULL), metadata(NULL), watermark(NULL), watermarkCount(0), backgroundImage(NULL), backgroundImageCount(0), audioSampleRate(AUDIO_SAMPLE_RATE_48000), audioBitrate(48), audioChannels(1), audioCodecProfile(AUDIO_CODEC_PROFILE_LC_AAC), advancedFeatures(NULL), advancedFeatureCount(0) {}
};</codeblock>
      <codeblock props="electron" outputclass="language-typescript"/>
      <codeblock props="unity" outputclass="language-csharp">public class LiveTranscoding
    {
        public LiveTranscoding()
        {
            width = 360;
            height = 640;
            videoBitrate = 400;
            videoFramerate = 15;
            lowLatency = false;
            videoGop = 30;
            videoCodecProfile = VIDEO_CODEC_PROFILE_TYPE.VIDEO_CODEC_PROFILE_HIGH;
            backgroundColor = 0x000000;
            videoCodecType = VIDEO_CODEC_TYPE_FOR_STREAM.VIDEO_CODEC_H264_FOR_STREAM;
            userCount = 0;
            transcodingUsers = new TranscodingUser[0];
            transcodingExtraInfo = null;
            metadata = null;
            watermark = new RtcImage[0];
            watermarkCount = 0;
            backgroundImage = new RtcImage[0];
            backgroundImageCount = 0;
            audioSampleRate = AUDIO_SAMPLE_RATE_TYPE.AUDIO_SAMPLE_RATE_48000;
            audioBitrate = 48;
            audioChannels = 1;
            audioCodecProfile = AUDIO_CODEC_PROFILE_TYPE.AUDIO_CODEC_PROFILE_LC_AAC;
            advancedFeatures = new LiveStreamAdvancedFeature[0];
            advancedFeatureCount = 0;
        }

        public LiveTranscoding(int width, int height, int videoBitrate, int videoFramerate, bool lowLatency,
            int videoGop, VIDEO_CODEC_PROFILE_TYPE videoCodecProfile, uint backgroundColor,
            VIDEO_CODEC_TYPE_FOR_STREAM videoCodecType, uint userCount, TranscodingUser[] transcodingUsers,
            string transcodingExtraInfo, string metadata, RtcImage[] watermark, uint watermarkCount,
            RtcImage[] backgroundImage, uint backgroundImageCount,
            AUDIO_SAMPLE_RATE_TYPE audioSampleRate, int audioBitrate, int audioChannels,
            AUDIO_CODEC_PROFILE_TYPE audioCodecProfile, LiveStreamAdvancedFeature[] advancedFeatures, uint advancedFeatureCount)
        {
            this.width = width;
            this.height = height;
            this.videoBitrate = videoBitrate;
            this.videoFramerate = videoFramerate;
            this.lowLatency = lowLatency;
            this.videoGop = videoGop;
            this.videoCodecProfile = videoCodecProfile;
            this.backgroundColor = backgroundColor;
            this.videoCodecType = videoCodecType;
            this.userCount = userCount;
            this.transcodingUsers = transcodingUsers;
            this.transcodingExtraInfo = transcodingExtraInfo;
            this.metadata = metadata;
            this.watermark = watermark;
            this.watermarkCount = watermarkCount;
            this.backgroundImage = backgroundImage;
            this.backgroundImageCount = backgroundImageCount;
            this.audioSampleRate = audioSampleRate;
            this.audioBitrate = audioBitrate;
            this.audioChannels = audioChannels;
            this.audioCodecProfile = audioCodecProfile;
            this.advancedFeatures = advancedFeatures;
            this.advancedFeatureCount = advancedFeatureCount;
        }
        public int width { set; get; }
        public int height { set; get; }
        public int videoBitrate { set; get; }
        public int videoFramerate { set; get; }
        public bool lowLatency { set; get; }
        public int videoGop { set; get; }
        public VIDEO_CODEC_PROFILE_TYPE videoCodecProfile { set; get; }
        public uint backgroundColor { set; get; }
        public VIDEO_CODEC_TYPE_FOR_STREAM videoCodecType { set; get; }
        public uint userCount { set; get; }
        public TranscodingUser[] transcodingUsers { set; get; }
        public string transcodingExtraInfo { set; get; }
        public string metadata { set; get; }
        public RtcImage[] watermark { set; get; }
        public uint watermarkCount { set; get; }
        public RtcImage[] backgroundImage { set; get; }
        public uint backgroundImageCount { set; get; }
        public AUDIO_SAMPLE_RATE_TYPE audioSampleRate { set; get; }
        public int audioBitrate { set; get; }
        public int audioChannels { set; get; }
        public AUDIO_CODEC_PROFILE_TYPE audioCodecProfile { set; get; }
        public LiveStreamAdvancedFeature[] advancedFeatures { set; get; }
        public uint advancedFeatureCount { set; get; }
    }</codeblock>
      <codeblock props="rn" outputclass="language-typescript">export class LiveTranscoding {
  width?: number;
  height?: number;
  videoBitrate?: number;
  videoFramerate?: number;
  lowLatency?: boolean;
  videoGop?: number;
  videoCodecProfile?: VideoCodecProfileType;
  backgroundColor?: number;
  videoCodecType?: VideoCodecTypeForStream;
  userCount?: number;
  transcodingUsers?: TranscodingUser[];
  transcodingExtraInfo?: string;
  metadata?: string;
  watermark?: RtcImage[];
  watermarkCount?: number;
  backgroundImage?: RtcImage[];
  backgroundImageCount?: number;
  audioSampleRate?: AudioSampleRateType;
  audioBitrate?: number;
  audioChannels?: number;
  audioCodecProfile?: AudioCodecProfileType;
  advancedFeatures?: LiveStreamAdvancedFeature[];
  advancedFeatureCount?: number;
}</codeblock>
      <codeblock props="flutter" outputclass="language-dart">class LiveTranscoding {
  const LiveTranscoding(
      {this.width,
      this.height,
      this.videoBitrate,
      this.videoFramerate,
      this.lowLatency,
      this.videoGop,
      this.videoCodecProfile,
      this.backgroundColor,
      this.videoCodecType,
      this.userCount,
      this.transcodingUsers,
      this.transcodingExtraInfo,
      this.metadata,
      this.watermark,
      this.watermarkCount,
      this.backgroundImage,
      this.backgroundImageCount,
      this.audioSampleRate,
      this.audioBitrate,
      this.audioChannels,
      this.audioCodecProfile,
      this.advancedFeatures,
      this.advancedFeatureCount});

  @JsonKey(name: 'width')
  final int? width;
  @JsonKey(name: 'height')
  final int? height;
  @JsonKey(name: 'videoBitrate')
  final int? videoBitrate;
  @JsonKey(name: 'videoFramerate')
  final int? videoFramerate;
  @JsonKey(name: 'lowLatency')
  final bool? lowLatency;
  @JsonKey(name: 'videoGop')
  final int? videoGop;
  @JsonKey(name: 'videoCodecProfile')
  final VideoCodecProfileType? videoCodecProfile;
  @JsonKey(name: 'backgroundColor')
  final int? backgroundColor;
  @JsonKey(name: 'videoCodecType')
  final VideoCodecTypeForStream? videoCodecType;
  @JsonKey(name: 'userCount')
  final int? userCount;
  @JsonKey(name: 'transcodingUsers')
  final List&lt;TranscodingUser>? transcodingUsers;
  @JsonKey(name: 'transcodingExtraInfo')
  final String? transcodingExtraInfo;
  @JsonKey(name: 'metadata')
  final String? metadata;
  @JsonKey(name: 'watermark')
  final List&lt;RtcImage>? watermark;
  @JsonKey(name: 'watermarkCount')
  final int? watermarkCount;
  @JsonKey(name: 'backgroundImage')
  final List&lt;RtcImage>? backgroundImage;
  @JsonKey(name: 'backgroundImageCount')
  final int? backgroundImageCount;
  @JsonKey(name: 'audioSampleRate')
  final AudioSampleRateType? audioSampleRate;
  @JsonKey(name: 'audioBitrate')
  final int? audioBitrate;
  @JsonKey(name: 'audioChannels')
  final int? audioChannels;
  @JsonKey(name: 'audioCodecProfile')
  final AudioCodecProfileType? audioCodecProfile;
  @JsonKey(name: 'advancedFeatures')
  final List&lt;LiveStreamAdvancedFeature>? advancedFeatures;
  @JsonKey(name: 'advancedFeatureCount')
  final int? advancedFeatureCount;
  factory LiveTranscoding.fromJson(Map&lt;String, dynamic> json) =>
      _$LiveTranscodingFromJson(json);
  Map&lt;String, dynamic> toJson() => _$LiveTranscodingToJson(this);
}</codeblock>
      </p>
    </section>
    <section id="parameters">
      <title><text
      conref="../conref/conref_api_metadata.dita#conref_api_metadata/property"
      /></title>
      <parml>
      <plentry props="android cpp electron rn unity flutter">
        <pt>width</pt>
        <pd>
          <p>推流视频的总宽度，默认值 360，单位为像素。</p>
          <ul>
          <li>如果推视频流，<codeph>width</codeph> 取值范围为 [64,1920]。如果取值低于 64，Agora 服务器会自动调整为 64； 如果取值高于 1920，Agora 服务器会自动调整为 1920。</li>
          <li>如果推音频流，请将 <codeph>width</codeph> 和 <codeph>height</codeph> 设为 0。</li>
          </ul> </pd>
      </plentry>
      <plentry props="android cpp electron rn unity flutter">
        <pt>height</pt>
        <pd>
          <p>推流视频的总高度，默认值 640，单位为像素。</p>
          <ul>
          <li>如果推视频流，<codeph>height</codeph> 取值范围为 [64,1080]。如果取值低于 64，Agora 服务器会自动调整为 64； 如果取值高于 1080，Agora 服务器会自动调整为 1080。</li>
          <li>如果推音频流，请将 <codeph>width</codeph> 和 <codeph>height</codeph> 设为 0。</li>
          </ul> </pd>
      </plentry>
      <plentry props="ios mac">
        <pt>size</pt>
        <pd>
          <p>推流视频的总尺寸（宽和高），单位为像素。</p>
          <ul>
          <li>如果推视频流，请注意：

            
            <ul>
            <li>宽的取值范围为 [64,1920]。如果取值低于 64，Agora 服务器会自动调整为 64；如果取值高于 1920，Agora 服务器会自动调整为 1920。</li>
            <li>高的取值范围为 [64,1080]。如果取值低于 64，Agora 服务器会自动调整为 64；如果取值高于 1080，Agora 服务器会自动调整为 1080。</li>
            </ul></li>
          <li>如果推音频流，请将宽和高都设为 0。</li>
          </ul> </pd>
      </plentry>
      <plentry>
        <pt>videoBitrate</pt>
        <pd>
          <p>用于旁路直播的输出视频的码率。单位为 Kbps。400 Kbps 为默认值。</p>
          <p props="native">你可以根据<xref keyref="video-profile-table"
          >视频属性</xref>参考表中的码率值进行设置；如果设置的码率超出合理范围，Agora 服务器会在合理区间内自动调整码率值。</p>
        </pd>
      </plentry>
      <plentry>
        <pt>videoFrameRate</pt>
        <pd>
          <p>用于旁路直播的输出视频的帧率。取值范围是 (0,30]，单位为 fps。15 fps 为默认值。</p>
          <note type="attention"
          >Agora 服务器会将高于 30 fps 的帧率统一调整为 30 fps。</note></pd>
      </plentry>
      <plentry>
        <pt>lowLatency</pt>
        <pd>
          <dl outputclass="deprecated">
          <dlentry>
            <dt>弃用</dt>
            <dd>Agora 不推荐使用。</dd>
          </dlentry>
          </dl>
          <p>低延时模式</p>
          <ul>
          <li><codeph><ph keyref="true"/></codeph>: 低延时，不保证画质。</li>
          <li><codeph><ph keyref="false"/></codeph>:（默认值）高延时，保证画质。</li>
          </ul></pd>
      </plentry>
      <plentry>
        <pt>videoGop</pt>
        <pd>用于旁路直播的输出视频的 GOP（Group of Pictures)。单位为帧。默认值为 30。</pd>
      </plentry>
      <plentry>
        <pt>videoCodecProfile</pt>
        <pd>
          <p>用于旁路直播的输出视频的编码规格。可以设置为 66、77 或 100，详见 <xref
          keyref="VIDEO_CODEC_PROFILE_TYPE"/>。</p>
          <note type="attention">如果你把这个参数设为其他值，Agora 服务器会将其调整为默认值。</note></pd>
      </plentry>
      <plentry>
        <pt>videoCodecType</pt>
        <pd>用于旁路直播的输出视频的编解码类型。详见 <xref keyref="VIDEO_CODEC_TYPE_FOR_STREAM"
          />。</pd>
      </plentry>
      <plentry>
        <pt>transcodingUsers</pt>
        <pd>
          <p>用于管理参与旁路直播的视频转码合图的用户。最多支持 17 人同时参与转码合图。详见 <xref
          keyref="TranscodingUser"/>。</p>
        </pd>
      </plentry>
      <plentry>
        <pt props="ios mac cpp unity electron rn flutter">transcodingExtraInfo</pt>
        <pt props="android">userConfigExtraInfo</pt>
        <pd>
          <p>预留参数：用户自定义的发送到旁路推流客户端的信息，用于填充 H264/H265 视频中 SEI 帧内容。长度限制：4096 字节。关于 SEI 的详细信息，详见 <xref
          keyref="faq-sei">SEI 帧相关问题</xref>。</p>
        </pd>
      </plentry>
      <plentry props="ios mac">
        <pt>backgroundColor</pt>
        <pd>
          <p>用于旁路直播的输出视频的背景色。</p>
          <p>格式为 RGB 定义下的十六进制整数，不要带 # 号，如 0xFFB6C1 表示浅粉色。默认 0x000000，黑色。</p>
          <p>COLOR_CLASS 为类型统称，具体为：
          
          <ul>
          <li>iOS: UIColor</li>
          <li>macOS: NSColor</li>
          </ul></p>
        </pd>
      </plentry>
      <plentry props="android cpp unity electron rn flutter">
        <pt>backgroundColor</pt>
        <pd props="android">
          <dl outputclass="deprecated">
          <dlentry>
            <dt>弃用</dt>
            <dd>已废弃，Agora 不推荐使用。请改用 <xref keyref="setBackgroundColor"/> 方法。</dd>
          </dlentry>
          </dl>
        </pd>
        <pd props="cpp unity electron rn flutter">
          <p>用于旁路直播的输出视频的背景色，格式为 RGB 定义下的十六进制整数，不要带 # 号，如 0xFFB6C1 表示浅粉色。默认0x000000，黑色。</p>
        </pd>
      </plentry>
      <plentry props="android cpp electron rn unity flutter">
        <pt>userCount</pt>
        <pd>
          <dl outputclass="deprecated" props="android">
          <dlentry>
            <dt>弃用</dt>
            <dd>已废弃，Agora 不推荐使用。请改用 <xref keyref="getUserCount"/> 方法。</dd>
          </dlentry>
          </dl>
          <p>参与合图的用户数量，默认 0。取值范围为 [0,17]。</p>
        </pd>
      </plentry>
      <plentry props="android cpp unity electron rn flutter">
        <pt>metadata</pt>
        <pd>
          <dl outputclass="deprecated">
          <dlentry>
            <dt>弃用</dt>
            <dd>已废弃，Agora 不推荐使用。</dd>
          </dlentry>
          </dl>
          <p>发送给 CDN 客户端的 metadata。</p>
        </pd>
      </plentry>
      <plentry>
        <pt>watermark</pt>
        <pd>
          <dl outputclass="deprecated" props="android ios mac">
          <dlentry>
            <dt>弃用</dt>
            <dd props="android">请改用 <xref keyref="addWatermark"/>。</dd>
            <dd props="ios mac">请改用 <parmname>watermarkArray</parmname>。</dd>
          </dlentry>
          </dl>
          <p>直播视频上的水印。图片格式需为 PNG。详见 <xref keyref="RtcImage" />。</p>
          <p props="cpp unity flutter electron rn">你可以添加一个水印，或使用数组的方式添加多个水印。<ph props="cpp unity electron rn">该参数与 <parmname>watermarkCount</parmname>搭配使用。</ph></p>
        </pd>
      </plentry>
      <plentry>
        <pt>backgroundImage</pt>
        <pd>
          <dl props="android ios mac" outputclass="deprecated">
          <dlentry>
            <dt>弃用</dt>
            <dd><ph>请改用 <parmname props="android"
              >addBackgroundImage</parmname><parmname props="ios mac"
              >backgroundImageArray</parmname>。</ph></dd>
          </dlentry>
          </dl>
          <p>直播视频上的背景图。图片格式需为 PNG。详见 <xref keyref="RtcImage" />。</p>
          <p props="cpp unity electron rn flutter">你可以添加一张背景图，或使用数组的方式添加多张背景图。该参数与 <parmname>backgroundImageCount</parmname> 搭配使用。</p>
        </pd>
      </plentry>
      <plentry props="ios mac">
        <pt>backgroundImageArray</pt>
        <pd>直播视频上的背景图数组。详见 <xref keyref="RtcImage"
          />。你可以使用 <parmname>backgroundImageArray</parmname> 添加一张或多张背景图。图片格式需为 PNG。直播视频上的水印和背景图的总数量需大于等于 0 且小于等于 10。</pd>
      </plentry>
      <plentry>
        <pt>audioSampleRate</pt>
        <pd>
          <p>用于旁路推流的输出媒体流的音频采样率 (Hz)，详见 <xref keyref="AUDIO_SAMPLE_RATE_TYPE"
          />。</p>
        </pd>
      </plentry>
      <plentry>
        <pt>audioBitrate</pt>
        <pd>
          <p>用于旁路直播的输出音频的码率。单位为 Kbps，默认值为 48，最大值为 128。</p>
        </pd>
      </plentry>
      <plentry>
        <pt>audioChannels</pt>
        <pd>
          <p>用于旁路直播的输出音频的声道数，默认值为 1。取值范围为 [1,5] 中的整型，建议取 1 或 2。3、4、5 需要特殊播放器支持： </p>
          <ul>
          <li>1: （默认）单声道</li>
          <li>2: 双声道</li>
          <li>3: 三声道</li>
          <li>4: 四声道</li>
          <li>5: 五声道</li>
          </ul> </pd>
      </plentry>
      <plentry>
        <pt>audioCodecProfile</pt>
        <pd>用于旁路直播输出音频的编码规格。详见 <xref keyref="AUDIO_CODEC_PROFILE_TYPE"/>。
                    </pd>
      </plentry>
      <plentry props="ios mac">
        <pt>watermarkArray</pt>
        <pd> 直播视频上的水印数组。详见 <xref keyref="RtcImage"
          />。你可以使用 <parmname>watermarkArray</parmname> 添加一张或多张水印。图片格式需为 PNG。直播视频上的水印和背景图的总数量需大于等于 0 且小于等于 10。 </pd>
      </plentry>
      <plentry props="cpp unity electron rn flutter">
        <pt>watermarkCount</pt>
        <pd>直播视频上的水印的数量。水印和背景图的总数量需大于等于 0 且小于等于 10。该参数与 <parmname>watermark</parmname> 搭配使用。</pd>
      </plentry>
      <plentry props="cpp unity electron rn flutter">
        <pt>backgroundImageCount</pt>
        <pd>直播视频上的背景图的数量。水印和背景图的总数量需大于等于 0 且小于等于 10。该参数与 <parmname>backgroundImage</parmname> 搭配使用。</pd>
      </plentry>
      <plentry props="cpp unity electron rn flutter">
        <pt>advancedFeatures</pt>
        <pd>转码推流的高级功能。详见 <xref keyref="LiveStreamAdvancedFeature"/>。</pd>
      </plentry>
      <plentry props="cpp unity electron rn flutter">
        <pt>advancedFeatureCount</pt>
        <pd>开启的高级功能数量。默认值为 0。</pd>
      </plentry>
      </parml> </section>
  </refbody>
</reference>
