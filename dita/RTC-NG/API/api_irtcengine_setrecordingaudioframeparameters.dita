<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="api_irtcengine_setrecordingaudioframeparameters">
    <title><ph keyref="setRecordingAudioFrameParameters" /></title>
    <shortdesc id="short"><ph id="shortdesc">设置采集的原始音频数据格式。</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="setRecordingAudioFrameParameters" />
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">public abstract int setRecordingAudioFrameParameters(
      int sampleRate, int channel, int mode, int samplesPerCall);</codeblock>
            <codeblock props="hmos" outputclass="language-arkts">public abstract setRecordingAudioFrameParameters(sampleRate: number, channel: number, mode: number, samplesPerCall: number): number;</codeblock>
            <codeblock props="ios mac" outputclass="language-objectivec">- (int)setRecordingAudioFrameParametersWithSampleRate:(NSInteger)sampleRate
                                              channel:(NSInteger)channel
                                                 mode:(AgoraAudioRawFrameOperationMode)mode
                                       samplesPerCall:(NSInteger)samplesPerCall;</codeblock>
            <codeblock props="cpp unreal" outputclass="language-cpp">virtual int setRecordingAudioFrameParameters(int sampleRate,
    int channel,
    RAW_AUDIO_FRAME_OP_MODE_TYPE mode,
    int samplesPerCall) = 0;</codeblock>
            <codeblock props="bp" outputclass="language-cpp">UFUNCTION(BlueprintCallable, Category = &quot;Agora|IRtcEngine&quot;)
	int SetRecordingAudioFrameParameters(int sampleRate, int channel, ERAW_AUDIO_FRAME_OP_MODE_TYPE mode, int samplesPerCall);</codeblock>
            <codeblock props="electron" outputclass="language-typescript">abstract setRecordingAudioFrameParameters(
    sampleRate: number,
    channel: number,
    mode: RawAudioFrameOpModeType,
    samplesPerCall: number
  ): number;</codeblock>
            <codeblock props="unity cs" outputclass="language-csharp">public abstract int SetRecordingAudioFrameParameters(int sampleRate, int channel, RAW_AUDIO_FRAME_OP_MODE_TYPE mode, int samplesPerCall);</codeblock>
            <codeblock props="rn" outputclass="language-typescript">abstract setRecordingAudioFrameParameters(
    sampleRate: number,
    channel: number,
    mode: RawAudioFrameOpModeType,
    samplesPerCall: number
  ): number;</codeblock>
            <codeblock props="flutter" outputclass="language-dart">Future&lt;void&gt; setRecordingAudioFrameParameters(
    {required int sampleRate,
    required int channel,
    required RawAudioFrameOpModeType mode,
    required int samplesPerCall});</codeblock>
            <codeblock props="reserve" outputclass="language-cpp"></codeblock></p>
        </section>
        <section id="detailed_desc" deliveryTarget="details" otherprops="no-title">
            <p><ph id="function">SDK 会通过该方法中的 <parmname>samplesPerCall</parmname>、<parmname>sampleRate</parmname> 和 <parmname>channel</parmname> 参数计算出采样间隔，计算公式为<equation-inline>采样间隔 = <parmname>samplesPerCall</parmname>/(<parmname>sampleRate</parmname> × <parmname>channel</parmname>)</equation-inline>。请确保采样间隔不小于 0.01 秒。</ph><ph>SDK 会根据该采样间隔触发 <xref keyref="onRecordAudioFrame" /> 回调。</ph></p>
        </section>
        <section id="timing" deliveryTarget="details">
            <title>调用时机</title>
            <p>该方法需要在加入频道前调用。</p>
        </section>        
        <section id="restriction" deliveryTarget="details">
            <title>调用限制</title>
            <p>无。</p>
        </section>
        <section id="parameters" deliveryTarget="details">
            <title>参数</title>
            <parml>
            <plentry id="sampleRate">
                <pt>sampleRate</pt>
                <pd>音频数据的采样率 (Hz)，可设置为 8000、 16000、 32000、44100 或 48000。</pd>
            </plentry>
            <plentry id="channel">
                <pt>channel</pt>
                <pd>
                    音频数据的声道数，可设置为 1 或 2:
                    <ul>
                    <li>1: 单声道。</li>
                    <li>2: 双声道。</li>
                    </ul>
                </pd>
            </plentry>
            <plentry id="mode">
                <pt>mode</pt>
                <pd>
                    <p props="apple cpp hmos framework">音频帧的使用模式，详见 <xref keyref="RAW_AUDIO_FRAME_OP_MODE_TYPE" />。</p>
                    <p conkeyref="registerAudioFrameObserver2_IMediaPlayer/mode" props="android" />
                </pd>
            </plentry>
            <plentry id="samplesPerCall">
                <pt>samplesPerCall</pt>
                <pd>音频数据的采样点数，如旁路推流应用中通常为 1024。</pd>
            </plentry>
            </parml> </section>
        <section id="return_values">
            <title><ph keyref="return-section-title"/></title>
            <p props="flutter">方法成功调用时，无返回值；方法调用失败时，会抛出 <xref keyref="AgoraRtcException"/> 异常，你需要捕获异常并进行处理。<ph props="cn">详见<xref keyref="error-code-link"/>了解详情和解决建议。</ph></p>
            <ul>
            <li props="native unreal bp unity electron rn cs">0：方法调用成功。</li>
            <li>&lt; 0：方法调用失败。<ph props="cn">详见<xref keyref="error-code-link"/>了解详情和解决建议。</ph></li>
            </ul> </section>
    </refbody>
</reference>