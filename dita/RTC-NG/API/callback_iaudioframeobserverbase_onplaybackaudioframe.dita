<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="callback_iaudioframeobserverbase_onplaybackaudioframe">
    <title><ph keyref="onPlaybackAudioFrame"/></title>
    <shortdesc id="short"><ph id="shortdesc">获得播放的原始音频数据。</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="onPlaybackAudioFrame"/>
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">public abstract boolean onPlaybackAudioFrame(int type, int samplesPerChannel, int bytesPerSample,
      int channels, int samplesPerSec, ByteBuffer buffer, long renderTimeMs, int avsync_type);
</codeblock>
            <codeblock props="ios mac" outputclass="language-objectivec">- (BOOL)onPlaybackAudioFrame:(AgoraAudioFrame* _Nonnull)frame;</codeblock>
            <codeblock props="cpp" outputclass="language-cpp">virtual bool onPlaybackAudioFrame(AudioFrame&amp; audioFrame) = 0;</codeblock>
            <codeblock props="electron" outputclass="language-typescript">  onPlaybackAudioFrame?(channelId: string, audioFrame: AudioFrame): boolean;</codeblock>
            <codeblock props="unity" outputclass="language-csharp">public virtual bool OnPlaybackAudioFrame(string channelId, AudioFrame audio_frame)
        {
            return true;
        }</codeblock>
            <codeblock props="rn" outputclass="language-typescript">  onPlaybackAudioFrame?(channelId: string, audioFrame: AudioFrame): boolean;</codeblock>
            <codeblock props="flutter" outputclass="language-dart">final void Function(String channelId, AudioFrame audioFrame)?
      onPlaybackAudioFrame;</codeblock>
            <codeblock props="unreal" outputclass="language-cpp"></codeblock></p>
        </section>
        <section id="detailed_desc">
            <p props="native unity">为保证播放的音频数据格式符合预期，你可以在如下两种方法中任选一种，设置音频的数据格式：                   
                <ul>
                <li>方法一：调用 <xref keyref="setPlaybackAudioFrameParameters"/> 设置音频数据格式后，调用 <xref keyref="registerAudioFrameObserver"/> 注册音频观测器对象，SDK 会根据该方法中的参数计算采样间隔，并根据该采样间隔触发 <apiname keyref="onPlaybackAudioFrame"/> 回调。</li>
                <li>方法二：调用 <xref keyref="registerAudioFrameObserver"/> 注册音频观测器对象后，在 <xref keyref="getObservedAudioFramePosition"/> 回调的返回值中设置具体的音频观测位置，然后在 <xref keyref="getPlaybackAudioParams"/> 回调的返回值中设置音频数据格式，SDK 会根据该回调的返回值计算采样间隔，并根据该采样间隔触发 <apiname keyref="onPlaybackAudioFrame"/> 回调。</li>
                </ul>
            </p> 
            <p props="flutter rn electron">为保证播放的音频数据格式符合预期，你可以在如下方法设置音频的数据格式：调用 <xref keyref="setPlaybackAudioFrameParameters"/> 设置音频数据格式后，调用 <xref keyref="registerAudioFrameObserver"/> 注册音频观测器对象，SDK 会根据该方法中的参数计算采样间隔，并根据该采样间隔触发 <apiname keyref="onPlaybackAudioFrame"/> 回调。</p> 
            <note type="note" id="attention" props="native unity flutter"><ul>
                <li props="native unity">方法一的优先级高于方法二，如果使用方法一设置音频数据格式，方法二设置无效。</li>
                <li props="flutter">由于 Flutter 框架的限制，该回调不支持将处理后的音频数据发送回 SDK。</li>
            </ul></note></section>
        <section id="parameters" conkeyref="onMixedAudioFrame/parameters"/>
        <section id="return_values" conkeyref="onMixedAudioFrame/return_values"/>
    </refbody>
</reference>
