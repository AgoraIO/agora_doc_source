<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="callback_ivideoframeobserver_oncapturevideoframe">
    <title><ph keyref="onCaptureVideoFrame"/></title>
    <shortdesc id="short"><ph id="shortdesc">获取本地设备采集到的视频数据。</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="onCaptureVideoFrame"/>
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">boolean onCaptureVideoFrame(int sourceType, VideoFrame videoFrame);</codeblock>
            <codeblock props="ios mac" outputclass="language-objectivec">- (BOOL)onCaptureVideoFrame:(AgoraOutputVideoFrame * _Nonnull)videoFrame sourceType:(AgoraVideoSourceType)sourceType;</codeblock>
            <codeblock props="cpp unreal" outputclass="language-cpp">virtual bool onCaptureVideoFrame(agora::rtc::VIDEO_SOURCE_TYPE sourceType, VideoFrame&amp; videoFrame) = 0;</codeblock>
         <codeblock props="bp" outputclass="language-cpp">DECLARE_DYNAMIC_MULTICAST_DELEGATE_TwoParams(FOnCaptureVideoFrame, EVIDEO_SOURCE_TYPE, sourceType, const FVideoFrame&amp;, videoFrame);</codeblock>
            <codeblock props="electron" outputclass="language-typescript">onCaptureVideoFrame?(
    sourceType: VideoSourceType,
    videoFrame: VideoFrame
  ): void;</codeblock>
            <codeblock props="unity cs" outputclass="language-csharp">public virtual bool OnCaptureVideoFrame(VIDEO_SOURCE_TYPE sourceType, VideoFrame videoFrame)</codeblock>
            <codeblock props="rn" outputclass="language-typescript">onCaptureVideoFrame?(
    sourceType: VideoSourceType,
    videoFrame: VideoFrame
  ): void;</codeblock>
            <codeblock props="flutter" outputclass="language-dart">final void Function(VideoSourceType sourceType, VideoFrame videoFrame)?
      onCaptureVideoFrame;</codeblock>
            <codeblock props="reserve" outputclass="language-cpp"></codeblock></p>
        </section>
        <section id="detailed_desc" deliveryTarget="details" otherprops="no-title">
            <p props="native unreal bp unity cs">你可以在回调中获取本地设备采集到的原始视频数据，并可根据需要进行前处理。完成前处理后，你可以在该回调中直接修改 <parmname>videoFrame</parmname>，并将返回值设置为 <codeph><ph keyref="true"/></codeph>，即可将修改后的视频数据发送给 SDK。</p>
            <p props="native unreal bp">如果你需要将处理后的数据发送给 SDK，需要先调用 <xref keyref="getVideoFrameProcessMode"/><codeph>(0)</codeph> 方法，将视频处理模式设置为读写模式。</p>
            <p props="flutter rn electron">你可以在回调中获取本地设备采集到的原始视频数据。</p>
        </section>
        <section id="scenario" deliveryTarget="details">
            <title>适用场景</title>
            <ul>
            <li props="native unreal bp unity electron rn cs">在本地采集的视频数据被 SDK 处理之前对其进行前处理。例如：通过该回调中获取视频数据，并对其进行滤镜、水印、裁剪、旋转等处理。</li>
            <li>获取本地采集的视频数据被 SDK 处理之前的信息。例如：视频帧的原始宽度、高度、帧率等。</li></ul>
        </section>
        <section id="timing" deliveryTarget="details">
            <title>触发时机</title>
            <p>成功注册视频数据观测器后，SDK 捕捉到每个视频帧时。</p>
        </section>        
        <section id="restriction" deliveryTarget="details">
            <title>使用限制</title>
            <ul>
                <li>此处获取的视频数据为原始视频数据，即：未经过水印、裁剪和旋转等前处理的视频数据。</li>
                <li>如果你获取到的视频数据类型为 RGBA，SDK 不支持对 Alpha 通道的值进行处理。</li>
                <li props="rn electron">建议你通过 C++ API 实现该回调。</li>
                <li props="flutter rn electron">由于框架的限制，该回调不支持将处理后的视频数据发送回 SDK。</li>
            </ul>
        </section>
        <section id="parameters">
            <title>参数</title>
            <parml>
                <plentry>
                    <pt>sourceType</pt>
                    <pd>视频源类型，可能的视频源包括：摄像头、屏幕或媒体播放器。详见 <xref keyref="VIDEO_SOURCE_TYPE"/> 。</pd>
                </plentry>
            <plentry id="videoframe">
                <pt>videoFrame</pt>
                <pd>视频帧数据。详见 <xref keyref="VideoFrame"/>。
                <note props="native unreal bp rn electron flutter cs">通过该回调获取的视频帧数据格式默认值如下：
                    <ul>
                        <li props="android cpp unreal bp">Android：I420 或 RGB (GLES20.GL_TEXTURE_2D)</li>
                        <li props="ios cpp unreal bp">iOS：I420 或 CVPixelBufferRef</li>
                        <li props="mac cpp unreal bp">macOS：I420 或 CVPixelBufferRef</li>
                        <li props="rn flutter">Android：I420</li>
                        <li props="rn flutter">iOS：I420</li>
                        <li props="electron flutter">macOS：I420</li>
                        <li props="cpp unreal bp electron flutter cs">Windows：YUV420</li></ul></note></pd>
            </plentry>
            </parml> </section>
        <section id="return_values" props="native unreal bp unity cs">
            <title>返回值</title>
            <p id="return">
            <ul>
            <li props="native unreal bp">当视频处理模式为 <apiname keyref="PROCESS_MODE_READ_ONLY"/> 时：

                <ul>
                <li><codeph><ph keyref="true"/></codeph>：无实际含义。</li>
                <li><codeph><ph keyref="false"/></codeph>：无实际含义。</li>
                </ul></li>
            <li props="native unreal bp">当视频处理模式为 <apiname keyref="PROCESS_MODE_READ_WRITE"/> 时：

                <ul>
                <li><codeph><ph keyref="true"/></codeph>：设置 SDK 接收视频帧。</li>
                <li><codeph><ph keyref="false"/></codeph>：设置 SDK 丢弃视频帧。</li>
                </ul></li>
            </ul>
            <ul props="unity cs">
            <li><codeph><ph keyref="true"/></codeph>：设置 SDK 接收视频帧。</li>
            <li><codeph><ph keyref="false"/></codeph>：设置 SDK 丢弃视频帧。</li>
            </ul></p>
        </section>
    </refbody>
</reference>
