<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="class_audiorecordingconfiguration">
    <title> <ph keyref="AudioRecordingConfiguration" /> </title>
    <shortdesc id="short"> <ph id="shortdesc">录音配置。</ph> </shortdesc>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">public class AudioRecordingConfiguration {
  public String filePath;
  public int sampleRate;
  public boolean codec;
  public int fileRecordOption;
  public int quality;
  int recordingChannel;

  public AudioRecordingConfiguration() {
    sampleRate = 32000;
    codec = true;
    fileRecordOption = Constants.AUDIO_FILE_RECORDING_MIXED;
    quality = Constants.AUDIO_RECORDING_QUALITY_MEDIUM;
    recordingChannel = 1;
  }
}</codeblock>
            <codeblock props="ios mac" outputclass="language-objectivec">__attribute__((visibility("default"))) @interface AgoraAudioRecordingConfiguration: NSObject
@property (copy, nonatomic) NSString * _Nullable filePath;
@property (assign, nonatomic) BOOL codec;
@property (assign, nonatomic) NSUInteger sampleRate;
@property (assign, nonatomic) AgoraAudioFileRecordingType fileRecordOption;
@property (assign, nonatomic) AgoraAudioRecordingQuality quality;
@property (assign, nonatomic) NSInteger recordingChannel;
@end</codeblock>
            <codeblock props="cpp" outputclass="language-cpp">struct AudioRecordingConfiguration {
  const char* filePath;
  bool encode;
  int sampleRate;
  AUDIO_FILE_RECORDING_TYPE fileRecordingType;
  AUDIO_RECORDING_QUALITY_TYPE quality;
  int recordingChannel;

  AudioRecordingConfiguration()
    : filePath(NULL),
      encode(false),
      sampleRate(32000),
      fileRecordingType(AUDIO_FILE_RECORDING_MIXED),
      quality(AUDIO_RECORDING_QUALITY_LOW),
      recordingChannel(1) {}

  AudioRecordingConfiguration(const char* file_path, int sample_rate, AUDIO_RECORDING_QUALITY_TYPE quality_type)
    : filePath(file_path),
      encode(false),
      sampleRate(sample_rate),
      fileRecordingType(AUDIO_FILE_RECORDING_MIXED),
      quality(quality_type),
      recordingChannel(channel) {}

  AudioRecordingConfiguration(const char* file_path, bool enc, int sample_rate, AUDIO_FILE_RECORDING_TYPE type, AUDIO_RECORDING_QUALITY_TYPE quality_type)
    : filePath(file_path),
      encode(enc),
      sampleRate(sample_rate),
      fileRecordingType(type),
      quality(quality_type),
      recordingChannel(channel) {}

  AudioRecordingConfiguration(const AudioRecordingConfiguration &amp;rhs)
    : filePath(rhs.filePath),
      encode(rhs.encode),
      sampleRate(rhs.sampleRate),
      fileRecordingType(rhs.fileRecordingType),
      quality(rhs.quality),
      recordingChannel(rhs.recordingChannel) {}
};</codeblock>
            <codeblock props="electron" outputclass="language-typescript">export class AudioRecordingConfiguration {
  
  filePath?: string;
  
  encode?: boolean;
  
  sampleRate?: number;
  
  fileRecordingType?: AudioFileRecordingType;
  
  quality?: AudioRecordingQualityType;
  
  recordingChannel?: number;
}</codeblock>
            <codeblock props="unity" outputclass="language-csharp">public class AudioRecordingConfiguration
    {
        public AudioRecordingConfiguration()
        {
            filePath = "";
            encode = false;
            sampleRate = 32000;
            fileRecordingType = AUDIO_FILE_RECORDING_TYPE.AUDIO_FILE_RECORDING_MIXED;
            quality = AUDIO_RECORDING_QUALITY_TYPE.AUDIO_RECORDING_QUALITY_LOW;
            recordingChannel = 1;
        }

        public AudioRecordingConfiguration(string file_path, int sample_rate, AUDIO_RECORDING_QUALITY_TYPE quality_type, int channel)
        {
            this.filePath = file_path;
            this.encode = false;
            this.sampleRate = sample_rate;
            this.fileRecordingType = AUDIO_FILE_RECORDING_TYPE.AUDIO_FILE_RECORDING_MIXED;
            this.quality = quality_type;
            recordingChannel = channel;
        }

        public AudioRecordingConfiguration(string file_path, bool enc, int sample_rate,
                                        AUDIO_FILE_RECORDING_TYPE type, AUDIO_RECORDING_QUALITY_TYPE quality_type, int channel)
        {
            this.filePath = file_path;
            this.encode = enc;
            this.sampleRate = sample_rate;
            this.fileRecordingType = type;
            this.quality = quality_type;
            this.recordingChannel = channel;
        }

        public string filePath { set; get; }
        public bool encode { set; get; }
        public int sampleRate { set; get; }
        public AUDIO_FILE_RECORDING_TYPE fileRecordingType { set; get; }
        public AUDIO_RECORDING_QUALITY_TYPE quality { set; get; }
        public int recordingChannel { set; get; }
    };</codeblock>
            <codeblock props="rn" outputclass="language-typescript">export class AudioRecordingConfiguration {
  
  filePath?: string;
  
  encode?: boolean;
  
  sampleRate?: number;
  
  fileRecordingType?: AudioFileRecordingType;
  
  quality?: AudioRecordingQualityType;
  
  recordingChannel?: number;
}</codeblock>
            <codeblock props="flutter" outputclass="language-dart">class AudioRecordingConfiguration {
  const AudioRecordingConfiguration(
      {this.filePath,
      this.encode,
      this.sampleRate,
      this.fileRecordingType,
      this.quality,
      this.recordingChannel});

  @JsonKey(name: 'filePath')
  final String? filePath;

  @JsonKey(name: 'encode')
  final bool? encode;

  @JsonKey(name: 'sampleRate')
  final int? sampleRate;

  @JsonKey(name: 'fileRecordingType')
  final AudioFileRecordingType? fileRecordingType;

  @JsonKey(name: 'quality')
  final AudioRecordingQualityType? quality;

  @JsonKey(name: 'recordingChannel')
  final int? recordingChannel;

  factory AudioRecordingConfiguration.fromJson(Map&lt;String, dynamic> json) =>
      _$AudioRecordingConfigurationFromJson(json);

  Map&lt;String, dynamic> toJson() => _$AudioRecordingConfigurationToJson(this);
}</codeblock>            
            <codeblock props="unreal" outputclass="language-cpp"></codeblock></p>
        </section>
        <section id="parameters">
            <title><text conref="../conref/conref_api_metadata.dita#conref_api_metadata/property" /></title>
            <parml>
            <plentry id="filepath">
                <pt>filePath</pt>
                <pd>录音文件在本地保存的绝对路径，需精确到文件名及格式。例如：<codeph><ph keyref="filePath-example" /></codeph>。



                    
                    <note id="note_scm_klz_mqb" type="attention">
                    <p>请确保你指定的路径存在并且可写。</p>
                    </note> </pd>
            </plentry>
            <plentry>
                <pt props="cpp unity electron rn flutter">encode</pt>
                <pt props="android ios mac">codec</pt>
                <pd>设置是否编码音频数据：


                    
                    <ul id="ul_bnv_mlz_mqb">
                    <li><codeph><ph keyref="true" /></codeph>: 将音频数据用 AAC 编码。</li>
                    <li><codeph><ph keyref="false" /></codeph>:（默认）不编码音频数据，直接保存录制的音频数据。</li>
                    </ul></pd>
            </plentry>
            <plentry>
                <pt>sampleRate</pt>
                <pd>录音采样率（Hz）。


                    
                    <ul id="ul_pqs_slz_mqb">
                    <li>16000</li>
                    <li>32000 （默认）</li>
                    <li>44100</li>
                    <li>48000</li>
                    </ul>
                    <note type="attention" id="note_gdq_zlz_mqb">
                    <p>如果把该参数设为 44100 或 48000，为保证录音效果，Agora 推荐录制 WAV 文件或 <parmname>quality</parmname> 为 <ph keyref="AUDIO_RECORDING_QUALITY_MEDIUM" /> 或 <ph keyref="AUDIO_RECORDING_QUALITY_HIGH" /> 的 AAC 文件。</p>
                    </note></pd>
            </plentry>
            <plentry>
                <pt props="cpp unity electron rn flutter">fileRecordingType</pt>
                <pt props="android ios mac">fileRecordOption</pt>
                <pd>
                    <p props="ios mac cpp unity flutter electron rn">录音内容。详见 <xref keyref="AUDIO_FILE_RECORDING_TYPE" />。</p>
                    <p props="android">录音内容：



                    
                    <ul>
                    <li><ph keyref="AUDIO_FILE_RECORDING_MIC" /> (1)：仅录制本地用户的音频。</li>
                    <li><ph keyref="AUDIO_FILE_RECORDING_PLAYBACK" /> (2)：仅录制所有远端用户的音频。</li>
                    <li><ph keyref="AUDIO_FILE_RECORDING_MIXED" /> (3): （默认）录制本地和所有远端用户混音后的音频。</li>
                    </ul> </p>
                </pd>
            </plentry>
            <plentry>
                <pt>quality</pt>
                <pd>
                    <p props="ios mac cpp unity electron rn flutter">录音音质。详见 <xref keyref="AUDIO_RECORDING_QUALITY_TYPE" />。</p>
                    <p props="android">录音音质：
                    <ul>
                    <li><ph keyref="AUDIO_RECORDING_QUALITY_LOW" /> (0)：低音质。例如，采样率为 32000 Hz，录音时长为 10 分钟的 AAC 文件大小约为 1.2 MB。</li>
                    <li><ph keyref="AUDIO_RECORDING_QUALITY_MEDIUM" /> (1)：（默认）中音质。例如，采样率为 32000 Hz，录音时长为 10 分钟的 AAC 文件大小约为 2 MB。</li>
                    <li><ph keyref="AUDIO_RECORDING_QUALITY_HIGH" /> (2)：高音质。例如，采样率为 32000 Hz，录音时长为 10 分钟的 AAC 文件大小约为 3.75 MB。</li>
                        <li><ph keyref="AUDIO_RECORDING_QUALITY_ULTRA_HIGH" />(3)：超高音质。例如，采样率为 32000 Hz，录制 10 分钟的文件大小约为 7.5 M 左右。</li>
                    </ul> </p>
                    <note id="note_hrx_mmz_mqb" type="attention">
                    <p>该参数仅适用于 AAC 文件。</p>
                    </note> </pd>
            </plentry>
                <plentry>
                    <pt>recordingChannel</pt>
                    <pd>录制的音频声道。目前支持如下取值：
                        <ul><li>1:（默认）单声道。</li>
                        <li>2: 双声道。</li></ul>
                        <note type="note"><p>实际录制的音频声道与你采集的音频声道有关：
                            <ul>
                                <li>如果采集的音频为单声道，<parmname>recordingChannel</parmname> 设为 <codeph>2</codeph>， 则录制的音频为经过单声道数据拷贝后的双声道数据，而不是立体声。</li>
                                <li>如果采集的音频为双声道，<parmname>recordingChannel</parmname> 设为 <codeph>1</codeph>，则录制的音频为经过双声道数据混合后的单声道数据。</li></ul>
                            <ph>此外，集成方案也会影响最终录制的音频声道。因此，如果你希望录制立体声，请<xref keyref="ticket-link" />协助。</ph></p></note>
</pd>
                </plentry>
            </parml> </section>
    </refbody>
</reference>