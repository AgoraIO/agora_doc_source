<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="class_remotevideostats">
    <title><ph keyref="RemoteVideoStats" /></title>
    <shortdesc id="short"><ph id="shortdesc">远端视频流的统计信息。</ph></shortdesc>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">public static class RemoteVideoStats {
    public int uid;
    public int delay;
    public int width;
    public int height;
    public int receivedBitrate;
    public int decoderOutputFrameRate;
    public int rendererOutputFrameRate;
    public int frameLossRate;
    public int packetLossRate;
    public int rxStreamType;
    public int totalFrozenTime;
    public int frozenRate;
    public int avSyncTimeMs;
    public long totalActiveTime;
    public long publishDuration;
    public int superResolutionType;
  }</codeblock>
            <codeblock props="ios mac" outputclass="language-objectivec">__attribute__((visibility("default"))) @interface AgoraRtcRemoteVideoStats : NSObject
@property(assign, nonatomic) NSUInteger uid;
@property(assign, nonatomic) NSUInteger delay __deprecated;
@property(assign, nonatomic) NSUInteger width;
@property(assign, nonatomic) NSUInteger height;
@property(assign, nonatomic) NSUInteger receivedBitrate;
@property(assign, nonatomic) NSUInteger receivedFrameRate;
@property(assign, nonatomic) AgoraVideoStreamType rxStreamType;
@property(assign, nonatomic) NSInteger decoderOutputFrameRate;
@property(assign, nonatomic) NSInteger rendererOutputFrameRate;
@property(assign, nonatomic) NSInteger frameLossRate;
@property(assign, nonatomic) NSInteger packetLossRate;
@property(assign, nonatomic) NSInteger totalFrozenTime;
@property(assign, nonatomic) NSInteger frozenRate;
@property(assign, nonatomic) NSUInteger totalActiveTime;
@property(assign, nonatomic) NSInteger publishDuration;
@property(assign, nonatomic) NSInteger avSyncTimeMs;
@property(assign, nonatomic) NSInteger superResolutionType;
@end</codeblock>
            <codeblock props="cpp" outputclass="language-cpp">struct RemoteVideoStats {
  uid_t uid;
  int delay;
  int width;
  int height;
  int receivedBitrate;
  int decoderOutputFrameRate;
  int rendererOutputFrameRate;
  int frameLossRate;
  int packetLossRate;
  VIDEO_STREAM_TYPE rxStreamType;
  int totalFrozenTime;
  int frozenRate;
  int avSyncTimeMs;
  int totalActiveTime;
  int publishDuration;
  int superResolutionType;
};</codeblock>
            <codeblock props="electron" outputclass="language-typescript">export class RemoteVideoStats {

  uid?: number;

  delay?: number;

  width?: number;

  height?: number;

  receivedBitrate?: number;

  decoderOutputFrameRate?: number;

  rendererOutputFrameRate?: number;

  frameLossRate?: number;

  packetLossRate?: number;

  rxStreamType?: VideoStreamType;

  totalFrozenTime?: number;

  frozenRate?: number;

  avSyncTimeMs?: number;

  totalActiveTime?: number;

  publishDuration?: number;

  superResolutionType?: number;
}</codeblock>
            <codeblock props="unity" outputclass="language-csharp">public class RemoteVideoStats
    {
        public uint uid { set; get; }
        public int delay { set; get; }
        public int width { set; get; }
        public int height { set; get; }
        public int receivedBitrate { set; get; }
        public int decoderOutputFrameRate { set; get; }
        public int rendererOutputFrameRate { set; get; }
        public int frameLossRate { set; get; }
        public int packetLossRate { set; get; }
        public VIDEO_STREAM_TYPE rxStreamType { set; get; }
        public int totalFrozenTime { set; get; }
        public int frozenRate { set; get; }
        public int avSyncTimeMs { set; get; }
        public int totalActiveTime { set; get; }
        public int publishDuration { set; get; }
        public int superResolutionType { set; get; }
    }</codeblock>
            <codeblock props="rn" outputclass="language-typescript">export class RemoteVideoStats {

  uid?: number;

  delay?: number;

  width?: number;

  height?: number;

  receivedBitrate?: number;

  decoderOutputFrameRate?: number;

  rendererOutputFrameRate?: number;

  frameLossRate?: number;

  packetLossRate?: number;

  rxStreamType?: VideoStreamType;

  totalFrozenTime?: number;

  frozenRate?: number;

  avSyncTimeMs?: number;

  totalActiveTime?: number;

  publishDuration?: number;

  superResolutionType?: number;
}</codeblock>
            <codeblock props="flutter" outputclass="language-dart">class RemoteVideoStats {
  const RemoteVideoStats(
      {this.uid,
      this.delay,
      this.width,
      this.height,
      this.receivedBitrate,
      this.decoderOutputFrameRate,
      this.rendererOutputFrameRate,
      this.frameLossRate,
      this.packetLossRate,
      this.rxStreamType,
      this.totalFrozenTime,
      this.frozenRate,
      this.avSyncTimeMs,
      this.totalActiveTime,
      this.publishDuration,
      this.superResolutionType});

  @JsonKey(name: 'uid')
  final int? uid;
  @JsonKey(name: 'delay')
  final int? delay;
  @JsonKey(name: 'width')
  final int? width;
  @JsonKey(name: 'height')
  final int? height;
  @JsonKey(name: 'receivedBitrate')
  final int? receivedBitrate;
  @JsonKey(name: 'decoderOutputFrameRate')
  final int? decoderOutputFrameRate;
  @JsonKey(name: 'rendererOutputFrameRate')
  final int? rendererOutputFrameRate;
  @JsonKey(name: 'frameLossRate')
  final int? frameLossRate;
  @JsonKey(name: 'packetLossRate')
  final int? packetLossRate;
  @JsonKey(name: 'rxStreamType')
  final VideoStreamType? rxStreamType;
  @JsonKey(name: 'totalFrozenTime')
  final int? totalFrozenTime;
  @JsonKey(name: 'frozenRate')
  final int? frozenRate;
  @JsonKey(name: 'avSyncTimeMs')
  final int? avSyncTimeMs;
  @JsonKey(name: 'totalActiveTime')
  final int? totalActiveTime;
  @JsonKey(name: 'publishDuration')
  final int? publishDuration;
  @JsonKey(name: 'superResolutionType')
  final int? superResolutionType;
  factory RemoteVideoStats.fromJson(Map&lt;String, dynamic&gt; json) =&gt;
      _$RemoteVideoStatsFromJson(json);
  Map&lt;String, dynamic&gt; toJson() =&gt; _$RemoteVideoStatsToJson(this);
}</codeblock>            
            <codeblock props="reserve" outputclass="language-cpp"></codeblock></p>
        </section>
        <section id="parameters">
            <title><text conref="../conref/conref_api_metadata.dita#conref_api_metadata/property" /></title>
            <parml>
            <plentry>
                <pt>uid</pt>
                <pd>用户 ID，指定是哪个用户的视频流。</pd>
            </plentry>
            <plentry>
                <pt>delay</pt>
                <pd>
                    <dl outputclass="deprecated">
                    <dlentry>
                        <dt>弃用：</dt>
                        <dd>在有音画同步机制的音视频场景中，你可以参考 <xref keyref="RemoteAudioStats" /> 里的 <parmname>networkTransportDelay</parmname> 和 <parmname>jitterBufferDelay</parmname> 成员的值，了解视频的延迟数据。</dd>
                    </dlentry>
                    </dl>
                    <p>延时（毫秒）。</p>
                </pd>
            </plentry>
            <plentry>
                <pt>width</pt>
                <pd>视频流宽（像素）。</pd>
            </plentry>
            <plentry>
                <pt>height</pt>
                <pd>视频流高（像素）。</pd>
            </plentry>
            <plentry>
                <pt>receivedBitrate</pt>
                <pd>（上次统计后）接收到的码率(Kbps)。</pd>
            </plentry>
            <plentry props="ios mac">
                <pt>receivedFramerate</pt>
                <pd>（上次统计后）接收到的帧率 (fps)。</pd>
            </plentry>
            <plentry>
                <pt>decoderOutputFrameRate</pt>
                <pd>远端视频解码器的输出帧率，单位为 fps。</pd>
            </plentry>
            <plentry>
                <pt>rendererOutputFrameRate</pt>
                <pd>远端视频渲染器的输出帧率，单位为 fps。</pd>
            </plentry>
            <plentry>
                <pt>frameLossRate</pt>
                <pd>远端视频丢包率(%)。</pd>
            </plentry>
            <plentry>
                <pt>packetLossRate</pt>
                <pd>远端视频在使用抗丢包技术之后的丢包率(%)。</pd>
            </plentry>
            <plentry>
                <pt>rxStreamType</pt>
                <pd><ph>视频流类型，大流或小流。</ph><ph props="ios mac cpp unity rn electron flutter">详见 <xref keyref="VIDEO_STREAM_TYPE" />。</ph>
                    <p props="android">
                    <ul>
                    <li><ph keyref="VIDEO_STREAM_HIGH" /> (0)：视频大流，即高分辨率高码率的视频流。</li>
                    <li><ph keyref="VIDEO_STREAM_LOW" /> (1)：视频小流，即低分辨率低码率的视频流。</li>
                    </ul> </p>
                </pd>
            </plentry>
            <plentry>
                <pt>totalFrozenTime</pt>
                <pd>远端用户在加入频道后发生视频卡顿的累计时长（ms）。通话过程中，视频帧率设置不低于 5 fps 时，连续渲染的两帧视频之间间隔超过 500 ms，则记为一次视频卡顿。</pd>
            </plentry>
            <plentry>
                <pt>frozenRate</pt>
                <pd>远端用户在加入频道后发生视频卡顿的累计时长占视频总有效时长的百分比 (%)。视频有效时长是指远端用户加入频道后视频未被停止发送或禁用的时长。</pd>
            </plentry>
            <plentry>
                <pt>totalActiveTime</pt>
                <pd>
                    <p>视频有效时长（毫秒）。</p>
                    <p>视频总有效时长是远端用户或主播加入频道后，既没有停止发送视频流，也没有禁用视频模块的通话时长。</p>
                </pd>
            </plentry>
            <plentry>
                <pt>publishDuration</pt>
                <pd>
                    <p>远端视频流的累计发布时长（毫秒）。</p>
                </pd>
            </plentry>
            <plentry props="unity rn flutter">
                <pt>superResolutionType</pt>
                <pd>超分辨率的开启状态：
                    <ul>
                    <li>&gt;0：超分辨率已开启。</li>
                    <li>=0：超分辨率未开启。</li>
                    </ul> </pd>
            </plentry>
            <plentry>
                <pt>avSyncTimeMs</pt>
                <pd>音频超前视频的时间 (ms)。

                    <note type="attention">如果为负值，则代表音频落后于视频。</note></pd>
            </plentry>
            </parml> </section>
    </refbody>
</reference>