<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="api_irtcengine_startlocalvideotranscoder">
    <title><ph keyref="startLocalVideoTranscoder" /></title>
    <shortdesc id="short"><ph id="shortdesc">开启本地合图。</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="startLocalVideoTranscoder" />
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">public abstract int startLocalVideoTranscoder(LocalTranscoderConfiguration config);</codeblock>
            <codeblock props="ios mac" outputclass="language-objectivec">- (int)startLocalVideoTranscoder:(AgoraLocalTranscoderConfiguration* _Nonnull)config NS_SWIFT_NAME(startLocalVideoTranscoder(_:));</codeblock>
            <codeblock props="cpp unreal" outputclass="language-cpp">virtual int startLocalVideoTranscoder(const LocalTranscoderConfiguration&amp; config) = 0;
</codeblock>
         <codeblock props="bp" outputclass="language-cpp">UFUNCTION(BlueprintCallable, Category = &quot;Agora|RtcEngineProxy&quot;)
	int StartLocalVideoTranscoder(const FLocalTranscoderConfiguration&amp; config);</codeblock>
            <codeblock props="electron" outputclass="language-typescript">abstract startLocalVideoTranscoder(
    config: LocalTranscoderConfiguration
  ): number;</codeblock>
            <codeblock props="unity cs" outputclass="language-csharp">public abstract int StartLocalVideoTranscoder(LocalTranscoderConfiguration config);</codeblock>
            <codeblock props="rn" outputclass="language-typescript">abstract startLocalVideoTranscoder(
    config: LocalTranscoderConfiguration
  ): number;</codeblock>
            <codeblock props="flutter" outputclass="language-dart">Future&lt;void&gt; startLocalVideoTranscoder(LocalTranscoderConfiguration config);</codeblock>
            <codeblock props="reserve" outputclass="language-cpp"></codeblock></p>
        </section>
        <section id="detailed_desc">
            <title>详情</title>
            <p>调用该方法后，你可以在本地将多路视频流合并为一路视频流。例如：将摄像头采集的视频流、屏幕共享流、媒体播放器中的视频流、远端视频流、视频文件、图片等合并为一路视频流，然后将已合图的视频流发布到频道中。</p>
                <note>
                <ul>
                    <li>本地合图对 CPU 的消耗较高，声网建议你在性能较高的设备上开启该功能。</li>
                    <li>如果你需要对本地采集的视频流进行合图，SDK 支持如下采集组合：<ul>
                        <li props="cpp unreal bp electron unity cs flutter">在 Windows 平台上，最多支持 4 路摄像头采集的视频流 + 4 路屏幕共享流合图。</li>
                        <li props="cpp unreal bp mac unity electron flutter">在 macOS 平台上，最多支持 4 路摄像头采集的视频流 + 1 路屏幕共享流合图。</li>
                        <li props="cpp unreal bp unity rn flutter">在 Android 和 iOS 平台上，最多支持 2 路摄像头采集的视频流（需要设备本身支持双摄或支持外接摄像头）+ 1 路屏幕共享合图。</li>
                        <li props="android">在 Android 平台上，最多支持 2 路摄像头采集的视频流（需要设备本身支持双摄或支持外接摄像头）+ 1 路屏幕共享合图。</li>
                        <li props="ios">在 iOS 平台上，最多支持 2 路摄像头采集的视频流（需要设备本身支持双摄或支持外接摄像头）+ 1 路屏幕共享合图。</li></ul></li>
                    <li>如果你需要对本地采集的视频流进行合图，需要在 <xref keyref="startCameraCapture"/> 或 <xref props="cpp unreal bp mac unity cs flutter electron" keyref="startScreenCapture2"/><xref props="ios android rn" keyref="startScreenCapture"/> 之后调用该方法。</li> 
                    <li>如果你要将合图后的视频流发布到频道中，需要在调用 <xref keyref="joinChannel2"/> 或 <xref keyref="updateChannelMediaOptions"/> 时，将 <xref keyref="ChannelMediaOptions"/> 中的 <parmname>publishTranscodedVideoTrack</parmname> 设置为 <codeph><ph keyref="true"/></codeph>。</li></ul>
                </note>
        </section>
        <section id="scenario">
        <title>适用场景</title>
        <p>你可以在远程会议、直播、在线教育等场景下开启本地合图功能，可以让用户更加方便地查看和管理多个视频画面，同时支持人像画中画等功能。</p>
        <p>以下是一个实现人像画中画的典型场景：
                <ol>
                <li>调用 <xref keyref="enableVirtualBackground"/>，并将自定义背景图设置为 <apiname keyref="BACKGROUND_NONE"/>，即：在摄像头采集的视频中将人像和背景分割。</li>
                <li>调用 <xref props="cpp unreal bp mac unity cs flutter electron" keyref="startScreenCapture2"/><xref props="ios android rn" keyref="startScreenCapture"/>，开始采集屏幕共享视频流。</li>
                <li>调用该方法，并将采集人像的视频源设置为参与本地合图的视频源之一，即可在合图后的视频中实现人像画中画。
                    <note>在进行合图配置时，需确保采集人像的摄像头视频流在合图中的图层编号大于屏幕共享流的图层编号，否则人像会被屏幕共享覆盖、无法显示在最终合图的视频流中。</note></li>
                </ol></p>
        </section>
        <section id="parameters">
            <title>参数</title>
            <parml>
            <plentry>
                <pt>config</pt>
                <pd>本地合图的配置，详见 <xref keyref="LocalTranscoderConfiguration" />。
                <note type="attention"><ul>
                <li>参与本地合图的每一路视频流的分辨率最大为 4096 × 2160，如果超出此限制，会导致合图不生效。</li>
                <li>合图后的视频流最大分辨率为 4096 × 2160。</li></ul></note></pd>
            </plentry>
            </parml> </section>
        <section id="return_values">
            <title><ph keyref="return-section-title"/></title>
            <p props="flutter">方法成功调用时，无返回值；方法调用失败时，会抛出 <xref keyref="AgoraRtcException"/> 异常，你需要捕获异常并进行处理。<ph props="cn">详见<xref keyref="error-code-link"/>了解详情和解决建议。</ph></p>
            <ul id="ul_ahk_23f_3qb">
            <li props="native unreal bp electron unity cs rn">0: 方法调用成功。</li>
            <li>&lt; 0: 方法调用失败。<ph props="cn">详见<xref keyref="error-code-link"/>了解详情和解决建议。</ph></li>
            </ul> </section>
    </refbody>
</reference>
