<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="api_irtcengine_setearmonitoringaudioframeparameters">
    <title><ph keyref="setEarMonitoringAudioFrameParameters"/></title>
    <shortdesc id="short"><ph id="shortdesc">设置耳返原始音频数据的格式。</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="setEarMonitoringAudioFrameParameters"/>
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">public abstract int setEarMonitoringAudioFrameParameters(int sampleRate, int channel, int mode, int samplesPerCall);</codeblock>
            <codeblock props="hmos" outputclass="language-arkts"/>
            <codeblock props="ios mac" outputclass="language-objectivec">- (int)setEarMonitoringAudioFrameParametersWithSampleRate:(NSInteger)sampleRate
                                                   channel:(NSInteger)channel
                                                      mode:(AgoraAudioRawFrameOperationMode)mode
                                            samplesPerCall:(NSInteger)samplesPerCall NS_SWIFT_NAME(setEarMonitoringAudioFrameParametersWithSampleRate(_:channel:mode:samplesPerCall:));</codeblock>
            <codeblock props="cpp unreal" outputclass="language-cpp">virtual int setEarMonitoringAudioFrameParameters(int sampleRate, int channel, RAW_AUDIO_FRAME_OP_MODE_TYPE mode, int samplesPerCall) = 0;</codeblock>
         <codeblock props="bp" outputclass="language-cpp">UFUNCTION(BlueprintCallable, Category = "Agora|IRtcEngine")
	int SetEarMonitoringAudioFrameParameters(int sampleRate, int channel, ERAW_AUDIO_FRAME_OP_MODE_TYPE mode, int samplesPerCall);</codeblock>
            <codeblock props="electron" outputclass="language-typescript">abstract setEarMonitoringAudioFrameParameters(
    sampleRate: number,
    channel: number,
    mode: RawAudioFrameOpModeType,
    samplesPerCall: number
  ): number;</codeblock>
            <codeblock props="unity cs" outputclass="language-csharp">public abstract int SetEarMonitoringAudioFrameParameters(int sampleRate, int channel, RAW_AUDIO_FRAME_OP_MODE_TYPE mode, int samplesPerCall);</codeblock>
            <codeblock props="rn" outputclass="language-typescript">abstract setEarMonitoringAudioFrameParameters(
    sampleRate: number,
    channel: number,
    mode: RawAudioFrameOpModeType,
    samplesPerCall: number
  ): number;</codeblock>
            <codeblock props="flutter" outputclass="language-dart">Future&lt;void&gt; setEarMonitoringAudioFrameParameters(
      {required int sampleRate,
      required int channel,
      required RawAudioFrameOpModeType mode,
      required int samplesPerCall});</codeblock>
            <codeblock props="reserve" outputclass="language-cpp"/></p>
        </section>
        <section id="detailed_desc">
            <title>详情</title>
            <p>该方法用于设置通过 <xref keyref="onEarMonitoringAudioFrame"/> 回调上报的耳返音频数据格式。<xref keyref="onEarMonitoringAudioFrame"/> 回调的耳返音频数据格式。</p>
            <note type="attention">
            <ul>
            <li>调用该方法前，你需要先调用 <xref keyref="enableInEarMonitoring2"/>，将 <parmname>includeAudioFilters</parmname> 设置为 <apiname keyref="EAR_MONITORING_FILTER_BUILT_IN_AUDIO_FILTERS"/> 或 <apiname keyref="EAR_MONITORING_FILTER_NOISE_SUPPRESSION"/>。</li>
            <li>SDK 会通过该方法中的 <parmname>samplesPerCall</parmname>、<parmname>sampleRate</parmname> 和 <parmname>channel</parmname> 参数计算出采样间隔，计算公式为<equation-inline>采样间隔 = <parmname>samplesPerCall</parmname>/(<parmname>sampleRate</parmname> × <parmname>channel</parmname>)</equation-inline>。请确保采样间隔不小于 0.01 秒。<ph>SDK 会根据该采样间隔触发 <apiname keyref="onEarMonitoringAudioFrame"/> 回调。</ph></li>
            </ul></note> <note type="attention" props="cpp"><ul>
                        <li>在调用该方法前，需要先调用 <xref keyref="enableInEarMonitoring2"/>，并将 <codeph>includeAudioFilters</codeph> 设置为 <ph keyref="EAR_MONITORING_FILTER_BUILT_IN_AUDIO_FILTERS"/> 或 <ph keyref="EAR_MONITORING_FILTER_NOISE_SUPPRESSION"/>。</li>
                        <li>SDK 会根据该方法中设置的 <codeph>samplesPerCall</codeph>、<codeph>sampleRate</codeph> 和 <codeph>channel</codeph> 参数计算采样间隔。采样间隔（秒）= <codeph>samplesPerCall / (sampleRate × channel)</codeph>。请确保采样间隔 ≥ 0.01 秒。SDK 会根据采样间隔触发 <xref keyref="onEarMonitoringAudioFrame"/> 回调。</li>
                        </ul>
                    </note>
            <note type="attention" props="apple"><ul>
                        <li>在调用该方法前，需要先调用 <xref keyref="enableInEarMonitoring2"/> 方法，并将 <codeph>includeAudioFilters</codeph> 设置为 <ph keyref="EAR_MONITORING_FILTER_BUILT_IN_AUDIO_FILTERS"/> 或 <ph keyref="EAR_MONITORING_FILTER_NOISE_SUPPRESSION"/>。</li>
                        <li>SDK 会根据该方法中设置的 <codeph>samplesPerCall</codeph>、<codeph>sampleRate</codeph> 和 <codeph>channel</codeph> 参数计算采样间隔。采样间隔（秒）= <codeph>samplesPerCall</codeph> / (<codeph>sampleRate</codeph> × <codeph>channel</codeph>)。请确保采样间隔 ≥ 0.01 秒。SDK 会根据采样间隔触发 <xref keyref="onEarMonitoringAudioFrame"/> 回调。</li>
                        </ul>
                    </note>
            <note type="attention" props="android"><ul>
                        <li>在调用该方法前，需要先调用 <xref keyref="enableInEarMonitoring2"/> 方法，并将 <codeph>includeAudioFilters</codeph> 设置为 <ph keyref="EAR_MONITORING_FILTER_BUILT_IN_AUDIO_FILTERS"/> 或 <ph keyref="EAR_MONITORING_FILTER_NOISE_SUPPRESSION"/>。</li>
                        <li>SDK 会根据该方法中设置的 <codeph>samplesPerCall</codeph>、<codeph>sampleRate</codeph> 和 <codeph>channel</codeph> 参数计算采样间隔。采样间隔（秒） = <codeph>samplesPerCall</codeph> / (<codeph>sampleRate</codeph> × <codeph>channel</codeph>)。请确保采样间隔 ≥ 0.01 秒。SDK 会根据采样间隔触发 <xref keyref="onEarMonitoringAudioFrame"/> 回调。</li>
                        </ul>
                    </note>
            </section>
        <section id="parameters">
            <title>参数</title>
            <parml>
            <plentry>
                <pt>sampleRate</pt>
                <pd props="bp cs electron flutter mac rn unity unreal"><apiname keyref="onEarMonitoringAudioFrame"/> 中报告音频的采样率 (Hz)，可设置为 8000、 16000、 32000、44100 或 48000。</pd>
            <pd props="android"><xref keyref="onEarMonitoringAudioFrame"/> 回调中上报的音频数据的采样率。可设置为 8000、16000、32000、44100 或 48000 Hz。</pd>
                <pd props="ios"><xref keyref="onEarMonitoringAudioFrame"/> 回调中上报的音频数据的采样率，可设置为 8000、16000、32000、44100 或 48000 Hz。</pd>
                <pd props="cpp"><xref keyref="onEarMonitoringAudioFrame"/> 回调中上报的音频数据的采样率，单位为 Hz。可设置为 8000、16000、32000、44100 或 48000。</pd>
                </plentry>
            <plentry>
                <pt>channel</pt>
                <pd props="bp cs electron flutter mac rn unity unreal">
                    <p><apiname keyref="onEarMonitoringAudioFrame"/> 中报告音频的声道数，可设置为 1 或 2:

                    <ul>
                    <li>1: 单声道。</li>
                    <li>2: 双声道。</li>
                    </ul></p>
                </pd>
            <pd props="android ios"><xref keyref="onEarMonitoringAudioFrame"/> 回调中上报的音频声道数：
                    <ul>
                        <li>1：单声道。</li>
                        <li>2：双声道。</li>
                        </ul>
                    </pd>
                <pd props="cpp"><xref keyref="onEarMonitoringAudioFrame"/> 回调中上报的音频数据的声道数：
                    <ul>
                        <li>1：单声道。</li>
                        <li>2：双声道。</li>
                        </ul>
                    </pd>
                </plentry>
            <plentry>
                <pt>mode</pt>
                <pd props="bp cs electron flutter mac rn unity unreal">
                    <p props="apple cpp framework hmos">音频帧的使用模式，详见 <xref keyref="RAW_AUDIO_FRAME_OP_MODE_TYPE"/>。</p>
                    <p props="android" conkeyref="registerAudioFrameObserver2_IMediaPlayer/mode"/>
                </pd>
            <pd props="android">音频帧的使用模式：
                    <ul>
                        <li><ph keyref="RAW_AUDIO_FRAME_OP_MODE_READ_ONLY"/>（0）：（默认）只读模式。例如，用户通过声网 SDK 获取数据后推送 RTMP 或 RTMPS 流。</li>
                        <li><ph keyref="RAW_AUDIO_FRAME_OP_MODE_READ_WRITE"/>（2）：读写模式。用户从 <xref keyref="AudioFrame"/> 中读取数据并进行修改后播放。例如，用户有自己的音效处理模块并进行语音预处理，如变声。</li>
                        </ul>
                    </pd>
                <pd props="cpp ios">音频帧的使用模式，详见 <xref keyref="RAW_AUDIO_FRAME_OP_MODE_TYPE"/>。</pd>
                </plentry>
            <plentry>
                <pt>samplesPerCall</pt>
                <pd props="bp cs electron flutter mac rn unity unreal"><apiname keyref="onEarMonitoringAudioFrame"/> 中报告的音频的采样点数，如旁路推流应用中通常为 1024。</pd>
            <pd props="android"><xref keyref="onEarMonitoringAudioFrame"/> 回调中上报的数据采样数，例如媒体推流场景中为 1024。</pd>
                <pd props="ios"><xref keyref="onEarMonitoringAudioFrame"/> 回调中上报的数据采样数，例如媒体推流时为 1024。</pd>
                <pd props="cpp"><xref keyref="onEarMonitoringAudioFrame"/> 回调中上报的数据采样点数量。例如，媒体推流时通常设置为 1024。</pd>
                </plentry>
        </parml> </section>
        <section id="return_values" props="bp cs electron flutter native rn unity unreal">
            <title><ph keyref="return-section-title"/></title>
        <p props="flutter">方法成功调用时，无返回值；方法调用失败时，会抛出 <xref keyref="AgoraRtcException"/> 异常，你需要捕获异常并进行处理。<ph props="cn">详见<xref keyref="error-code-link"/>了解详情和解决建议。</ph></p>
        <ul>
            <li props="bp cs electron rn unity unreal">0：方法调用成功。</li>
            <li>&lt; 0：方法调用失败。<ph props="cn">详见<xref keyref="error-code-link"/>了解详情和解决建议。</ph></li>
            </ul>
        <p props="native"><ul>
                        <li>0：方法调用成功。</li>
                        <li>&lt; 0：方法调用失败。</li>
                        </ul>
                    </p>
    </section>
    </refbody>
</reference>
