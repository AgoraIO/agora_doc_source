<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="class_audioparams">
    <title><ph keyref="AudioParams"/></title>
    <shortdesc id="short"><ph id="shortdesc">音频数据格式。</ph></shortdesc>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">public class AudioParams {
  public int sampleRate = 0;
  public int channel = 0;
  public int mode = Constants.RAW_AUDIO_FRAME_OP_MODE_READ_ONLY;
  public int samplesPerCall = 0;

  @CalledByNative
  public AudioParams(int sampleRate, int channelCnt, int mode, int samplesPerCall) {
    this.sampleRate = sampleRate;
    this.channel = channelCnt;
    this.mode = mode;
    this.samplesPerCall = samplesPerCall;
  }
}</codeblock>
            <codeblock props="ios mac" outputclass="language-objectivec">__attribute__((visibility("default"))) @interface AgoraAudioParams : NSObject

@property (assign, nonatomic) NSInteger sampleRate;

@property (assign, nonatomic) NSInteger channel;

@property (assign, nonatomic) AgoraAudioRawFrameOperationMode mode;

@property (assign, nonatomic) NSInteger samplesPerCall;

@end</codeblock>
            <codeblock props="cpp" outputclass="language-cpp">struct AudioParams {
  int sample_rate;
  int channels;
  rtc::RAW_AUDIO_FRAME_OP_MODE_TYPE mode;
  int samples_per_call;
  AudioParams() : sample_rate(0), channels(0), mode(rtc::RAW_AUDIO_FRAME_OP_MODE_READ_ONLY), samples_per_call(0) {}
  AudioParams(int samplerate, int channel, rtc::RAW_AUDIO_FRAME_OP_MODE_TYPE type, int samplesPerCall) : sample_rate(samplerate), channels(channel), mode(type), samples_per_call(samplesPerCall) {}
};</codeblock>
            <codeblock props="cs" outputclass="language-csharp"/>
            <codeblock props="electron" outputclass="language-typescript">export class AudioParams {
  
  sample_rate?: number;
  
  channels?: number;
  
  mode?: RawAudioFrameOpModeType;
  
  samples_per_call?: number;
}</codeblock>
            <codeblock props="unity" outputclass="language-csharp">public class AudioParams
    {
        public int sample_rate { set; get; }
        public int channels { set; get; }
        public RAW_AUDIO_FRAME_OP_MODE_TYPE mode { set; get; }
        public int samples_per_call { set; get; }

        public AudioParams()
        {
            sample_rate = 0;
            channels = 0;
            mode = RAW_AUDIO_FRAME_OP_MODE_TYPE.RAW_AUDIO_FRAME_OP_MODE_READ_ONLY;
            samples_per_call = 0;
        }

        public AudioParams(int samplerate, int channel, RAW_AUDIO_FRAME_OP_MODE_TYPE type, int samplesPerCall)
        {
            sample_rate = samplerate;
            channels = channel;
            mode = type;
            samples_per_call = samplesPerCall;
        }
    };</codeblock>
            <codeblock props="rn" outputclass="language-typescript">export class AudioParams {
  
  sample_rate?: number;
  
  channels?: number;
  
  mode?: RawAudioFrameOpModeType;
  
  samples_per_call?: number;
}</codeblock>
            <codeblock props="flutter" outputclass="language-dart">class AudioParams {
  const AudioParams(
      {this.sampleRate, this.channels, this.mode, this.samplesPerCall});

  @JsonKey(name: 'sample_rate')
  final int? sampleRate;

  @JsonKey(name: 'channels')
  final int? channels;

  @JsonKey(name: 'mode')
  final RawAudioFrameOpModeType? mode;

  @JsonKey(name: 'samples_per_call')
  final int? samplesPerCall;

  factory AudioParams.fromJson(Map&lt;String, dynamic> json) =>
      _$AudioParamsFromJson(json);

  Map&lt;String, dynamic> toJson() => _$AudioParamsToJson(this);
}</codeblock>
            <codeblock props="reserve" outputclass="language-cpp"></codeblock></p>
        </section>
        <section id="detailed_desc">
            <p props="native unity">你可以在以下回调的返回值中传入 <apiname keyref="AudioParams"/> 对象，用于设置对应回调报告的音频数据格式：
            <ul>
            <li><xref keyref="getRecordAudioParams"/>：设置 <xref keyref="onRecordAudioFrame"/> 回调的数据格式。</li>
            <li><xref keyref="getPlaybackAudioParams"/>：设置 <xref keyref="onPlaybackAudioFrame"/> 回调的数据格式。</li>
            <li><xref keyref="getMixedAudioParams"/>：设置 <xref keyref="onMixedAudioFrame"/> 回调的数据格式。</li>
            <li><xref keyref="getEarMonitoringAudioParams"/>：设置 <xref keyref="onEarMonitoringAudioFrame"/> 回调的数据格式。</li>    
            </ul></p>
            <p props="electron rn">SDK 会根据 <apiname keyref="AudioParams"/> 设置以下回调中的音频数据格式：
            <ul>
            <li><xref keyref="onRecordAudioFrame"/> </li>
            <li><xref keyref="onPlaybackAudioFrame"/> </li>
            <li><xref keyref="onMixedAudioFrame"/> </li>
            </ul></p>            
            <note type="attention">
            <ul>
            <li>SDK 会通过 <apiname keyref="AudioParams"/> 中的 <parmname>samplesPerCall</parmname>、<parmname>sampleRate</parmname> 和 <parmname>channel</parmname> 参数计算采样间隔，并根据该采样间隔触发 <apiname keyref="onRecordAudioFrame"/>、<apiname keyref="onPlaybackAudioFrame"/>、<apiname keyref="onMixedAudioFrame"/> 和 <apiname keyref="onEarMonitoringAudioFrame"/> 回调。</li>
            <li><equation-inline>采样间隔 = <parmname>samplesPerCall</parmname>/(<parmname>sampleRate</parmname> × <parmname>channel</parmname>)</equation-inline>。</li>
            <li>请确保采样间隔不得小于 0.01 (s)。</li>
            </ul></note> </section>
        <section id="parameters">
            <title><text conref="../conref/conref_api_metadata.dita#conref_api_metadata/property"/></title>
            <parml>
            <plentry>
                <pt props="android ios mac flutter">sampleRate</pt>
                <pt props="cpp unity electron rn">sample_rate</pt>
                <pd>数据的采样率，单位为 Hz，取值如下：
                    
                    <ul>
                    <li>8000</li>
                    <li>16000（默认值）</li>
                    <li>32000</li>
                    <li>44100</li>
                    <li>48000</li>
                    </ul></pd>
            </plentry>
            <plentry>
                <pt props="android ios mac">channel</pt>
                <pt props="cpp unity electron rn flutter">channels</pt>
                <pd>数据的声道数，取值如下：                
                    <ul>
                    <li>1：单声道（默认值）</li>
                    <li>2：双声道</li>
                    </ul></pd>
            </plentry>
            <plentry>
                <pt>mode</pt>
                <pd props="ios mac cpp unity electron rn flutter">数据的使用模式。详见 <xref keyref="RAW_AUDIO_FRAME_OP_MODE_TYPE"/>。</pd>
                <pd props="android">数据的使用模式，取值如下：
                    <ul>
                    <li><ph keyref="RAW_AUDIO_FRAME_OP_MODE_READ_ONLY"/>(0): 只读模式，<ph props="cpp">用户仅从 <xref keyref="AudioFrame"/> 获取原始数据，不作任何修改。</ph>例如: 若用户通过 SDK 采集数据，自己进行旁路推流，则可以选择该模式。</li>
                    <li><ph keyref="RAW_AUDIO_FRAME_OP_MODE_READ_WRITE"/>(2): 读写模式, <ph props="cpp">用户从 <xref keyref="AudioFrame"/> 获取并修改数据，并返回给 SDK 进行编码传输。</ph><ph props="electron">用户修改 SDK 返回的原始视频，并返回给 SDK 进行编码传输。</ph>例如: 若用户自己有音效处理模块，且想要根据实际需要对数据进行前处理(例如变声)，则可以选择该模式。</li>
                    </ul> </pd>
            </plentry>
            <plentry>
                <pt props="android ios mac flutter">samplesPerCall</pt>
                <pt props="cpp unity electron rn">samples_per_call</pt>
                <pd>数据的采样点数，如旁路推流应用中通常为 1024。</pd>
            </plentry>
            </parml> </section>
    </refbody>
</reference>
