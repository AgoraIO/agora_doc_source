<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="class_mixedaudiostream">
    <title><ph keyref="MixedAudioStream"/></title>
    <shortdesc id="short"><ph id="shortdesc">在本地进行合流的音频源。</ph></shortdesc>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">public static class MixedAudioStream {
    public int remoteUserUid;
    public String channelId;
    public Constants.AudioSourceType sourceType;
    public int trackId;
    public MixedAudioStream() {
      this.sourceType = Constants.AudioSourceType.AUDIO_SOURCE_UNKNOWN;
      this.remoteUserUid = 0;
      this.channelId = "";
      this.trackId = 0;
    }
  };</codeblock>
            <codeblock props="hmos" outputclass="language-arkts"/>
            <codeblock props="ios mac" outputclass="language-objectivec">__attribute__((visibility("default"))) @interface AgoraMixedAudioStream: NSObject
@property (assign, nonatomic) AgoraAudioSourceType sourceType;
@property (assign, nonatomic) NSUInteger remoteUserUid;
@property (copy, nonatomic) NSString * _Nullable channelId;
@property (assign, nonatomic) NSUInteger trackId;
@end</codeblock>
            <codeblock props="cpp unreal" outputclass="language-cpp">struct MixedAudioStream {
  AUDIO_SOURCE_TYPE sourceType;
  uid_t remoteUserUid;
  const char* channelId;
  track_id_t trackId;
  MixedAudioStream(AUDIO_SOURCE_TYPE source)
    : sourceType(source),
      remoteUserUid(0),
      channelId(NULL),
      trackId(-1) {}
  MixedAudioStream(AUDIO_SOURCE_TYPE source, track_id_t track)
    : sourceType(source),
      trackId(track) {}
  MixedAudioStream(AUDIO_SOURCE_TYPE source, uid_t uid, const char* channel)
    : sourceType(source),
      remoteUserUid(uid),
      channelId(channel) {}
  MixedAudioStream(AUDIO_SOURCE_TYPE source, uid_t uid, const char* channel, track_id_t track)
    : sourceType(source),
      remoteUserUid(uid),
      channelId(channel),
      trackId(track) {}
};</codeblock>
            <codeblock props="bp" outputclass="language-cpp">USTRUCT(BlueprintType)
struct FUABT_MixedAudioStream {

	GENERATED_BODY()

public:

	UPROPERTY(VisibleAnywhere, BlueprintReadWrite)
	EUABT_AUDIO_SOURCE_TYPE sourceType = EUABT_AUDIO_SOURCE_TYPE::AUDIO_SOURCE_MICROPHONE;

	UPROPERTY(VisibleAnywhere, BlueprintReadWrite)
	int64 remoteUserUid;

	UPROPERTY(VisibleAnywhere, BlueprintReadWrite)
	FString channelName;

	UPROPERTY(VisibleAnywhere, BlueprintReadWrite)
	int64 trackId;
};</codeblock>
            <codeblock props="electron" outputclass="language-typescript">export class MixedAudioStream {
  sourceType?: AudioSourceType;
  remoteUserUid?: number;
  channelId?: string;
  trackId?: number;
}</codeblock>
            <codeblock props="unity cs" outputclass="language-csharp">public class MixedAudioStream
{
    public AUDIO_SOURCE_TYPE sourceType;
    public uint remoteUserUid;
    public string channelId;
    public uint trackId;
    }</codeblock>
            <codeblock props="rn" outputclass="language-typescript">export class MixedAudioStream {
  sourceType?: AudioSourceType;
  remoteUserUid?: number;
  channelId?: string;
  trackId?: number;
}</codeblock>
            <codeblock props="flutter" outputclass="language-dart">class MixedAudioStream {

  const MixedAudioStream(
      {this.sourceType, this.remoteUserUid, this.channelId, this.trackId});

  @JsonKey(name: 'sourceType')
  final AudioSourceType? sourceType;

  @JsonKey(name: 'remoteUserUid')
  final int? remoteUserUid;

  @JsonKey(name: 'channelId')
  final String? channelId;

  @JsonKey(name: 'trackId')
  final int? trackId;

  factory MixedAudioStream.fromJson(Map&lt;String, dynamic> json) =>
      _$MixedAudioStreamFromJson(json);

  Map&lt;String, dynamic> toJson() => _$MixedAudioStreamToJson(this);
}</codeblock> </p>
        </section>
        <section id="detailed_desc">
            <dl outputclass="since">
            <dlentry props="native">
                <dt>自从</dt>
                <dd>v4.5.0</dd>
            </dlentry>
            </dl>
            <p/>
        </section>
        <section id="parameters">
            <title><text conref="../conref/conref_api_metadata.dita#conref_api_metadata/property"/></title>
            <parml>
            <plentry>
                <pt>sourceType</pt>
                <pd>音频源的类型。详见 <xref keyref="AUDIO_SOURCE_TYPE"/>。</pd>
            </plentry>
            <plentry>
              <pt>remoteUserUid</pt>
              <pd>
                  <p>远端用户 ID。</p>
                  <note type="attention">当参与本地音频合流的音频源类型为 <ph keyref="AUDIO_SOURCE_REMOTE_USER" /> 时，需要设置该参数。</note></pd>
          </plentry>
        <plentry>
            <pt>channelId</pt>
            <pd>
              <p conkeyref="joinChannel2/channelID_desc" />
              <note type="attention">当参与本地音频合流的音频源类型为 <ph keyref="AUDIO_SOURCE_REMOTE_CHANNEL" /> 或 <ph keyref="AUDIO_SOURCE_REMOTE_USER" /> 时，需要设置该参数。</note></pd>
        </plentry>
        <plentry>
          <pt>trackId</pt>
          <pd>
            <p>音频轨道 ID。将该参数设置为调用 <apiname keyref="createCustomAudioTrack"/> 方法返回的自定义音频轨道 ID。</p>
            <note type="attention">当参与本地本地音频合流的音频源类型为 <ph keyref="AUDIO_SOURCE_CUSTOM"/> 时，需要设置该参数。</note>
          </pd>
      </plentry>
      </parml> </section>
                </refbody>
</reference>
