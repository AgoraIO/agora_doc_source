<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="callback_iaudioframeobserverbase_getobservedaudioframeposition">
    <title><ph keyref="getObservedAudioFramePosition"/></title>
    <shortdesc id="short"><ph id="shortdesc">设置音频观测位置。</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="getObservedAudioFramePosition"/>
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">- (AgoraAudioFramePosition)getObservedAudioFramePosition NS_SWIFT_NAME(getObservedAudioFramePosition());</codeblock>
            <codeblock props="ios mac" outputclass="language-objectivec">- (AgoraAudioFramePosition)getObservedAudioFramePosition NS_SWIFT_NAME(getObservedAudioFramePosition());</codeblock>
            <codeblock props="cpp unreal" outputclass="language-cpp">virtual int getObservedAudioFramePosition() = 0;</codeblock>
         <codeblock props="bp" outputclass="language-cpp">DECLARE_DYNAMIC_MULTICAST_DELEGATE(FGetObservedAudioFramePosition);</codeblock>
            <codeblock props="electron" outputclass="language-typescript"/>
            <codeblock props="unity cs" outputclass="language-csharp">public virtual int GetObservedAudioFramePosition()</codeblock>
            <codeblock props="rn" outputclass="language-typescript"/>
           <codeblock props="flutter" outputclass="language-dart"/> 
            <codeblock props="reserve" outputclass="language-cpp"></codeblock></p>
        </section>
        <section id="detailed_desc">
            <p>成功注册音频数据观测器后，SDK 会在每个特定的音频帧处理节点通过该回调来判断是否触发如下回调：
            
            <ul>
            <li><xref keyref="onRecordAudioFrame"/></li>
            <li><xref keyref="onPlaybackAudioFrame"/></li>
            <li><xref keyref="onPlaybackAudioFrameBeforeMixing"/></li>
            <li><xref keyref="onMixedAudioFrame"/></li>
            <li><xref keyref="onEarMonitoringAudioFrame"/></li>
            </ul></p>
            <p>你可以根据场景需求，通过修改 <apiname keyref="getObservedAudioFramePosition"/> 的返回值，设置你需要观测的某个或多个位置。</p>
            <p>注解观测多个位置时，需要使用 |（或运算符）。为降低设备耗能，你可以根据实际需求适当减少观测位置。</p>
        </section>
        <section id="return_values">
            <title>返回值</title>
            <p>返回设置观测位置的位掩码，取值如下：
            
            <ul>
            <li><ph keyref="AUDIO_FRAME_POSITION_PLAYBACK"/> (0x0001)：该位置可观测所有远端用户混音后的播放音频，对应 <apiname keyref="onPlaybackAudioFrame"/> 回调。</li>
            <li><ph keyref="AUDIO_FRAME_POSITION_RECORD"/> (0x0002)：该位置可观测采集的本地用户的音频，对应 <apiname keyref="onRecordAudioFrame"/> 回调。</li>
            <li><ph keyref="AUDIO_FRAME_POSITION_MIXED"/> (0x0004)：该位置可观测本地和所有远端用户混音后的音频，对应 <apiname keyref="onMixedAudioFrame"/> 回调。</li>
            <li><ph keyref="AUDIO_FRAME_POSITION_BEFORE_MIXING"/> (0x0008)：该位置可观测单个远端用户混音前的音频，对应 <apiname keyref="onPlaybackAudioFrameBeforeMixing"/> 回调。</li>
            <li><ph keyref="AUDIO_FRAME_POSITION_EAR_MONITORING"/> (0x0010)：该位置可观测单个本地用户耳返的音频，对应 <apiname keyref="onEarMonitoringAudioFrame"/> 回调。</li>
            </ul></p>
        </section>
    </refbody>
</reference>
