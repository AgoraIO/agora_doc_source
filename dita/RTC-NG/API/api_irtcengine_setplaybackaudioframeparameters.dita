<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="api_irtcengine_setplaybackaudioframeparameters">
    <title><ph keyref="setPlaybackAudioFrameParameters"/></title>
    <shortdesc id="short"><ph id="shortdesc">设置原始音频播放数据的格式。</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="setPlaybackAudioFrameParameters"/>
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
            <codeblock props="android" outputclass="language-java">public abstract int setPlaybackAudioFrameParameters(int sampleRate, int channel, int mode, int samplesPerCall);</codeblock>
            <codeblock props="hmos" outputclass="language-arkts">public abstract setPlaybackAudioFrameParameters(sampleRate: number, channel: number, mode: number, samplesPerCall: number): number;</codeblock>
            <codeblock props="ios mac" outputclass="language-objectivec">- (int)setPlaybackAudioFrameParametersWithSampleRate:(NSInteger)sampleRate
                                             channel:(NSInteger)channel
                                                mode:(AgoraAudioRawFrameOperationMode)mode
                                      samplesPerCall:(NSInteger)samplesPerCall NS_SWIFT_NAME(setPlaybackAudioFrameParametersWithSampleRate(_:channel:mode:samplesPerCall:));</codeblock>
            <codeblock props="cpp unreal" outputclass="language-cpp">virtual int setPlaybackAudioFrameParameters(int sampleRate, int channel, RAW_AUDIO_FRAME_OP_MODE_TYPE mode, int samplesPerCall) = 0;</codeblock>
            <codeblock props="bp" outputclass="language-cpp">UFUNCTION(BlueprintCallable, Category = "Agora|IRtcEngine")
	int SetPlaybackAudioFrameParameters(int sampleRate, int channel, ERAW_AUDIO_FRAME_OP_MODE_TYPE mode, int samplesPerCall);</codeblock>
            <codeblock props="electron" outputclass="language-typescript">abstract setPlaybackAudioFrameParameters(
    sampleRate: number,
    channel: number,
    mode: RawAudioFrameOpModeType,
    samplesPerCall: number
  ): number;</codeblock>
            <codeblock props="unity cs" outputclass="language-csharp">public abstract int SetPlaybackAudioFrameParameters(int sampleRate, int channel,
            RAW_AUDIO_FRAME_OP_MODE_TYPE mode, int samplesPerCall);</codeblock>
            <codeblock props="rn" outputclass="language-typescript">abstract setPlaybackAudioFrameParameters(
    sampleRate: number,
    channel: number,
    mode: RawAudioFrameOpModeType,
    samplesPerCall: number
  ): number;</codeblock>
            <codeblock props="flutter" outputclass="language-dart">Future&lt;void&gt; setPlaybackAudioFrameParameters(
    {required int sampleRate,
    required int channel,
    required RawAudioFrameOpModeType mode,
    required int samplesPerCall});</codeblock>
            <codeblock props="reserve" outputclass="language-cpp"/></p>
        </section>
        <section id="detailed_desc" deliveryTarget="details" otherprops="no-title">
            <p>SDK 会根据 <codeph>samplesPerCall</codeph>、<codeph>sampleRate</codeph> 和 <codeph>channel</codeph> 参数计算采样间隔。采样间隔（单位：秒） = <codeph>samplesPerCall</codeph> / (<codeph>sampleRate</codeph> × <codeph>channel</codeph>)。请确保采样间隔 ≥ 0.01 秒。SDK 会根据采样间隔触发 <xref keyref="onPlaybackAudioFrame"/> 回调。<codeph>samplesPerCall</codeph>、<codeph>sampleRate</codeph> 和 <codeph>channel</codeph> 参数计算采样间隔。采样间隔（单位：秒） = <codeph>samplesPerCall</codeph> / (<codeph>sampleRate</codeph> × <codeph>channel</codeph>)。请确保采样间隔 ≥ 0.01 秒。SDK 会根据采样间隔触发 <xref keyref="onPlaybackAudioFrame"/> 回调。<ph conkeyref="setRecordingAudioFrameParameters/function"/><ph>SDK 会根据该采样间隔触发 <xref keyref="onPlaybackAudioFrame"/> 回调。</ph></p>
            <note type="attention" props="apple cpp">请在加入频道前调用该方法。</note>
            </section>
        <section id="timing" deliveryTarget="details">
            <title>调用时机</title>
            <p>请在加入频道前调用该方法。</p>
        </section>        
        <section id="restriction" deliveryTarget="details">
            <title>调用限制</title>
            <p>无。</p>
        </section>
        <section id="parameters" deliveryTarget="details">
            <title>参数</title>
            <parml>
            <plentry conkeyref="setRecordingAudioFrameParameters/sampleRate">
                <pt/>
                <pd/>
            </plentry>
            <plentry conkeyref="setRecordingAudioFrameParameters/channel">
                <pt/>
                <pd/>
            </plentry>
            <plentry conkeyref="setRecordingAudioFrameParameters/mode">
                <pt/>
                <pd/>
            </plentry>
            <plentry conkeyref="setRecordingAudioFrameParameters/samplesPerCall">
                <pt/>
                <pd/>
            </plentry>
            <plentry props="android cpp ios">
                <pt props="android cpp ios">sampleRate</pt>
                <pd props="android cpp ios">回调中返回的采样率，单位为 Hz。可设置为 8000、16000、32000、44100 或 48000。</pd>
                </plentry>
            <plentry props="android cpp ios">
                <pt props="android cpp ios">channel</pt>
                <pd props="android">音频声道数。可设置为：
                    <ul>
                        <li>1：单声道。</li>
                        <li>2：立体声。</li>
                        </ul>
                    </pd>
                <pd props="ios">音频声道数，可设置为 1 或 2。
                    <ul>
                        <li>1：单声道。</li>
                        <li>2：立体声。</li>
                        </ul>
                    </pd>
                <pd props="cpp">音频声道数，可设置为：
                    <ul>
                        <li>1：单声道。</li>
                        <li>2：立体声。</li>
                        </ul>
                    </pd>
                </plentry>
            <plentry props="android cpp ios">
                <pt props="android cpp ios">mode</pt>
                <pd props="android">音频帧的使用模式：
                    <ul>
                        <li><ph keyref="RAW_AUDIO_FRAME_OP_MODE_READ_ONLY"/> (0)：（默认）只读模式。例如，你通过声网 SDK 获取数据后推送 RTMP 或 RTMPS 流。</li>
                        <li><ph keyref="RAW_AUDIO_FRAME_OP_MODE_READ_WRITE"/> (2)：读写模式。你可以从 <xref keyref="AudioFrame"/> 中读取数据并进行修改后播放。例如，你有自己的音效处理模块并进行语音预处理，如变声。</li>
                        </ul>
                    </pd>
                <pd props="cpp ios">音频帧的使用模式，详见 <xref keyref="RAW_AUDIO_FRAME_OP_MODE_TYPE"/>。</pd>
                </plentry>
            <plentry props="android cpp ios">
                <pt props="android cpp ios">samplesPerCall</pt>
                <pd props="android">每次回调返回的数据采样数。例如，在媒体推流场景中设置为 1024。</pd>
                <pd props="ios">每次回调返回的数据采样数，例如媒体推流时为 1024。</pd>
                <pd props="cpp">每次回调的数据采样点数量。例如，媒体推流时通常设置为 1024。</pd>
                </plentry>
        </parml> </section>
        <section id="return_values" props="bp cs electron flutter native rn unity unreal">
            <title><ph keyref="return-section-title"/></title>
        <p props="flutter">方法成功调用时，无返回值；方法调用失败时，会抛出 <xref keyref="AgoraRtcException"/> 异常，你需要捕获异常并进行处理。<ph props="cn">详见<xref keyref="error-code-link"/>了解详情和解决建议。</ph></p>
        <ul>
            <li props="bp cs electron rn unity unreal">0：方法调用成功。</li>
            <li>&lt; 0：方法调用失败。<ph props="cn">详见<xref keyref="error-code-link"/>了解详情和解决建议。</ph></li>
            </ul>
        <p props="native"><ul>
                        <li>0：方法调用成功。</li>
                        <li>&lt; 0：方法调用失败。</li>
                        </ul>
                    </p>
    </section>
        </refbody>
</reference>
