<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="api_pullaudioframe">
    <title><ph keyref="pullAudioFrame"/></title>
    <shortdesc id="short"><ph id="shortdesc">拉取远端音频数据。</ph></shortdesc>
    <prolog>
        <metadata>
   <keywords>
       <indexterm keyref="pullAudioFrame" />
   </keywords>
        </metadata>
    </prolog>
    <refbody><section id="prototype">
        <p outputclass="codeblock">
                <codeblock props="android" outputclass="language-java">public abstract int pullPlaybackAudioFrame(byte[] data, int lengthInByte);</codeblock>
                <codeblock props="ios mac" outputclass="language-objectivec">- (BOOL)pullPlaybackAudioFrameRawData:(void * _Nonnull)data
                              lengthInByte:(NSUInteger)lengthInByte;</codeblock>
                <codeblock props="windows" outputclass="language-cpp">virtual int pullAudioFrame(IAudioFrameObserver::AudioFrame* frame) = 0;</codeblock>
                <codeblock props="electron" outputclass="language-typescript"/>
                <codeblock props="unity" outputclass="language-csharp"/>
                <codeblock props="rn" outputclass="language-typescript"/>
                <codeblock props="flutter" outputclass="language-dart"/>
        </p>
        </section>
        <section id="detailed_desc">
            <p props="rtc">使用该方法前，你需要调用 <xref keyref="setExternalAudioSink"/> 通知 app 开启并设置外部渲染。</p>
            <p props="rtc-ng">
                <ph props="android windows">使用该方法前，你需要在 <xref keyref="RtcEngineConfig"/> 中设置 <parmname props="android">mEnableAudioDevice</parmname><parmname props="windows">enableAudioDevice</parmname> 为 <codeph><ph keyref="false"/></codeph>， 并调用 <xref keyref="setExternalAudioSink"/> 通知 app 开启并设置外部渲染。</ph>
                <ph props="ios mac">使用该方法前，你需要调用 <xref keyref="setExternalAudioSink"/> 通知 app 开启并设置外部渲染。</ph>
            </p>
   <p>调用该方法后，app 会采取主动拉取的方式获取远端已解码和混音后的音频数据，用于音频播放。</p>
   <note type="attention">
       <ul>
           <li>开启外部音频渲染后，app 将无法从 <xref keyref="onPlaybackAudioFrame"/> 回调中获得数据。</li>
           <li>该方法和 <apiname keyref="onPlaybackAudioFrame"/> 回调相比，区别在于： 
               <ul><li>SDK 通过 <apiname keyref="onPlaybackAudioFrame"/> 回调将音频数据传输给 app。如果 app 处理延时，可能会导致音频播放抖动。</li>
                   <li>调用该方法后 app 会主动拉取音频数据。通过设置音频数据，SDK 可以调整缓存，帮助 app 处理延时，从而有效避免音频播放抖动。</li>
               </ul></li>
       </ul>
   </note>
        </section>
        <section id="parameters"><title>参数</title>
   <parml>
       <plentry props="windows">
  <pt>frame</pt>
  <pd>指向 <xref keyref="AudioFrame"/> 的指针。</pd>
       </plentry>
       <plentry props="android ios mac">
           <pt>data</pt>
           <pd>待拉取的远端音频数据，数据类型为 <codeph>byte[]</codeph>。</pd>
       </plentry>
       <plentry props="android ios mac" id="length">
           <pt>lengthInByte</pt>
           <pd>远端音频数据长度，单位为字节。 该参数的值由音频数据时长、<apiname keyref="setExternalAudioSink"/> 的 <codeph>sampleRate</codeph> 和 <codeph>channels</codeph> 参数确定。 <codeph>lengthInByte</codeph> = <codeph>sampleRate</codeph>/1000 × 2 × <codeph>channels</codeph> × 音频数据时长 (ms)。</pd>
       </plentry>
   </parml>
        </section>
        <section id="return_values">
   <title>返回值</title>
   <ul props="android windows">
       <li>0：方法调用成功。</li>
       <li>&lt; 0：方法调用失败。</li>
   </ul>
            <ul props="ios mac">
       <li><codeph><ph keyref="true"/></codeph>：方法调用成功。</li>
       <li><codeph><ph keyref="false"/></codeph>：方法调用失败。</li>
   </ul> 
        </section></refbody>
</reference>
