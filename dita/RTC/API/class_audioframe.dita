<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="class_audioframe">
    <title><ph keyref="AudioFrame"/></title>
    <shortdesc id="short"><ph id="shortdesc">AudioFrame 定义。</ph></shortdesc>
    <refbody>
        <section id="prototype">
   <p conref="../conref/conref_rtc_api.dita#apidef/AudioFrame"/>
        </section>
        <section id="parameters">
   <title><text conref="../conref/conref_api_metadata.dita#metadata/property"/></title>
   <parml>
       <plentry>
  <pt>type</pt>
  <pd>
      <p>音频帧类型，详见 <xref keyref="AUDIO_FRAME_TYPE"/>。</p>
      </pd>
       </plentry>
       <plentry>
  <pt>samples</pt>
  <pd>每个声道的采样点数。</pd>
       </plentry>
       <plentry>
  <pt>bytesPerSample</pt>
  <pd>每个采样点的字节数: 对于 PCM 来说，一般使用 16 bit，即两个字节。</pd>
       </plentry>
       <plentry>
  <pt>channels</pt>
  <pd>
      <p>声道数量(如果是立体声，数据是交叉的)。<ul id="ul_zxz_2wt_r4b">
     <li>1: 单声道</li>
     <li>2: 双声道</li>
 </ul></p>
  </pd>
       </plentry>
       <plentry>
  <pt>samplesPerSec</pt>
  <pd>每声道每秒的采样点数。</pd>
       </plentry>
       <plentry>
  <pt>buffer</pt>
  <pd>
      <p>声音数据缓存区（如果是立体声，数据是交叉存储的）。</p>
      <p>缓存区数据大小 <codeph>buffer</codeph> = <codeph>samples</codeph> ×
     <codeph>channels</codeph> × <codeph>bytesPerSample</codeph>。</p>
  </pd>
       </plentry>
       <plentry>
  <pt>renderTimeMs</pt>
  <pd>
      <p>外部音频帧的渲染时间戳。</p>
      <p>你可以使用该时间戳还原音频帧顺序；在有视频的场景中（包含使用外部视频源的场景），该参数可以用于实现音视频同步。</p>
  </pd>
       </plentry>
       <plentry>
  <pt>avsync_type</pt>
  <pd>保留参数。</pd>
       </plentry>
   </parml>
        </section></refbody>
</reference>
