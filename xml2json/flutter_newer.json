[
    {
        "id": "api_addhandler",
        "name": "setEventHandler",
        "description": "Adds event handlers\nThe SDK uses the RtcEngineEventHandler class to send callbacks to the app. The app inherits the methods of this class to receive these callbacks. All methods in this interface class have default (empty) implementations. Therefore, the application can only inherit some required events. In the callbacks, avoid time-consuming tasks or calling APIs that can block the thread, such as the sendStreamMessage method. Otherwise, the SDK may not work properly.",
        "parameters": [
            {
                "handler": "Callback events to be added. For details, see RtcEngineEventHandler."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_addinjectstreamurl",
        "name": "addInjectStreamUrl",
        "description": "Injects an online media stream to a live streaming channel.\nAgora will soon stop the service for injecting online media streams on the client. If you have not implemented this service, Agora recommends that you do not use it. For details, see Service Sunset Plans.\n   \n  \n      Ensure that you enable the RTMP Converter service before using this function. See Prerequisites in Push Streams to CDN.\n      This method takes effect only when you are a host in a live streaming channel.\n      Only one online media stream can be injected into the same channel at the same time.\n      Call this method after joining a channel.\n  \n       \n   This method injects the currently playing audio and video as audio and video sources into the\n                ongoing live broadcast. This applies to scenarios where all users in the channel can\n                watch a live show and interact with each other. After calling this method, the SDK\n                triggers the streamInjectedStatus callback on the local client to\n                report the state of injecting the online media stream; after successfully injecting\n                the media stream, the stream joins the channel, and all users in the channel receive\n                the userJoined callback, where uid is\n                    666.",
        "parameters": [
            {
                "url": "The URL address to be added to the ongoing streaming. Valid protocols are RTMP, HLS, and HTTP-FLV.\n     Supported audio codec type: AAC.\n     Supported video codec type: H264 (AVC).\n \n      \n  "
            },
            {
                "config": "The configuration information for the added voice or video stream: LiveInjectStreamConfig."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_addpublishstreamurl",
        "name": "addPublishStreamUrl",
        "description": "Publishes the local stream to a specified CDN live streaming URL.\nAfter calling this method, you can push media streams in RTMP or RTMPS protocol to the CDN. The SDK triggers the rtmpStreamingStateChanged callback on the local client to report the state of adding a local stream to the CDN.\n   \n       \n  Call this method after joining a channel.\n           Ensure that you enable the RTMP Converter service before using this function. \n  This method takes effect only when you are a host in live interactive streaming.\n  This method adds only one stream CDN streaming URL each time it is called. To push multiple URLs, call this method multiple times.\n  Agora supports pushing media streams in RTMPS protocol to the CDN only when you enable transcoding.",
        "parameters": [
            {
                "url": "The CDN streaming URL in the RTMP or RTMPS format. The maximum length of this parameter is 1024 bytes. The URL address must not contain special characters, such as Chinese language characters."
            },
            {
                "transcodingEnabled": "Whether to enable transcoding. Transcoding in a CDN live streaming converts the audio and video streams before pushing them to the CDN server. It applies to scenarios where a channel has multiple broadcasters and composite layout is needed\n                                true: Enable transcoding.\n                                false: Disable transcoding.\n                            \n      If you set this parameter as true, ensure that you call the setLiveTranscoding method before this method.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_addvideowatermark2",
        "name": "addVideoWatermark",
        "description": "Adds a watermark image to the local video.\nThis method adds a PNG watermark image to the local video in the live streaming. Once the watermark image is added, all the audience in the channel (CDN audience included), and the capturing device can see and capture it. Agora supports adding only one watermark image onto the local video, and the newly watermark image replaces the previous one.\n   The watermark coordinates are dependent on the settings in the setVideoEncoderConfiguration method:\n  If the orientation mode of the encoding video (VideoOutputOrientationMode) is FIXED_LANDSCAPE, or the landscape mode in ADAPTIVE, the watermark uses the landscape orientation.\n  If the orientation mode of the encoding video (VideoOutputOrientationMode) is FIXED_PORTRAIT, or the portrait mode in ADAPTIVE, the watermark uses the portrait orientation.\n  When setting the watermark position, the region must be less than the dimensions set in the setVideoEncoderConfiguration method. Otherwise, the watermark image will be cropped.\n       \n   \n   \n       \n  Ensure that you have called enableVideo before calling this method.\n  If you only want to add a watermark to the CDN live streaming, you can call this method or the setLiveTranscoding method.\n  This method supports adding a watermark image in the PNG file format only. Supported pixel formats of the PNG image are RGBA, RGB, Palette, Gray, and Alpha_gray.\n  If the dimensions of the PNG image differ from your settings in this method, the image will be cropped or zoomed to conform to your settings.\n  If you have enabled the local video preview by calling the startPreview method, you can use the visibleInPreview member to set whether or not the watermark is visible in the preview.\n  If you have enabled the mirror mode for the local video, the watermark on the local video is also mirrored. To avoid mirroring the watermark, Agora recommends that you do not use the mirror and watermark functions for the local video at the same time. You can implement the watermark function in your application layer.",
        "parameters": [
            {
                "watermarkUrl": "The local file path of the watermark image to be added. This method supports adding a watermark image from the local absolute or relative file path."
            },
            {
                "options": "The options of the watermark image to be added. For details, see WatermarkOptions."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_adjustaudiomixingplayoutvolume",
        "name": "adjustAudioMixingPlayoutVolume",
        "description": "Adjusts the volume of audio mixing for local playback.\nYou need to call this method after calling startAudioMixing and receiving the audioMixingStateChanged(PLAY) callback.",
        "parameters": [
            {
                "volume": "Audio mixing volume for local playback. The value range is [0,100]. The default value is 100, the original volume."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_adjustaudiomixingpublishvolume",
        "name": "adjustAudioMixingPublishVolume",
        "description": "Adjusts the volume of audio mixing for publishing.\nThis method adjusts the volume of audio mixing for publishing (sending to other users).\n   You need to call this method after calling startAudioMixing and receiving the audioMixingStateChanged(PLAY) callback.",
        "parameters": [
            {
                "volume": "Audio mixing volume. The value range is [0,100]. The default value is 100, the original volume."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_adjustaudiomixingvolume",
        "name": "adjustAudioMixingVolume",
        "description": "Adjusts the volume during audio mixing.\nThis method adjusts the audio mixing volume on both the local client and remote clients.\n   \n       \n  Call this method after startAudioMixing.\n  Calling this method does not affect the volume of audio effect file playback invoked by the playEffect method.",
        "parameters": [
            {
                "volume": "Audio mixing volume. The value ranges between 0 and 100. The default value is 100, the original volume."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_adjustplaybacksignalvolume",
        "name": "adjustPlaybackSignalVolume",
        "description": "Adjusts the playback signal volume of all remote users.\nThis method adjusts the playback volume that is the mixed volume of all remote users.\n  You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "volume": "Integer only. The value range is [0,400].\n                                0: Mute.\n                                100: (Default) The original volume.\n                                400: Four times the original volume (amplifying the audio signals by four times).\n                            \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_adjustrecordingsignalvolume",
        "name": "adjustRecordingSignalVolume",
        "description": "Adjusts the capturing signal volume.\nYou can call this method either before or after joining a channel.",
        "parameters": [
            {
                "volume": "Integer only. The value range is [0,400].\n                                0: Mute.\n                                100: (Default) The original volume.\n                                400: Four times the original volume (amplifying the audio signals by four times).\n                            \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_adjustuserplaybacksignalvolume",
        "name": "adjustUserPlaybackSignalVolume",
        "description": "Adjusts the playback signal volume of a specified remote user.\nYou can call this method to adjust the playback volume of a specified remote user. To adjust the playback volume of different remote users, call the method as many times, once for each remote user.\n   \n       \n  Call this method after joining a channel.\n  The playback volume here refers to the mixed volume of a specified remote user.",
        "parameters": [
            {
                "volume": "Audio mixing volume. The value ranges between 0 and 100. The default value is 100, the original volume."
            },
            {
                "uid": "The ID of the remote user."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_clearvideowatermarks",
        "name": "clearVideoWatermarks",
        "description": "Removes the watermark image from the video stream.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_complain",
        "name": "complain",
        "description": "Allows a user to complain about the call quality after a call ends.\nThis method allows users to complain about the quality of the call. Call this method after the user leaves the channel.",
        "parameters": [
            {
                "callId": "The current call ID. You can get the call ID by calling getCallId."
            },
            {
                "description": "(Optional) A description of the call. The string length should be less than 800 bytes."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_configrhythmplayer",
        "name": "configRhythmPlayer",
        "description": "Configures the virtual metronome.\nAfter enabling the virtual metronome, the SDK plays the specified audio effect file from the beginning, and controls the playback duration of each file according to beatsPerMinute you set in RhythmPlayerConfig. For example, if you set beatsPerMinute as 60, the SDK plays one beat every second. If the file duration exceeds the beat duration, the SDK only plays the audio within the beat duration.\n            \n        After calling startRhythmPlayer, you can call this method to reconfigure the virtual metronome.",
        "parameters": [
            {
                "config": "The metronome configuration. See RhythmPlayerConfig."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_create2",
        "name": "createWithContext",
        "description": "Initializes RtcEngine.\nAll called methods provided by the RtcEngine class are executed asynchronously. We recommend calling these methods in the same thread.\n            \n                \n                    Before calling other APIs, you must call create and createWithContext to create and initialize an RtcEngine object.\n                    The SDK supports creating only one RtcEngine instance for an app.",
        "parameters": [
            {
                "config": "Configurations for the RtcEngine instance. For details, see RtcEngineContext.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_createagorartcengine",
        "name": "create",
        "description": "Creates the RtcEngine object.\nDeprecated:\n                    This method is deprecated. Use createWithContext instead.",
        "parameters": [
            {
                "appId": "The Agora App ID of your Agora project."
            }
        ],
        "returns": "The RtcEngine instance, if the method call succeeds.\n                    An error code, if the call fails."
    },
    {
        "id": "api_createdatastream",
        "name": "createDataStream",
        "description": "Creates a data stream.\nEach user can create up to five data streams during the lifecycle of RtcEngine.\n   \n       \n  Call this method after joining a channel.\n  Agora does not support setting reliable as true and ordered as true.",
        "parameters": [
            {
                "reliable": "Whether or not the data stream is reliable:\n      true: The recipients receive the data from the sender within five seconds. If the recipient does not receive the data within five seconds, the SDK triggers the streamMessageError callback and returns an error code.\n      false: There is no guarantee that the recipients receive the data stream within five seconds and no error message is reported for any delay or missing data stream.\n  "
            },
            {
                "ordered": "Whether or not the recipients receive the data stream in the sent order:\n      true: The recipients receive the data in the sent order.\n      false: The recipients do not receive the data in the sent order.\n  "
            }
        ],
        "returns": "ID of the created data stream, if the method call succeeds.\n       < 0: Failure."
    },
    {
        "id": "api_createdatastream2",
        "name": "createDataStreamWithConfig",
        "description": "Creates a data stream.\nCreates a data stream. Each user can create up to five data streams in a single channel.\n            Compared with createDataStream[1/2], this method does not support data reliability. If a data packet is not received five seconds after it was sent, the SDK directly discards the data.",
        "parameters": [
            {
                "config": "The configurations for the data stream. For details, see DataStreamConfig."
            }
        ],
        "returns": "ID of the created data stream, if the method call succeeds.\n       < 0: Failure."
    },
    {
        "id": "api_createwithareacode",
        "name": "createWithAreaCode",
        "description": "Initializes the RtcEngine object.\nDeprecated:\n                    This method is deprecated. Use createWithContext instead.",
        "parameters": [
            {
                "appId": "The App ID of your Agora project."
            },
            {
                "areaCode": "The area code. For details, see AreaCode."
            }
        ],
        "returns": "The RtcEngine instance, if the method call succeeds.\n                    An error code, if the call fails."
    },
    {
        "id": "api_createwithconfig",
        "name": "createWithConfig",
        "description": "Initializes the RtcEngine object.\nDeprecated:\n                    This method is deprecated. Use createWithContext instead.",
        "parameters": [
            {
                "config": "The RtcEngine configuraiton. For details, see RtcEngineContext."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_devicemanager",
        "name": "deviceManager",
        "description": "Gets the RtcDeviceManager class.\n",
        "parameters": [],
        "returns": "The RtcDeviceManager class."
    },
    {
        "id": "api_disableaudio",
        "name": "disableAudio",
        "description": "Disables the audio module.\nThis method disables the internal engine and can be called anytime after initialization. It is still valid after one leaves channel.\n                This method resets the internal engine and takes some time to take effect. Agora recommends using the following API methods to control the audio modules separately:\n                    enableLocalAudio: Whether to enable the microphone to create the local audio stream.\n                    muteLocalAudioStream: Whether to publish the local audio stream.\n                    muteRemoteAudioStream: Whether to subscribe and play the remote audio stream.\n                    muteAllRemoteAudioStreams: Whether to subscribe to and play all remote audio streams.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_disablelastmiletest",
        "name": "disableLastmileTest",
        "description": "Disables the network connection quality test.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_disablevideo",
        "name": "disableVideo",
        "description": "Disables the video module.\nThis method disables video. You can call this method either before or after joining a channel. If you call it before joining a channel, an audio call starts when you join the channel. If you call it after joining a channel, a video call switches to an audio call. Call enableVideo to enable video.A successful call of this method triggers the userEnableVideo(false) callback on the remote client.\n   \n       This method affects the internal engine and can be called after leaving the channel.\n       This method resets the internal engine and takes some time to take effect. Agora recommends using the following API methods to control the video engine modules separately:\n                            enableLocalVideo: Whether to enable the camera to create the local video stream.\n                            muteLocalVideoStream: Whether to publish the local video stream.\n                            muteRemoteVideoStream: Whether to subscribe to and play the remote video stream.\n                            muteAllRemoteVideoStreams: Whether to subscribe to and play all remote video streams.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_enableaudio",
        "name": "enableAudio",
        "description": "Enables the audio module.\nThe audio mode is enabled by default.\n   \n       This method enables the internal engine and can be called anytime after initialization. It is still valid after one leaves channel.\n       This method enables the audio module and takes some time to take effect. Agora recommends using the following API methods to control the audio module separately:\n  enableLocalAudio: Whether to enable the microphone to create the local audio stream.\n  muteLocalAudioStream: Whether to publish the local audio stream.\n  muteRemoteAudioStream: Whether to subscribe and play the remote audio stream.\n  muteAllRemoteAudioStreams: Whether to subscribe to and play all remote audio streams.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_enableaudiovolumeindication",
        "name": "enableAudioVolumeIndication",
        "description": "Enables the reporting of users' volume indication.\nThis method enables the SDK to regularly report the volume information of the local user who sends a stream and remote users (up to three) whose instantaneous volumes are the highest to the app. Once you call this method and users send streams in the channel, the SDK triggers the audioVolumeIndication callback at the time interval set in this method.\n   You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "interval": "Sets the time interval between two consecutive volume indications:\n                            ≤ 0: Disables the volume indication.\n                            > 0: Time interval (ms) between two consecutive volume indications. We recommend a setting greater than 200 ms. Do not set this parameter to less than 10 milliseconds, otherwise the audioVolumeIndication callback will not be triggered.\n                        "
            },
            {
                "smooth": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "api_enabledeeplearningdenoise",
        "name": "enableDeepLearningDenoise",
        "description": "Enables/Disables deep-learning noise reduction.\nThe SDK enables traditional noise reduction mode by default to reduce most of the stationary background noise. If you need to reduce most of the non-stationary background noise, Agora recommends enabling deep-learning noise reduction as follows:\n       Ensure that the dynamic library is integrated in your project: libagora_ai_denoise_extension.dll\n       Call enableDeepLearningDenoise(true).\n   \n   Deep-learning noise reduction requires high-performance devices. The deep-learning noise reduction is enabled only when the device supports this function. For example, the following devices and later models are known to support deep-learning noise reduction:\n       iPhone 6S\n       MacBook Pro 2015\n       iPad Pro (2nd generation)\n       iPad mini (5th generation)\n       iPad Air (3rd generation)\n   \n   After successfully enabling deep-learning noise reduction, if the SDK detects that the device performance is not sufficient, it automatically disables deep-learning noise reduction and enables traditional noise reduction.\n   If you call enableDeepLearningDenoise(true) or the SDK automatically disables deep-learning noise reduction in the channel, when you need to re-enable deep-learning noise reduction, you need to call leaveChannel first, and then call enableDeepLearningDenoise(true).\n   \n       This method dynamically loads the library, so Agora recommends calling this method before joining a channel.\n       This method works best with the human voice. Agora does not recommend using this method for audio containing music.",
        "parameters": [
            {
                "enable": "Whether to enable deep-learning noise reduction.\n      true: (Default) Enable deep-learning noise reduction.\n      false: Disable deep-learning noise reduction.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_enabledualstreammode",
        "name": "enableDualStreamMode",
        "description": "Enables/Disables dual-stream mode.\nYou can call this method to enable or disable the dual-stream mode on the publisher side. Dual streams are a hybrid of a high-quality video stream and a low-quality video stream:\n                    High-quality video stream: High bitrate, high resolution.\n                    Low-quality video stream: Low bitrate, low resolution.\n        After you enable the dual-stream mode, you can call \n           to choose to receive the high-quality video stream or low-quality video stream on the subscriber side.\n            \n                You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "enabled": "Enables dual-stream mode.\n true: Enables dual-stream mode.\n false: Disables dual-stream mode.\n      \n                        \n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_enableencryption",
        "name": "enableEncryption",
        "description": "Enables/Disables the built-in encryption.\nIn scenarios requiring high security, Agora recommends calling this method to enable the built-in encryption before joining a channel.\n               All users in the same channel must use the same encryption mode and encryption key. After the user leaves the channel, the SDK automatically disables the built-in encryption. To enable the built-in encryption, call this method before the user joins the channel again.\n               If you enable the built-in encryption, you cannot use the RTMP or RTMPS streaming function.",
        "parameters": [
            {
                "enabled": "Whether to enable built-in encryption:\n                                        true: Enable the built-in encryption.\n                                        false: Disable the built-in encryption.\n                                   \n                              \n                         "
            },
            {
                "config": "Configurations of built-in encryption. For details, see EncryptionConfig."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_enablefacedetection",
        "name": "enableFaceDetection",
        "description": "Enables/Disables face detection for the local user.\nYou can call this method either before or after joining a channel.\n   This method is for Android and iOS only.\n            Once face detection is enabled, the SDK triggers the facePositionChanged callback to report the face information of the local user:\n       The width and height of the local video.\n       The position of the human face in the local video.\n       The distance between the human face and the screen.\n   \n   \n   This method needs to be called after the camera is started (for example, by calling startPreview or joinChannel).",
        "parameters": [
            {
                "enable": "Whether to enable face detection:\n      true: Enable face detection.\n      false: (Default) Disable face detection.\n  \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_enableinearmonitoring",
        "name": "enableInEarMonitoring",
        "description": "Enables in-ear monitoring.\nThis method enables or disables in-ear monitoring.\n\n       \n  \n      This method is for Android and iOS only.\n      Users must use wired earphones to hear their own voices.\n      You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "enabled": "Enables in-ear monitoring.\n true: Enables in-ear monitoring.\n      false: (Default) Disables in-ear monitoring.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_enablelastmiletest",
        "name": "enableLastmileTest",
        "description": "Enables the network connection quality test.\nThis method tests the quality of the users' network connections. By default, this function is disabled. This method applies to the following scenarios:\n                    Before a user joins a channel, call this method to check the uplink network quality.\n                    Before an audience switches to a host, call this method to check the uplink network quality.\n                \n            \n            Regardless of the scenario, enabling this method consumes extra network traffic and affects the call quality. After receiving the lastmileQuality callback, call disableLastmileTest to stop the test, and then join the channel or switch to the host.\n            \n                \n                    Do not use this method together with startLastmileProbeTest.\n                    Do not call any other methods before receiving the lastmileQuality callback. Otherwise, the callback may be interrupted by other methods, and hence may not be triggered.\n                    A host should not call this method after joining a channel (when in a call).\n                    If you call this method to test the last mile network quality, the SDK consumes the bandwidth of a video stream, whose bitrate corresponds to the bitrate you set in setVideoEncoderConfiguration. After joining a channel, whether you have called disableLastmileTest or not, the SDK automatically stops consuming the bandwidth.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_enablelocalaudio",
        "name": "enableLocalAudio",
        "description": "Enables/Disables the local audio capture.\nThe audio function is enabled by default. This method disables or re-enables the local audio function to stop or restart local audio capturing.\n   This method does not affect receiving or playing the remote audio streams, and enableLocalAudio(false) applies to scenarios where the user wants to receive remote audio streams without sending any audio stream to other users in the channel.\n   Once the local audio function is disabled or re-enabled, the SDK triggers the localAudioStateChanged callback, which reports Stopped(0) or Recording(1).\n       This method is different from the muteLocalAudioStream method:\n                            enableLocalVideo: Disables/Re-enables the local audio capturing and processing. If you disable or re-enable local audio capturing using the enableLocalAudio method, the local user might hear a pause in the remote audio playback.\n                            muteLocalAudioStream: Sends/Stops sending the local audio streams.\n                        \n                    \n       You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "enabled": "true: (Default) Re-enable the local audio function, that is, to start the local audio capturing device (for example, the microphone).\n      false: Disable the local audio function, that is, to stop local audio capturing.\n  \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_enablelocalvideo",
        "name": "enableLocalVideo",
        "description": "Enables/Disables the local video capture.\nThis method disables or re-enables the local video capturer, and does not affect receiving the remote video stream.\n   After calling enableVideo, the local video capturer is enabled by default. You can call enableLocalVideo(false) to disable the local video capturer. If you want to re-enable the local video, call enableLocalVideo(true).\n   After the local video capturer is successfully disabled or re-enabled, the SDK triggers the callback on the remote clientremoteVideoStateChanged.\n   \n       \n  You can call this method either before or after joining a channel.\n  This method enables the internal engine and is valid after .",
        "parameters": [
            {
                "enabled": "Whether to enable the local video capture.\n      \n true: (Default) Enable the local video capture.\n false: Disables the local video capture. Once the local video is disabled, the remote users can no longer receive the video stream of this user, while this user can still receive the video streams of the other remote users. When set to false, this method does not require a local camera.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_enableloopbackrecording",
        "name": "enableLoopbackRecording",
        "description": "Enables loopback audio capturing.\nIf you enable loopback audio capturing, the output of the sound card is mixed into the audio stream sent to the other end.\n       \n  \n      This method applies to macOS and Windows only.\n      You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "enabled": "Sets whether to enable loopback capturing.\n true: Enable loopback audio capturing.\n false: (Default) Disable loopback capturing.\n      "
            },
            {
                "deviceName": "The device name of the sound card. The default value is null (the default sound card). If you use a virtual sound card like \"Soundflower\", set this parameter as the name of the sound card, \"Soundflower\". The SDK will find the corresponding sound card and start capturing."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_enableremotesuperresolution",
        "name": "enableRemoteSuperResolution",
        "description": "Enables/Disables the super-resolution algorithm for a remote user's video stream.\nThis feature effectively boosts the resolution of a remote user's video seen by the local user. If the original resolution of a remote user's video is a × b, the local user's device can render the remote video at a resolution of 2a × 2b\n            after you enable this feature.\n            After you call this method, the SDK triggers the userSuperResolutionEnabled callback to report whether you have successfully enabled super resolution.\n            The super resolution feature requires extra system resources. To balance the visual experience and system usage, the SDK poses the following restrictions: This feature can only be enabled for a single remote user.\n                On Android, the original resolution of the remote video must not exceed 640 × 360 pixels. On iOS, the original resolution of the remote video must not exceed 640 × 480 pixels. If you exceed these limitations, the SDK triggers the warning callback and returns the corresponding warning codes:\n                SuperResolutionStreamOverLimitation: 1610. The origin resolution of the remote video is beyond the range where the super resolution can be applied.\n                SuperResolutionUserCountOverLimitation: 1611. Super resolution is already being used on another remote user's video.\n                SuperResolutionDeviceNotSupported: 1612. The device does not support using super resolution.\n            \n            \n                \n                    This method is for Android and iOS only.\n                    Before calling this method, ensure that you have integrated the following dynamic libraries:\n                        Android: libagora_super_resolution_extension.so\n                        iOS: AgoraSuperResolutionExtension.xcframework\n                    \n                    \n                    Because this method has certain system performance requirements, Agora recommends that you use the following devices or better:\n                        Android:\n                            VIVO: V1821A, NEX S, 1914A, 1916A, 1962A, 1824BA, X60, X60 Pro\n                            OPPO: PCCM00, Find X3\n                            OnePlus: A6000\n                            Xiaomi: Mi 8, Mi 9, Mi 10, Mi 11, MIX3, Redmi K20 Pro\n                            SAMSUNG: SM-G9600, SM-G9650, SM-N9600, SM-G9708, SM-G960U, SM-G9750, S20, S21\n                            HUAWEI: SEA-AL00, ELE-AL00, VOG-AL00, YAL-AL10, HMA-AL00, EVR-AN00, nova 4, nova 5 Pro, nova 6 5G, nova 7 5G, Mate 30, Mate 30 Pro, Mate 40, Mate 40 Pro, P40, P40 Pro, Huawei M6, MatePad 10.8\n                        \n                        iOS:\n                            iPhone XR\n                            iPhone XS\n                            iPhone XS Max\n                            iPhone 11\n                            iPhone 11 Pro\n                            iPhone 11 Pro Max\n                            iPhone 12\n                            iPhone 12 mini\n                            iPhone 12 Pro\n                            iPhone 12 Pro Max\n                            iPhone 12 SE (2nd generation)\n                            iPad Pro 11-inch (3rd generation)\n                            iPad Pro 12.9-inch (3rd generation)\n                            iPad Air 3 (3rd generation)\n                            iPad Air 3 (4th generation)",
        "parameters": [
            {
                "userId": "The ID of the remote user."
            },
            {
                "enable": "Whether to enable super resolution for the remote user’s video:\n                        true: Enable virtual background.\n                        false: Do not enable virtual background.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_enablesoundpositionindication",
        "name": "enableSoundPositionIndication",
        "description": "Enables/Disables stereo panning for remote users.\nEnsure that you call this method before joining a channel to enable stereo panning for remote users so that the local user can track the position of a remote user by calling setRemoteVoicePosition.",
        "parameters": [
            {
                "enabled": "Whether to enable stereo panning for remote users:\n true: Enable stereo panning.\n false: Disable stereo panning.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_enablevideo",
        "name": "enableVideo",
        "description": "Enables the video module.\nCall this method either before joining a channel or during a call. If this method is called before joining a channel, the call starts in the video mode. Call disableVideo to disable the video mode.A successful call of this method triggers the remoteVideoStateChanged callback on the remote client.\n                \n                    This method enables the internal engine and is valid after leaving the channel.\n                    This method resets the internal engine and takes some time to take effect. Agora recommends using the following API methods to control the video engine modules separately:\n                            enableLocalVideo: Whether to enable the camera to create the local video stream.\n                            muteLocalVideoStream: Whether to publish the local video stream.\n                            muteRemoteVideoStream: Whether to subscribe to and play the remote video stream.\n                            muteAllRemoteVideoStreams: Whether to subscribe to and play all remote video streams.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_enablevirtualbackground",
        "name": "enableVirtualBackground",
        "description": "Enables/Disables the virtual background. (beta feature)\nAfter enabling the virtual background feature, you can replace the original background image of the local user with a custom background image. After the replacement, all users in the channel can see the custom background image.\n            \n                    This function requires a high-performance device. Agora recommends that you use this function on devices with the following chips:\n                    Snapdragon 700 series 750G and later\n                    Snapdragon 800 series 835 and later\n                    Dimensity 700 series 720 and later\n                    Kirin 800 series 810 and later\n                    Kirin 900 series 980 and later\n                    Devices with an A9 chip and better, as follows:\n                        iPhone 6S and later\n                        iPad Air 3rd generation and later\n                        iPad 5th generation and later\n                        iPad Pro 2nd generation and later\n                        iPad mini 5th generation and later\n                    \n                Agora recommends that you use this function in scenarios that meet the following conditions:\n                    A high-definition camera device is used, and the environment is uniformly lit.\n                    There are few objects in the captured video. Portraits are half-length and unobstructed. Ensure that the background is a solid color that is different from the color of the user's clothing.\n                \n                The virtual background feature does not support video in the texture format or video obtained from custom video capture by the Push method.",
        "parameters": [
            {
                "enabled": "Whether to enable virtual background:\n                        true: Enable virtual background.\n                        false: Disable virtual background.\n                    "
            },
            {
                "backgroundSource": "The custom background image. See VirtualBackgroundSource. To adapt the resolution of the custom background image to that of the video captured by the SDK, the SDK scales and crops the custom background image while ensuring that the content of the custom background image is not distorted."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_enablewebsdkinteroperability",
        "name": "enableWebSdkInteroperability",
        "description": "Enables interoperability with the Agora Web SDK (applicable only in the live streaming scenarios).\nDeprecated:\n  The SDK automatically enables interoperability with the Web SDK, so you no longer need to call this method.\n       \n   \n   This method enables or disables interoperability with the Agora Web SDK. If the channel has Web SDK users, ensure that you call this method, or the video of the Native user will be a black screen for the Web user.\n   This method is only applicable in live streaming scenarios, and interoperability is enabled by default in communication scenarios.",
        "parameters": [
            {
                "enabled": "Whether to enable interoperability with the Agora Web SDK.\n      true: Enable interoperability.\n      false: (Default) Disable interoperability.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_enumeratedisplays",
        "name": "enumerateDisplays",
        "description": "Enumerates the information of all the screens in the system.\n",
        "parameters": [],
        "returns": "The information of the screen for screen-sharing."
    },
    {
        "id": "api_enumeratewindows",
        "name": "enumerateWindows",
        "description": "Enumerates the information of all the windows in the system.\n",
        "parameters": [],
        "returns": "The information of the window for screen-sharing."
    },
    {
        "id": "api_getassetabsolutepath",
        "name": "getAssetAbsolutePath",
        "description": "Gets the actual absolute path of the asset through the relative path of the asset.\n",
        "parameters": [
            {
                "assetPath": "The resource path configured in the flutter -> assets field of pubspec.yaml, for example: assets/Sound_Horizon.mp3."
            }
        ],
        "returns": "The actual path of the asset."
    },
    {
        "id": "api_getaudiofileinfo",
        "name": "getAudioFileInfo",
        "description": "Gets the information of a specified audio file.\nAfter calling this method successfully, the SDK triggers the requestAudioFileInfoCallback callback to report the information of an audio file, such as audio duration. You can call this method multiple times to get the information of multiple audio files.\n            \n                \n                    For the audio file formats supported by this method, see What formats of audio files does the Agora RTC SDK support.\n            Call this method after joining a channel.",
        "parameters": [
            {
                "filePath": "The file path:\n                    \n                        Android: The file path, including the filename extensions. To access an online file, Agora\n                            supports using a URL address; to access a local file, Agora supports using a URI address, an absolute path, or a path that starts\n                            with /assets/. You might encounter permission issues if you use an absolute path to access a local file, so Agora recommends\n                            using a URI address instead. For example: content://com.android.providers.media.documents/document/audio%3A14441.\n                        Windows: The absolute path or URL address (including the filename extensions) of the audio file.\n                            For example: C:\\music\\audio.mp4.\n                        iOS or macOS: The absolute path or URL address (including the filename extensions) of the audio file. For example: /var/mobile/Containers/Data/audio.mp4.\n                    "
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_getaudiomixingcurrentposition",
        "name": "getAudioMixingCurrentPosition",
        "description": "Retrieves the playback position (ms) of the music file.\nRetrieves the playback position (ms) of the audio.\n            You need to call this method after calling startAudioMixing and receiving the audioMixingStateChanged(PLAY) callback.",
        "parameters": [],
        "returns": "≥ 0: The current playback position of the audio mixing, if this method call succeeds.\n       < 0: Failure."
    },
    {
        "id": "api_getaudiomixingduration2",
        "name": "getAudioMixingDuration",
        "description": "Retrieves the duration (ms) of the music file.\nCall this method after joining a channel.",
        "parameters": [
            {
                "filePath": "The absolute path or URL address (including the suffixes of the filename) of the audio effect file. For example: Android: /sdcard/emulated/0/audio.mp4, iOS: /var/mobile/Containers/Data/audio.mp4. Supported audio formats include MP3, AAC, M4A, MP4, WAV, and 3GP. See supported audio formats."
            }
        ],
        "returns": "≥ 0: A successful method call. Returns the total duration (ms) of the specified music file.\n                < 0: Failure."
    },
    {
        "id": "api_getaudiomixingplayoutvolume",
        "name": "getAudioMixingPlayoutVolume",
        "description": "Retrieves the audio mixing volume for local playback.\nThis method helps troubleshoot audio volume‑related issues.\n            You need to call this method after calling startAudioMixing and receiving the audioMixingStateChanged(PLAY) callback.",
        "parameters": [],
        "returns": "≥ 0: The audio mixing volume, if this method call succeeds. The value range is [0,100].\n       < 0: Failure."
    },
    {
        "id": "api_getaudiomixingpublishvolume",
        "name": "getAudioMixingPublishVolume",
        "description": "Retrieves the audio mixing volume for publishing.\nThis method helps troubleshoot audio volume‑related issues.\n            You need to call this method after calling startAudioMixing and receiving the audioMixingStateChanged(PLAY) callback.",
        "parameters": [],
        "returns": "≥ 0: The audio mixing volume, if this method call succeeds. The value range is [0,100].\n       < 0: Failure."
    },
    {
        "id": "api_getaudiotrackcount",
        "name": "getAudioTrackCount",
        "description": "Gets the audio track index of the current music file.\nFor the audio file formats supported by this method, see What formats of audio files does the Agora RTC SDK support.\n            This method is for Android, iOS, and Windows only.\n                    Call this method after calling startAudioMixing and receiving the audioMixingStateChanged(AUDIO_MIXING_STATE_PLAYING)\n                    callback.",
        "parameters": [],
        "returns": "≥ 0: The audio track index of the current music file, if this method call\n                    succeeds.\n                < 0: Failure."
    },
    {
        "id": "api_getcallid",
        "name": "getCallId",
        "description": "Retrieves the call ID.\nWhen a user joins a channel on a client, a callId is generated to identify the call from the client. Some methods, such as rate and complain, must be called after the call ends to submit feedback to the SDK. These methods require the callId parameter.\n   Call this method after joining a channel.",
        "parameters": [],
        "returns": "The current call ID."
    },
    {
        "id": "api_getcameramaxzoomfactor",
        "name": "getCameraMaxZoomFactor",
        "description": "Gets the maximum zoom ratio supported by the camera.\nCall this method before calling joinChannel, enableVideo, or enableLocalVideo, depending on which method you use to turn on your local camera.",
        "parameters": [],
        "returns": "The maximum zoom factor."
    },
    {
        "id": "api_getconnectionstate",
        "name": "getConnectionState",
        "description": "Gets the current connection state of the SDK.\nYou can call this method either before or after joining a channel.",
        "parameters": [],
        "returns": "The current connection state."
    },
    {
        "id": "api_geteffectcurrentposition",
        "name": "getEffectCurrentPosition",
        "description": "Retrieves the playback position of the audio effect file.\nCall this method after playEffect.",
        "parameters": [
            {
                "soundId": "The audio effect ID. The ID of each audio effect file is unique."
            }
        ],
        "returns": "≥ 0: A successful method call. Returns the playback position (ms) of the specified audio effect file.\n                < 0: Failure."
    },
    {
        "id": "api_geteffectduration",
        "name": "getEffectDuration",
        "description": "Retrieves the duration of the audio effect file.\nCall this method after joining a channel.",
        "parameters": [
            {
                "filePath": "The absolute path or URL address (including the suffixes of the filename) of the audio effect file. For example: Android: /sdcard/emulated/0/audio.mp4, iOS: /var/mobile/Containers/Data/audio.mp4. Supported audio formats include MP3, AAC, M4A, MP4, WAV, and 3GP. See supported audio formats.\n                        "
            }
        ],
        "returns": "≥ 0: A successful method call. Returns the total duration (ms) of the specified audio effect file.\n                < 0: Failure."
    },
    {
        "id": "api_geteffectsvolume",
        "name": "getEffectsVolume",
        "description": "Retrieves the volume of the audio effects.\nThe volume is an integer ranging from 0 to 100. The default value is 100, the original volume.",
        "parameters": [],
        "returns": "Volume of the audio effects, if this method call succeeds.\n       < 0: Failure."
    },
    {
        "id": "api_geterrordescription",
        "name": "getErrorDescription",
        "description": "Gets the warning or error description.\n",
        "parameters": [
            {
                "error": "The error code or warning code reported by the SDK."
            }
        ],
        "returns": "The specific error or warning description."
    },
    {
        "id": "api_getnativehandle",
        "name": "getNativeHandle",
        "description": "Gets the C++ handle of the Native SDK.\nThis method is used to retrieve the native C++ handle of the SDK engine used in special scenarios, such as registering the audio and video frame observer.",
        "parameters": [],
        "returns": "The native handle of the SDK."
    },
    {
        "id": "api_getscreensharehelper",
        "name": "getScreenShareHelper",
        "description": "Gets a child process object.\n",
        "parameters": [
            {
                "appGroup": "The app group."
            }
        ],
        "returns": "A child process object, which can be used in scenarios such as screen sharing."
    },
    {
        "id": "api_getuserinfobyuid",
        "name": "getUserInfoByUid",
        "description": "Gets the user information by passing in the user ID.\nAfter a remote user joins the channel, the SDK gets the UID and user account of the remote user, caches them in a mapping table object, and triggers the userInfoUpdated callback on the local client. After receiving the callback, you can call this method to get the user account of the remote user from the UserInfo object by passing in the user ID.",
        "parameters": [
            {
                "uid": "User ID."
            }
        ],
        "returns": "The UserInfo object that identifies the user information.\n            \n                Not null: Success.\n                Null: Failure."
    },
    {
        "id": "api_getuserinfobyuseraccount",
        "name": "getUserInfoByUserAccount",
        "description": "Gets the user information by passing in the user account.\nAfter a remote user joins the channel, the SDK gets the UID and user account of the remote user, caches them in a mapping table object, and triggers the userInfoUpdated callback on the local client. After receiving the callback, you can call this method to get the user account of the remote user from the UserInfo object by passing in the user ID.",
        "parameters": [
            {
                "userAccount": "The user account."
            }
        ],
        "returns": "The UserInfo object that identifies the user information.\n            \n                Not null: Success.\n                Null: Failure."
    },
    {
        "id": "api_getversion",
        "name": "getSdkVersion",
        "description": "Gets the SDK version.\n",
        "parameters": [],
        "returns": "The SDK version number. The format is a string."
    },
    {
        "id": "api_iaudiodevicemanager_enumerateplaybackdevices",
        "name": "enumerateAudioPlaybackDevices",
        "description": "Enumerates the audio playback devices.\n",
        "parameters": [],
        "returns": "Success: Returns a MediaDeviceInfo list that contains\n                    the device ID and device name of all the audio playback devices.\n       Failure: null."
    },
    {
        "id": "api_iaudiodevicemanager_enumeraterecordingdevices",
        "name": "enumerateAudioRecordingDevices",
        "description": "Enumerates the audio capture devices.\n",
        "parameters": [],
        "returns": "Success: Returns a MediaDeviceInfo list that contains the device ID and device name of all the audio recording devices.\n       Failure: null."
    },
    {
        "id": "api_iaudiodevicemanager_getplaybackdevice",
        "name": "getAudioPlaybackDevice",
        "description": "Retrieves the audio playback device associated with the device ID.\n",
        "parameters": [],
        "returns": "The current audio playback device."
    },
    {
        "id": "api_iaudiodevicemanager_getplaybackdeviceinfo",
        "name": "getAudioPlaybackDeviceInfo",
        "description": "Retrieves the audio playback device information associated with the device ID and device name.\n",
        "parameters": [],
        "returns": "A MediaDeviceInfo class, which includes the device ID and the device name."
    },
    {
        "id": "api_iaudiodevicemanager_getplaybackdevicemute",
        "name": "getAudioPlaybackDeviceMute",
        "description": "Retrieves whether the audio playback device is muted.\n",
        "parameters": [],
        "returns": "true: The audio playback device is muted.\nfalse: The audio playback device is unmuted."
    },
    {
        "id": "api_iaudiodevicemanager_getplaybackdevicevolume",
        "name": "getAudioPlaybackDeviceVolume",
        "description": "Retrieves the volume of the audio playback device.\n",
        "parameters": [],
        "returns": "The volume of the audio playback device. The value ranges between 0 (lowest volume) and 255 (highest volume)."
    },
    {
        "id": "api_iaudiodevicemanager_getrecordingdevice",
        "name": "getAudioRecordingDevice",
        "description": "Gets the current audio recording device.\n",
        "parameters": [],
        "returns": "The current audio recording device."
    },
    {
        "id": "api_iaudiodevicemanager_getrecordingdeviceinfo",
        "name": "getAudioRecordingDeviceInfo",
        "description": "Retrieves the audio capture device information associated with the device ID and device name.\n",
        "parameters": [],
        "returns": "A MediaDeviceInfo class that contains the device ID and device name of all the audio recording devices."
    },
    {
        "id": "api_iaudiodevicemanager_getrecordingdevicemute",
        "name": "getAudioRecordingDeviceMute",
        "description": "Gets the microphone's mute status.\n",
        "parameters": [],
        "returns": "true: The microphone is muted.\n                            false: The microphone is unmuted."
    },
    {
        "id": "api_iaudiodevicemanager_getrecordingdevicevolume",
        "name": "getAudioRecordingDeviceVolume",
        "description": "Retrieves the volume of the audio recording device.\n",
        "parameters": [],
        "returns": "The volume of the audio recording device. The value ranges between 0 (lowest volume) and 255 (highest volume)."
    },
    {
        "id": "api_iaudiodevicemanager_setplaybackdevice",
        "name": "setAudioPlaybackDevice",
        "description": "Sets the audio playback device.\n",
        "parameters": [
            {
                "deviceId": "The ID of the audio playback device. You can get the device ID by calling enumerateAudioPlaybackDevices. Plugging or unplugging the audio device does not change the device ID.\n                        "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_iaudiodevicemanager_setplaybackdevicemute",
        "name": "setAudioPlaybackDeviceMute",
        "description": "Mutes the audio playback device.\n",
        "parameters": [
            {
                "mute": "Whether to mute the audio playback device:\n      true: Mute the audio playback device.\n      false: Unmute the audio playback device.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_iaudiodevicemanager_setplaybackdevicevolume",
        "name": "setAudioPlaybackDeviceVolume",
        "description": "Sets the volume of the audio playback device.\n",
        "parameters": [
            {
                "volume": "The volume of the audio playback device. The value ranges between 0 (lowest volume) and 255 (highest volume)."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_iaudiodevicemanager_setrecordingdevice",
        "name": "setAudioRecordingDevice",
        "description": "Sets the audio capture device.\n",
        "parameters": [
            {
                "deviceId": "The ID of the audio capture device. You can get the device ID by calling enumerateAudioRecordingDevices. Plugging or unplugging the audio device does not change the device ID.\n      "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_iaudiodevicemanager_setrecordingdevicemute",
        "name": "setAudioRecordingDeviceMute",
        "description": "Sets the mute status of the audio capture device.\n",
        "parameters": [
            {
                "mute": "Whether to mute the audio capture device:\n      true: Mute the audio capture device.\n      false: Unmute the audio capture device.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_iaudiodevicemanager_setrecordingdevicevolume",
        "name": "setAudioRecordingDeviceVolume",
        "description": "Sets the volume of the audio capture device.\n",
        "parameters": [
            {
                "volume": "The volume of the audio recording device. The value ranges between 0 (lowest volume) and 255 (highest volume)."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_iaudiodevicemanager_startaudiodeviceloopbacktest",
        "name": "startAudioDeviceLoopbackTest",
        "description": "Starts an audio device loopback test.\nThis method tests whether the local audio capture device and playback device are working properly. After starting the test, the audio capture device records the local audio, and the audio playback device plays the captured audio. The SDK triggers two independent audioVolumeIndication callbacks at the time interval set in this method, which reports the volume information of the capture device (uid = 0) and the volume information of the playback device (uid = 1) respectively.\n   \n       Ensure that you call this method before joining a channel.\n       This method tests local audio devices and does not report the network conditions.",
        "parameters": [
            {
                "indicationInterval": "The time interval (ms) at which the SDK triggers the audioVolumeIndication callback. Agora recommends a setting greater than 200 ms. This value must not be less than 10 ms; otherwise, you can not receive the audioVolumeIndication callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_iaudiodevicemanager_startplaybackdevicetest",
        "name": "startAudioPlaybackDeviceTest",
        "description": "Starts the audio playback device test.\nThis method tests whether the audio playback device works properly. Once a user starts the test, the SDK plays an audio file specified by the user. If the user can hear the audio, the playback device works properly.\n   After calling this method, the SDK triggers the audioVolumeIndication callback every 100 ms, reporting uid = 1 and the volume information of the playback device.\n            Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "testAudioFilePath": "The path of the audio file for the audio playback device test in UTF-8.\n      Supported file formats: wav, mp3, m4a, and aac.\n      Supported file sample rates: 8000, 16000, 32000, 44100, and 48000 Hz.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_iaudiodevicemanager_startrecordingdevicetest",
        "name": "startAudioRecordingDeviceTest",
        "description": "Starts the audio capture device test.\nThis method tests whether the audio capture device works properly. After calling this method, the SDK triggers the audioVolumeIndication callback at the time interval set in this method, which reports uid = 0 and the volume information of the capture device.\n            Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "indicationInterval": "The time interval (ms) at which the SDK triggers the audioVolumeIndication callback. Agora recommends a setting greater than 200 ms. This value must not be less than 10 ms; otherwise, you can not receive the audioVolumeIndication callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_iaudiodevicemanager_stopaudiodeviceloopbacktest",
        "name": "stopAudioDeviceLoopbackTest",
        "description": "Stops the audio device loopback test.\nEnsure that you call this method before joining a channel.\n           Ensure that you call this method to stop the loopback test after calling the startAudioDeviceLoopbackTest method.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_iaudiodevicemanager_stopplaybackdevicetest",
        "name": "stopAudioPlaybackDeviceTest",
        "description": "Stops the audio playback device test.\nThis method stops the audio playback device test. You must call this method to stop the test after calling the startAudioPlaybackDeviceTest method.\n        Ensure that you call this method before joining a channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_iaudiodevicemanager_stoprecordingdevicetest",
        "name": "stopAudioRecordingDeviceTest",
        "description": "Stops the audio capture device test.\nThis method stops the audio capture device test. You must call this method to stop the test after calling the startAudioRecordingDeviceTest method.\n   Ensure that you call this method before joining a channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_ichannel_addinjectstreamurl",
        "name": "addInjectStreamUrl",
        "description": "Injects an online media stream to a live streaming channel.\nAgora will soon stop the service for injecting online media streams on the client. If you have not implemented this service, Agora recommends that you do not use it. For details, see Service Sunset Plans.\n   \n  \n      Ensure that you enable the RTMP Converter service before using this function. See Prerequisites in Push Streams to CDN.\n      This method takes effect only when you are a host in a live streaming channel.\n      Only one online media stream can be injected into the same channel at the same time.\n      Call this method after joining a channel.\n  \n       \n   This method injects the currently playing audio and video as audio and video sources into the\n                ongoing live broadcast. This applies to scenarios where all users in the channel can\n                watch a live show and interact with each other. After calling this method, the SDK\n                triggers the streamInjectedStatus callback on the local client to\n                report the state of injecting the online media stream; after successfully injecting\n                the media stream, the stream joins the channel, and all users in the channel receive\n                the userJoined callback, where uid is\n                    666.",
        "parameters": [
            {
                "url": "The URL address to be added to the ongoing streaming. Valid protocols are RTMP, HLS, and HTTP-FLV.\n     Supported audio codec type: AAC.\n     Supported video codec type: H264 (AVC).\n \n      \n  "
            },
            {
                "config": "The configuration information for the added voice or video stream: LiveInjectStreamConfig."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_addpublishstreamurl",
        "name": "addPublishStreamUrl",
        "description": "Publishes the local stream to a specified CDN live streaming URL.\nCall this method after joining a channel.\n           Ensure that you enable the RTMP Converter service before using this function. \n  This method takes effect only when you are a host in live interactive streaming.\n  This method adds only one stream CDN streaming URL each time it is called. To push multiple URLs, call this method multiple times.\n  Agora supports pushing media streams in RTMPS protocol to the CDN only when you enable transcoding.\n       \n   \n        After calling this method, you can push media streams in RTMP or RTMPS protocol to the CDN. The SDK triggers the rtmpStreamingStateChanged callback on the local client to report the state of adding a local stream to the CDN.",
        "parameters": [
            {
                "url": "The CDN streaming URL in the RTMP or RTMPS format. The maximum length of this parameter is 1024 bytes. The URL address must not contain special characters, such as Chinese language characters."
            },
            {
                "transcodingEnabled": "Whether to enable transcoding. Transcoding in a CDN live streaming converts the audio and video streams before pushing them to the CDN server. It applies to scenarios where a channel has multiple broadcasters and composite layout is needed\n                                true: Enable transcoding.\n                                false: Disable transcoding.\n                            \n      If you set this parameter as true , ensure that you call the setLiveTranscoding method before this method.\n       "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_adjustuserplaybacksignalvolume",
        "name": "adjustUserPlaybackSignalVolume",
        "description": "Adjusts the playback signal volume of a specified remote user.\nYou can call this method to adjust the playback volume of a specified remote user. To adjust the playback volume of different remote users, call the method as many times, once for each remote user.\n   \n       \n  Call this method after joining a channel.\n  The playback volume here refers to the mixed volume of a specified remote user.",
        "parameters": [
            {
                "null": ""
            },
            {
                "uid": "The ID of the remote user."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_channelId",
        "name": "channelId",
        "description": "Gets the current channel ID.\n",
        "parameters": [],
        "returns": "The current channel ID, if the method call succeeds.\n       The empty string \"\", if the method call fails."
    },
    {
        "id": "api_ichannel_createdatastream",
        "name": "createDataStream",
        "description": "Creates a data stream.\nCall this method after joining a channel.\n  Agora does not support setting reliable as true and ordered as true.\n       \n   \n        Each user can create up to five data streams during the lifecycle of RtcEngine.\n   \n       \n  Deprecated:\n  Please use createDataStreamWithConfig instead.",
        "parameters": [
            {
                "ordered": "Whether or not the recipients receive the data stream in the sent order:\n      true: The recipients receive the data in the sent order.\n      false: The recipients do not receive the data in the sent order.\n  "
            },
            {
                "reliable": "Whether or not the data stream is reliable:\n                            true: The recipients receive the\n                                data from the sender within five seconds. If the recipient does not\n                                receive the data within five seconds, the SDK triggers the streamMessageError callback and returns an\n                                error code.\n                            false: There is no guarantee that\n                                the recipients receive the data stream within five seconds and no\n                                error message is reported for any delay or missing data stream.\n                            \n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_createdatastream2",
        "name": "createDataStreamWithConfig",
        "description": "Creates a data stream.\nCompared with createDataStream[1/2], this method does not support data reliability. If a data packet is not received five seconds after it was sent, the SDK directly discards the data.\n        Creates a data stream. Each user can create up to five data streams in a single channel.",
        "parameters": [
            {
                "config": "The configurations for the data stream. For details, see DataStreamConfig."
            }
        ],
        "returns": "ID of the created data stream, if the method call succeeds.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_enableencryption",
        "name": "enableEncryption",
        "description": "Enables/Disables the built-in encryption.\nIn scenarios requiring high security, Agora recommends calling this method to enable the built-in encryption before joining a channel.\n               All users in the same channel must use the same encryption mode and encryption key. After the user leaves the channel, the SDK automatically disables the built-in encryption. To enable the built-in encryption, call this method before the user joins the channel again.\n               If you enable the built-in encryption, you cannot use the RTMP or RTMPS streaming function.",
        "parameters": [
            {
                "enabled": "Whether to enable built-in encryption:\n                                        true: Enable the built-in encryption.\n                                        false: Disable the built-in encryption.\n                                   \n                              \n                         "
            },
            {
                "config": "Configurations of built-in encryption. For details, see EncryptionConfig."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_enableremotesuperresolution",
        "name": "enableRemoteSuperResolution",
        "description": "Enables/Disables the super-resolution algorithm for a remote user's video stream.\nThis feature effectively boosts the resolution of a remote user's video seen by the local user. If the original resolution of a remote user's video is a × b, the local user's device can render the remote video at a resolution of 2a × 2b\n            after you enable this feature.\n            After you call this method, the SDK triggers the userSuperResolutionEnabled callback to report whether you have successfully enabled super resolution.\n            The super resolution feature requires extra system resources. To balance the visual experience and system usage, the SDK poses the following restrictions: This feature can only be enabled for a single remote user.\n                On Android, the original resolution of the remote video must not exceed 640 × 360 pixels. On iOS, the original resolution of the remote video must not exceed 640 × 480 pixels. If you exceed these limitations, the SDK triggers the warning callback and returns the corresponding warning codes:\n                SuperResolutionStreamOverLimitation: 1610. The origin resolution of the remote video is beyond the range where the super resolution can be applied.\n                SuperResolutionUserCountOverLimitation: 1611. Super resolution is already being used on another remote user's video.\n                SuperResolutionDeviceNotSupported: 1612. The device does not support using super resolution.\n            \n            \n                \n                    This method is for Android and iOS only.\n                    Before calling this method, ensure that you have integrated the following dynamic libraries:\n                        Android: libagora_super_resolution_extension.so\n                        iOS: AgoraSuperResolutionExtension.xcframework\n                    \n                    \n                    Because this method has certain system performance requirements, Agora recommends that you use the following devices or better:\n                        Android:\n                            VIVO: V1821A, NEX S, 1914A, 1916A, 1962A, 1824BA, X60, X60 Pro\n                            OPPO: PCCM00, Find X3\n                            OnePlus: A6000\n                            Xiaomi: Mi 8, Mi 9, Mi 10, Mi 11, MIX3, Redmi K20 Pro\n                            SAMSUNG: SM-G9600, SM-G9650, SM-N9600, SM-G9708, SM-G960U, SM-G9750, S20, S21\n                            HUAWEI: SEA-AL00, ELE-AL00, VOG-AL00, YAL-AL10, HMA-AL00, EVR-AN00, nova 4, nova 5 Pro, nova 6 5G, nova 7 5G, Mate 30, Mate 30 Pro, Mate 40, Mate 40 Pro, P40, P40 Pro, Huawei M6, MatePad 10.8\n                        \n                        iOS:\n                            iPhone XR\n                            iPhone XS\n                            iPhone XS Max\n                            iPhone 11\n                            iPhone 11 Pro\n                            iPhone 11 Pro Max\n                            iPhone 12\n                            iPhone 12 mini\n                            iPhone 12 Pro\n                            iPhone 12 Pro Max\n                            iPhone 12 SE (2nd generation)\n                            iPad Pro 11-inch (3rd generation)\n                            iPad Pro 12.9-inch (3rd generation)\n                            iPad Air 3 (3rd generation)\n                            iPad Air 3 (4th generation)",
        "parameters": [
            {
                "userId": "The ID of the remote user."
            },
            {
                "enable": "Whether to enable super resolution for the remote user’s video:\n                        true: Enable virtual background.\n                        false: Do not enable virtual background.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_getcallid",
        "name": "getCallId",
        "description": "Retrieves the call ID.\nWhen a user joins a channel on a client, a callId is generated to identify the call from the client. Some methods, such as rate and complain, must be called after the call ends to submit feedback to the SDK. These methods require the callId parameter.\n   Call this method after joining a channel.",
        "parameters": [],
        "returns": "The current call ID."
    },
    {
        "id": "api_ichannel_getconnectionstate",
        "name": "getConnectionState",
        "description": "Gets the current connection state of the SDK.\nYou can call this method either before or after joining a channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_ichannel_joinchannel",
        "name": "joinChannel",
        "description": "Joins the channel with a user ID.\nOnce the user joins the channel, the user subscribes to the audio and video streams of all the other users in the channel by default, giving rise to usage and billing calculation. If you do not want to subscribe to a specified stream or all remote streams, call the mute methods accordingly.\n   \n       \n  If you are already in a channel, you cannot rejoin it with the user ID.\n  We recommend using different UIDs for different channels.\n  If you want to join the same channel from different devices, ensure that the user IDs in all devices are different.",
        "parameters": [
            {
                "options": "The channel media options. For details, see ChannelMediaOptions."
            },
            {
                "token": "The token generated on your server for authentication. See Authenticate Your Users with Token.\n    Ensure that the App ID used for creating the token is the same App ID used by the createWithContext method for initializing the RTC engine.\n      "
            },
            {
                "optionalUid": "User ID. This parameter is used to identify the user in the channel for real-time audio and video interaction. You need to set and manage user IDs yourself, and ensure that each user ID in the same channel is unique. This parameter is a 32-bit unsigned integer with a value ranging from 1 to 232 -1. If the user ID is not assigned (or set as 0), the SDK assigns a user ID and reports it in the joinChannelSuccess callback. Your app must maintain this user ID."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_joinchannelwithuseraccount",
        "name": "joinChannelWithUserAccount",
        "description": "Joins the channel with a user account.\nOnce the user joins the channel, the user subscribes to the audio and video streams of all the other users in the channel by default, giving rise to usage and billing calculation. If you do not want to subscribe to a specified stream or all remote streams, call the mute methods accordingly.\n   \n       \n  If you are already in a channel, you cannot rejoin it with the user ID.\n  We recommend using different user accounts for different channels.\n  If you want to join the same channel from different devices, ensure that the user accounts in all devices are different.",
        "parameters": [
            {
                "options": "The channel media options. For details, see ChannelMediaOptions."
            },
            {
                "userAccount": "The user account. This parameter is used to identify the user in the channel for real-time audio and video engagement. You need to set and manage user accounts yourself and ensure that each user account in the same channel is unique.   The maximum length of this parameter is 255 bytes. Ensure that you set this parameter and do not set it as null. Supported characters are (89 in total):\n                                The 26 lowercase English letters: a to z.\n                                The 26 uppercase English letters: A to Z.\n                                All numeric characters: 0 to 9.\n                                Space\n                                \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\", \".\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \"{\", \"}\", \"|\", \"~\", \",\"\n                            \n                    "
            },
            {
                "token": "The token generated on your server for authentication. See Authenticate Your Users with Token.\n    Ensure that the App ID used for creating the token is the same App ID used by the createWithContext method for initializing the RTC engine.\n      "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_leavechannel",
        "name": "leaveChannel",
        "description": "Leaves a channel.\nThis method lets the user leave the channel, for example, by hanging up or exiting the call. This method releases all resources related to the session. This method call is asynchronous, and the user has not left the channel when the method call returns.\n   After calling joinChannel, you must call leaveChannel to end the call, otherwise the next call cannot be started.\n   No matter whether you are currently in a call or not, you can call leaveChannel without side effects.\n   A successful call of this method triggers the following callbacks: \n                    The local client: leaveChannel.\n                    The remote client: userOffline, if the user\n                        joining the channel is in the COMMUNICATION profile, or is a host in the\n                        LIVE_BROADCASTING profile.\n                \n   \n       \n  If you call the leaveChannel method immediately after calling destroy, the SDK will not be able to trigger the leaveChannel callback.\n  If you call the leaveChannel method during a CDN live streaming, the SDK automatically calls the removePublishStreamUrl method.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_ichannel_muteallremoteaudiostreams",
        "name": "muteAllRemoteAudioStreams",
        "description": "Stops or resumes subscribing to the audio streams of all remote users.\nAs of v3.3.0, after successfully calling this method, the local user stops or resumes subscribing to the audio streams of all remote users, including all subsequent users.\n   \n       \n  Call this method after joining a channel.",
        "parameters": [
            {
                "muted": "Whether to subscribe to the audio streams of all remote users:\n                                true: Do not subscribe to the audio streams of all remote users.\n                                false: (Default) Subscribe to the audio streams of all remote users by default.\n                            \n                        \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_muteallremotevideostreams",
        "name": "muteAllRemoteVideoStreams",
        "description": "Stops or resumes subscribing to the video streams of all remote users.\nAs of v3.3.0, after successfully calling this method, the local user stops or resumes subscribing to the video streams of all remote users, including all subsequent users.\n   \n       \n  Call this method after joining a channel.",
        "parameters": [
            {
                "muted": "Whether to stop subscribing to the video streams of all remote users.\n     true: Stop subscribing to the video streams of all remote users.\n     false: (Default) Subscribe to the audio streams of all remote users by default.\n \n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_mutelocalaudiostream",
        "name": "muteLocalAudioStream",
        "description": "Stops or resumes publishing the local audio stream.\n",
        "parameters": [
            {
                "mute": "Whether to stop publishing the local audio stream.\n  \n      true: Stop publishing the local audio stream.\n      false: (Default) Resumes publishing the local audio stream.\n  \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_mutelocalvideostream",
        "name": "muteLocalVideoStream",
        "description": "Stops or resumes publishing the local video stream.\n",
        "parameters": [
            {
                "mute": "Whether to stop publishing the local video stream.\n                            true: Stop publishing the local video stream.\n                            false: (Default) Publish the local video stream.\n                        \n                        \n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_muteremoteaudiostream",
        "name": "muteRemoteAudioStream",
        "description": "Stops or resumes subscribing to the audio stream of a specified user.\nCall this method after joining a channel.\n  See recommended settings in Set the Subscribing State.",
        "parameters": [
            {
                "userId": "The user ID of the specified user."
            },
            {
                "muted": "Whether to stop subscribing to the audio stream of the specified user.\n      \n true: Stop subscribing to the audio stream of the specified user.\n false: (Default) Subscribe to the audio stream of the specified user.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_muteremotevideostream",
        "name": "muteRemoteVideoStream",
        "description": "Stops or resumes subscribing to the video stream of a specified user.\nCall this method after joining a channel.\n  See recommended settings in Set the Subscribing State.",
        "parameters": [
            {
                "userId": "The ID of the specified user."
            },
            {
                "muted": "Whether to stop subscribing to the video stream of the specified user.\n      true: Stop subscribing to the video streams of the specified user.\n      false: (Default) Subscribe to the video stream of the specified user.\n  \n      "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_pauseallchannelmediarelay",
        "name": "pauseAllChannelMediaRelay",
        "description": "Pauses the media stream relay to all destination channels.\nAfter the cross-channel media stream relay starts, you can call this method to pause relaying media streams to all destination channels; after the pause, if you want to resume the relay, call resumeAllChannelMediaRelay.\n            After a successful method call, the SDK triggers the channelMediaRelayEvent callback to report whether the media stream relay is successfully paused.\n            Call this method after startChannelMediaRelay.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_ichannel_publish",
        "name": "publish",
        "description": "Publish local audio and video streams to the channel.\nThe call of this method must meet the following requirements, otherwise the SDK returns -5(ERR_REFUSED):\n  This method only supports publishing audio and video streams to the channel corresponding to the current RtcChannel object.\n  In the interactive live streaming channel, only a host can call this method. To switch the client role, call setClientRole of the current RtcChannel object.\n  You can publish a stream to only one channel at a time. For details on joining multiple channels, see the advanced guide Join Multiple Channels.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_ichannel_registermediametadataobserver",
        "name": "registerMediaMetadataObserver",
        "description": "Registers the metadata observer.\nCall this method before joinChannel.\n  This method applies only to interactive live streaming.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_ichannel_release",
        "name": "destroy",
        "description": "Releases the RtcChannel instance.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_ichannel_releaseall",
        "name": "destroyAll",
        "description": "Destroys all RtcChannel instance.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_ichannel_removeinjectstreamurl",
        "name": "removeInjectStreamUrl",
        "description": "Removes the voice or video stream URL address from the live streaming.\nAfter a successful method, the SDK triggers the userOffline callback\n                with the uid of 666.",
        "parameters": [
            {
                "url": "The URL address of the injected stream to be removed."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_removepublishstreamurl",
        "name": "removePublishStreamUrl",
        "description": "Removes an RTMP or RTMPS stream from the CDN.\nEnsure that you enable the RTMP Converter service before using this function.\n           This method takes effect only when you are a host in live interactive streaming.\n           Call this method after joining a channel.\n           This method removes only one CDN streaming URL each time it is called. To remove multiple URLs, call this method multiple times.\n       \n   \n        After a successful method call, the SDK triggers rtmpStreamingStateChanged on the local client to report the result of deleting the address.",
        "parameters": [
            {
                "url": "The CDN streaming URL to be removed. The maximum length of this parameter is 1024 bytes. The CDN streaming URL must not contain special characters, such as Chinese characters."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_renewtoken",
        "name": "renewToken",
        "description": "Gets a new token when the current token expires after a period of time.\nPasses a new token to the SDK. A token expires after a certain period of time. The app should get a new token and call this method to pass the token to the SDK. Failure to do so results in the SDK disconnecting from the server.\n                    The SDK triggers the tokenPrivilegeWillExpire callback.\n                    The connectionStateChanged callback reports TokenExpired(9).",
        "parameters": [
            {
                "token": "The new token."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_resumeallchannelmediarelay",
        "name": "resumeAllChannelMediaRelay",
        "description": "Resumes the media stream relay to all destination channels.\nAfter calling the pauseAllChannelMediaRelay method, you can call this method to resume relaying media streams to all destination channels.\n            After a successful method call, the SDK triggers the channelMediaRelayEvent callback to report whether the media stream relay is successfully resumed.\n            Call this method after the pauseAllChannelMediaRelay method.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_ichannel_sendmetadata",
        "name": "sendMetadata",
        "description": "Sends media metadata.\nIf the metadata is sent successfully, the SDK triggers the metadataReceived callback on the receiver.",
        "parameters": [
            {
                "metadata": "Media metadata. See Metadata."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_sendstreammessage",
        "name": "sendStreamMessage",
        "description": "Sends data stream messages.\nSends data stream messages to all users in a channel. The SDK has the following restrictions on this method:Up to 30 packets can be sent per second in a channel with each packet having a maximum size of 1 KB.Each client can send up to 6 KB of data per second.Each user can have up to five data streams simultaneously.\n   A successful method call triggers the streamMessage callback on the remote client, from which the remote user gets the stream message. A failed method call triggers the streamMessageError callback on the remote client.\n   \n       Ensure that you call createDataStreamWithConfig to create a data channel before calling this method.\n       In live streaming scenarios, this method only applies to hosts.",
        "parameters": [
            {
                "streamId": "The data stream ID. You can get the data stream ID by calling createDataStreamWithConfig."
            },
            {
                "message": "The message to be sent."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_setchanneleventhandler",
        "name": "setEventHandler",
        "description": "Sets the event handler for the RtcChannel object.\nAfter setting the channel event handler, you can listen for channel events and receive the statistics of the corresponding RtcChannel object.",
        "parameters": [
            {
                "handler": "The event handler for the RtcChannel object. For details, see RtcChannelEventHandler."
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_setclientrole2",
        "name": "setClientRole",
        "description": "Sets the user role and level in an interactive live streaming channel.\nYou can call this method either before or after joining the channel to set the user role as audience or host.\n   If you call this method to switch the user role after joining the channel, the SDK triggers the following callbacks:\n       The local client: clientRoleChanged.\n       The remote client: userJoined or userOffline.\n   \n   \n       \n       This method only takes effect when the channel profile is live interactive streaming (when the profile parameter in setChannelProfile set as LiveBroadcasting).",
        "parameters": [
            {
                "role": "The user role in the interactive live streaming. See ClientRole.\n               "
            },
            {
                "options": "The detailed options of a user, including the user level. See ClientRoleOptions."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_setdefaultmuteallremoteaudiostreams",
        "name": "setDefaultMuteAllRemoteAudioStreams",
        "description": "Stops or resumes subscribing to the audio streams of all remote users by default.\nCall this method after joining a channel. After successfully calling this method, the local user stops or resumes subscribing to the audio streams of all subsequent users.\n   \n       \n  Deprecated:\n  This method is deprecated.\n       \n   \n   \n       If you need to resume subscribing to the audio streams of remote users in the channel after calling this method, do the following:\n       \n  If you need to resume subscribing to the audio stream of a specified user, call muteRemoteAudioStream (false), and specify the user ID.\n  If you need to resume subscribing to the audio streams of multiple remote users, call muteRemoteAudioStream (false) multiple times.",
        "parameters": [
            {
                "muted": "Whether to stop subscribing to the audio streams of all remote users by default.\n true: Stop subscribing to the audio streams of all remote users by default.\n false: (Default) Subscribe to the audio streams of all remote users by default.\n      \n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_setdefaultmuteallremotevideostreams",
        "name": "setDefaultMuteAllRemoteVideoStreams",
        "description": "Stops or resumes subscribing to the video streams of all remote users by default.\nCall this method after joining a channel. After successfully calling this method, the local user stops or resumes subscribing to the audio streams of all subsequent users.\n            \n       \n  Deprecated:\n  This method is deprecated.\n       \n   \n   \n       If you need to resume subscribing to the video streams of remote users in the channel, do the following:\n       \n  If you need to resume subscribing to a single user, call muteRemoteVideoStream(false) and specify the ID of the remote user you want to subscribe to.\n  If you want to resume subscribing to multiple users, call muteRemoteVideoStream(false) multiple times.",
        "parameters": [
            {
                "muted": "Whether to stop subscribing to the audio streams of all remote users by default.\n     true: Stop subscribing to the audio streams of all remote users by default.\n     false: (Default) Resume subscribing to the audio streams of all remote users by default.\n \n \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_setencryptionmode",
        "name": "setEncryptionMode",
        "description": "Sets the built-in encryption mode.\nsecret. Refer to the information related to the AES encryption algorithm on the differences between the encryption modes.\n   \n       \n  Deprecated:\n  Please use the enableEncryption method instead.\n       \n   \n   Before calling this method, please call setEncryptionSecret to enable the built-in encryption function.",
        "parameters": [
            {
                "encryptionMode": "Encryption mode.\n     \"aes-128-xts\": 128-bit AES encryption, XTS mode.\n     \"aes-128-ecb\": 128-bit AES encryption, ECB mode.\n          \"aes-256-xts\": 256-bit AES encryption, XTS mode.\n          \"sm4-128-ecb\": 128-bit SM4 encryption, ECB mode.\n          \"aes-128-gcm\": 128-bit AES encryption, GCM mode.\n          \"aes-256-gcm\": 256-bit AES encryption, GCM mode.\n          \n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_setencryptionsecret",
        "name": "setEncryptionSecret",
        "description": "Enables built-in encryption with an encryption password before users join a channel.\nDo not use this method for CDN live streaming.\n  For optimal transmission, ensure that the encrypted data size does not exceed the original data size + 16 bytes. 16 bytes is the maximum padding size for AES encryption.\n       \n   \n        Before joining the channel, you need to call this method to set the secret parameter to enable the built-in encryption. All users in the same channel should use the same secret. The secret is automatically cleared once a user leaves the channel. If you do not specify the secret or secret is set as null, the built-in encryption is disabled.\n   \n       \n  Deprecated:\n  Please use the enableEncryption method instead.",
        "parameters": [
            {
                "secret": "The encryption password."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_setlivetranscoding",
        "name": "setLiveTranscoding",
        "description": "Sets the transcoding configurations for CDN live streaming.\nThis method takes effect only when you are a host in live interactive streaming.\n  Ensure that you enable the RTMP Converter service before using this function. See Prerequisites in the advanced guide Push Streams to CDN.\n  If you call this method to set the transcoding configuration for the first time, the SDK does not trigger the transcodingUpdated callback.\n  Call this method after joining a channel.\n  Agora supports pushing media streams in RTMPS protocol to the CDN only when you enable transcoding.\n       \n   \n   This method sets the video layout and audio settings for CDN live streaming. The SDK triggers the transcodingUpdated callback when you call this method to update the transcoding setting.",
        "parameters": [
            {
                "transcoding": "The transcoding configurations for CDN live streaming. For details, see LiveTranscoding."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_setmaxmetadatasize",
        "name": "setMaxMetadataSize",
        "description": "Sets the maximum size of the media metadata.\nAfter calling registerMediaMetadataObserver, you can call this method to set the maximum size of the media metadata.",
        "parameters": [
            {
                "size": "The maximum size of media metadata."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_setremotedefaultvideostreamtype",
        "name": "setRemoteDefaultVideoStreamType",
        "description": "Sets the default stream type of remote video streams.\nThe result of this method returns in the apiCallExecuted callback.\n   By default, users receive the high-quality video stream. Call this method if you want to switch to the low-quality video stream. This method allows the app to adjust the corresponding video stream type based on the size of the video window to reduce the bandwidth and resources. The aspect ratio of the low-quality video stream is the same as the high-quality video stream. Once the resolution of the high-quality video stream is set, the system automatically sets the resolution, frame rate, and bitrate of the low-quality video stream.\n   Under limited network conditions, if the publisher has not disabled the dual-stream mode using (),the receiver can choose to receive either the high-quality video stream or the low-quality video stream. The high-quality video stream has a higher resolution and bitrate, and the low-quality video stream has a lower resolution and bitrate.enableDualStreamModefalse\n   Call this method after joining a channel. If you call both setRemoteVideoStreamType and setRemoteDefaultVideoStreamType, the setting of setRemoteVideoStreamType takes effect.",
        "parameters": [
            {
                "streamType": "The default stream type of the remote video, see VideoStreamType.\n               "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_setremoteuserpriority",
        "name": "setRemoteUserPriority",
        "description": "Prioritizes a remote user's stream.\nPrioritizes a remote user's stream. The SDK ensures the high-priority user gets the best possible stream quality. The SDK ensures the high-priority user gets the best possible stream quality.\n               \n                    \n                         The SDK supports setting only one user as high priority.\n                         Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "userPriority": "The priority of the remote user. See UserPriority."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_setremotevideostreamtype",
        "name": "setRemoteVideoStreamType",
        "description": "          Sets the stream type of the remote video.\nThe method result returns in the apiCallExecuted callback.\n               By default, users receive the high-quality video stream. Call this method if you want to switch to the low-quality video stream. This method allows the app to adjust the corresponding video stream type based on the size of the video window to reduce the bandwidth and resources. The aspect ratio of the low-quality video stream is the same as the high-quality video stream. Once the resolution of the high-quality video stream is set, the system automatically sets the resolution, frame rate, and bitrate of the low-quality video stream.\n               \n                    Under limited network conditions, if the publisher has not disabled the dual-stream mode using enableDualStreamMode(false), the receiver can choose to receive either the high-quality video stream (the high resolution, and high bitrate video stream) or the low-quality video stream (the low resolution, and low bitrate video stream). The high-quality video stream has a higher resolution and bitrate, and the low-quality video stream has a lower resolution and bitrate.\n               Call this method after joining a channel. If you call both setRemoteVideoStreamType and setRemoteDefaultVideoStreamType, the setting of setRemoteVideoStreamType takes effect.",
        "parameters": [
            {
                "streamType": "The video stream type: VideoStreamType.\n                              "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_setremotevoiceposition",
        "name": "setRemoteVoicePosition",
        "description": "Sets the 2D position (the position on the horizontal plane) of the remote user's voice.\nThis method sets the 2D position and volume of a remote user, so that the local user can easily hear and identify the remote user's position.\n   When the local user calls this method to set the voice position of a remote user, the voice difference between the left and right channels allows the local user to track the real-time position of the remote user, creating a sense of space. This method applies to massive multiplayer online games, such as Battle Royale games.\n   \n       \n  For this method to work, enable stereo panning for remote users by calling the enableSoundPositionIndication method before joining a channel.\n           For the best voice positioning, Agora recommends using a wired headset.\n  Call this method after joining a channel.",
        "parameters": [
            {
                "uid": "The user ID of the remote user."
            },
            {
                "pan": "The voice position of the remote user. The value ranges from -1.0 to 1.0:\n 0.0: (Default) The remote voice comes from the front.\n -1.0: The remote voice comes from the left.\n 1.0: The remote voice comes from the right.\n      \n  "
            },
            {
                "gain": "The volume of the remote user. The value ranges from 0.0 to 100.0. The default value is 100.0 (the original volume of the remote user). The smaller the value, the lower the volume."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_startchannelmediarelay",
        "name": "startChannelMediaRelay",
        "description": "Starts relaying media streams across channels. This method can be used to implement scenarios such as co-host across channels.\nAfter a successful method call, the SDK triggers the channelMediaRelayStateChanged and channelMediaRelayEvent callbacks, and these callbacks return the state and events of the media stream relay.\n  If the channelMediaRelayStateChanged callback returns Running(2) and None(0), and the channelMediaRelayEvent callback returns SentToDestinationChannel(4), it means that the SDK starts relaying media streams between the source channel and the destination channel.\n  If the channelMediaRelayStateChanged callback returns Failure(3), an exception occurs during the media stream relay.\n       \n   \n   \n       \n  Call this method after joining the channel.\n  This method takes effect only when you are a host in a live streaming channel.\n  After a successful method call, if you want to call this method again, ensure that you call the stopChannelMediaRelay method to quit the current relay.\n  Contact support@agora.io (https://agora-ticket.agora.io/) before implementing this function.\n  We do not support string user accounts in this API.",
        "parameters": [
            {
                "channelMediaRelayConfiguration": "The configuration of the media stream relay. For details, see ChannelMediaRelayConfiguration."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_stopchannelmediarelay",
        "name": "stopChannelMediaRelay",
        "description": "Stops the media stream relay. Once the relay stops, the host quits all the destination channels.\nAfter a successful method call, the SDK triggers the channelMediaRelayStateChanged callback. If the callback reports Idle(0) and None(0), the host successfully stops the relay.\n   If the method call fails, the SDK triggers the channelMediaRelayStateChanged callback with the ServerNoResponse(2) or ServerConnectionLost(8) status code. You can call the leaveChannel method to leave the channel, and the media stream relay automatically stops.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_ichannel_unpublish",
        "name": "unpublish",
        "description": "Stops publishing a stream to the channel.\nIf you call this method in a channel where you are not publishing streams, the SDK returns\n                    -5 (ERR_REFUSED).",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_ichannel_unregistermediametadataobserver",
        "name": "unregisterMediaMetadataObserver",
        "description": "Unregisters the media metadata observer.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_ichannel_updatechannelmediarelay",
        "name": "updateChannelMediaRelay",
        "description": "Updates the channels for media stream relay.\nAfter the media relay starts, if you want to relay the media stream to more channels, or leave the current relay channel, you can call the updateChannelMediaRelay method.\n   After a successful method call, the SDK triggers the channelMediaRelayEvent callback with the UpdateDestinationChannel(7) state code.\n   Call this method after the startChannelMediaRelay method to update the destination channel.",
        "parameters": [
            {
                "channelMediaRelayConfiguration": "The configuration of the media stream relay. For more details, see ChannelMediaRelayConfiguration."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_imediaplayer_selectaudiotrack",
        "name": "selectAudioTrack",
        "description": "Selects the audio track used during playback.\nIf the media file has multiple audio tracks, you can call this method to select the audio track used during playback.",
        "parameters": [
            {
                "index": "The index of the audio track."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_imediaplayer_setaudiomixingdualmonomode",
        "name": "setAudioMixingDualMonoMode",
        "description": "Sets the channel mode of the current audio file.\nIn a stereo music file, the left and right channels can store different audio data. According to your needs, you can set the channel mode to original mode, left channel mode, right channel mode, or mixed channel mode. For example, in the KTV scenario, the left channel of the music file stores the musical accompaniment, and the right channel stores the singing voice. If you only need to listen to the accompaniment, call this method to set the channel mode of the music file to left channel mode; if you need to listen to the accompaniment and the singing voice at the same time, call this method to set the channel mode to mixed channel mode.\n            \n                Call this method after calling startAudioMixing and receiving the audioMixingStateChanged (Playing) callback.\n                This method only applies to stereo audio files.",
        "parameters": [
            {
                "mode": "The channel mode. For details, see AudioMixingDualMonoMode."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_irtcengine2_createchannel",
        "name": "create",
        "description": "Creates and gets an RtcChannel object.\nYou can call this method multiple times to create multiple RtcChannel objects,\n                and then call the joinChannel methods of each RtcChannel to join multiple channels at the same time.\n   After joining multiple channels, you can simultaneously subscribe to the the audio and video streams of all the channels, but publish a stream in only one channel at one time.",
        "parameters": [
            {
                "channelId": "The channel name. This parameter signifies the channel in which users engage in real-time audio and video interaction. Under the premise of the same App ID, users who fill in the same channel ID enter the same channel for audio and video interaction. The string length must be less than 64 bytes. Supported characters:\n     The 26 lowercase English letters: a to z.\n     The 26 uppercase English letters: A to Z.\n     The 10 numeric characters: 0 to 9.\n     Space\n     \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\", \".\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \"{\", \"}\", \"|\", \"~\", \",\"\n \n  \n \n     The parameter does not have a default value. You must set it.\n     Do not set this parameter as the empty string \"\". Otherwise, the SDK returns ERR_REFUSED(5).\n \n      \n  "
            }
        ],
        "returns": "A pointer to the RtcChannel instance, if the method call succeeds.\n       If the call fails, returns null."
    },
    {
        "id": "api_iscameraautofocusfacemodesupported",
        "name": "isCameraAutoFocusFaceModeSupported",
        "description": "Checks whether the device supports the face auto-focus function.\nThis method needs to be called after the camera is started (for example, by calling startPreview or joinChannel).",
        "parameters": [],
        "returns": "true: The device supports the face auto-focus function.\n       false: The device does not support the face auto-focus function."
    },
    {
        "id": "api_iscameraexposurepositionsupported",
        "name": "isCameraExposurePositionSupported",
        "description": "Checks whether the device supports manual exposure.\nCall this method before calling joinChannel, enableVideo, or enableLocalVideo, depending on which method you use to turn on your local camera.",
        "parameters": [],
        "returns": "true: The device supports manual exposure.\n       false: The device does not support manual exposure."
    },
    {
        "id": "api_iscamerafocussupported",
        "name": "isCameraFocusSupported",
        "description": "Check whether the device supports the manual focus function.\nCall this method before calling joinChannel, enableVideo, or enableLocalVideo, depending on which method you use to turn on your local camera.",
        "parameters": [],
        "returns": "true: The device supports the manual focus function.\n       false: The device does not support the manual focus function."
    },
    {
        "id": "api_iscameratorchsupported",
        "name": "isCameraTorchSupported",
        "description": "Checks whether the device supports camera flash.\nThis method needs to be called after the camera is started (for example, by calling startPreview or joinChannel).\n            \n                \n                The app enables the front camera by default. If your front camera does not support flash, this method returns false. \n                    If you want to check whether the rear camera supports flash, call switchCamera before this method.",
        "parameters": [],
        "returns": "true: The device supports camera flash.\n       false: The device does not support camera flash."
    },
    {
        "id": "api_iscamerazoomsupported",
        "name": "isCameraZoomSupported",
        "description": "Checks whether the device supports camera zoom.\nCall this method before calling joinChannel, enableVideo, or enableLocalVideo, depending on which method you use to turn on your local camera.",
        "parameters": [],
        "returns": "true: The device supports camera zoom.\n       false: The device does not support camera zoom."
    },
    {
        "id": "api_isspeakerphoneenabled",
        "name": "isSpeakerphoneEnabled",
        "description": "Checks whether the speakerphone is enabled.\nThis method is for Android and iOS only.",
        "parameters": [],
        "returns": "true: The speakerphone is enabled, and the audio plays from the speakerphone.\n       false: The speakerphone is not enabled, and the audio plays from devices other than the speakerphone. For example, the headset or earpiece."
    },
    {
        "id": "api_ivideodevicemanager_enumeratevideodevices",
        "name": "enumerateVideoDevices",
        "description": "Enumerates the video devices.\n",
        "parameters": [],
        "returns": "Success: Returns a MediaDeviceInfo that contains all the video devices.\n       Failure: null."
    },
    {
        "id": "api_ivideodevicemanager_getdevice",
        "name": "getVideoDevice",
        "description": "Retrieves the current video capture device.\n",
        "parameters": [],
        "returns": "The video capture device."
    },
    {
        "id": "api_ivideodevicemanager_setdevice",
        "name": "setVideoDevice",
        "description": "Specifies the video capture device with the device ID.\nPlugging or unplugging a device does not change its device ID.",
        "parameters": [
            {
                "deviceId": "The device ID. You can get the device ID by calling enumerateVideoDevices.\n      "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_joinchannel2",
        "name": "joinChannel",
        "description": "Joins a channel with the user ID, and configures whether to automatically subscribe to the audio or video streams.\nThis method enables the local user to join a real-time audio and video interaction channel. With the same App ID, users in the same channel can talk to each other, and multiple users in the same channel can start a group chat.\n            A successful call of this method triggers the following callbacks: \n                The local client: The joinChannelSuccess and connectionStateChanged callbacks.\n                The remote client: userJoined, if the user joining the channel is in the Communication profile or is a host in the Live-broadcasting profile.\n            \n            When the connection between the client and Agora's server is interrupted due to poor network conditions, the SDK tries reconnecting to the server. When the local client successfully rejoins the channel, the SDK triggers the rejoinChannelSuccess callback on the local client.",
        "parameters": [
            {
                "token": "The token generated on your server for authentication. See Authenticate Your Users with Token.\n    Ensure that the App ID used for creating the token is the same App ID used by the createWithContext method for initializing the RTC engine.\n      "
            },
            {
                "null": "The channel name. This parameter signifies the channel in which users engage in real-time audio and video interaction. Under the premise of the same App ID, users who fill in the same channel ID enter the same channel for audio and video interaction. The string length must be less than 64 bytes. Supported characters:\n     The 26 lowercase English letters: a to z.\n     The 26 uppercase English letters: A to Z.\n     The 10 numeric characters: 0 to 9.\n     Space\n     \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\", \".\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \"{\", \"}\", \"|\", \"~\", \",\"\n \n  "
            },
            {
                "uid": "User ID This parameter is used to identify the user in the channel for real-time audio and video interaction. You need to set and manage user IDs yourself, and ensure that each user ID in the same channel is unique.  This parameter is a 32-bit unsigned integer.  The value range is 1 to\n                            232-1. If the user ID is not assigned (or set to 0), the SDK assigns a random user ID and returns it in the joinChannelSuccess callback. Your app must maintain the returned user ID, because the SDK\n                        does not do so."
            },
            {
                "options": "The channel media options. For details, see ChannelMediaOptions."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_joinchannelwithuseraccount2",
        "name": "joinChannelWithUserAccount",
        "description": "Joins the channel with a user account, and configures whether to automatically subscribe to audio or video streams after joining the channel.\nThis method allows a user to join the channel with the user account. After the user successfully joins the channel, the SDK triggers the following callbacks:\n                    The local client: localUserRegistered, joinChannelSuccess and connectionStateChanged callbacks.\n                    The remote client: The userJoined callback if the user is in the COMMUNICATION profile, and the userInfoUpdated callback if the user is a host in the LIVE_BROADCASTING profile.\n                \n            Once a user joins the channel, the user subscribes to the audio and video streams of all the other users in the channel by default, giving rise to usage and billing calculation. To stop subscribing to a specified stream or all remote streams, call the corresponding mute methods.\n            To ensure smooth communication, use the same parameter type to identify the user. For example, if a user joins the channel with a user ID, then ensure all the other users use the user ID too. The same applies to the user account. If a user joins the channel with the Agora Web SDK, ensure that the ID of the user is set to the same parameter type.",
        "parameters": [
            {
                "options": "The channel media options. For details, see ChannelMediaOptions."
            },
            {
                "token": ""
            },
            {
                "userAccount": "The user account. This parameter is used to identify the user in the channel for real-time audio and video engagement. You need to set and manage user accounts yourself and ensure that each user account in the same channel is unique.   The maximum length of this parameter is 255 bytes. Ensure that you set this parameter and do not set it as null. Supported characters are (89 in total):\n                                The 26 lowercase English letters: a to z.\n                                The 26 uppercase English letters: A to Z.\n                                All numeric characters: 0 to 9.\n                                Space\n                                \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\", \".\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \"{\", \"}\", \"|\", \"~\", \",\"\n                            \n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_leavechannel",
        "name": "leaveChannel",
        "description": "Leaves a channel.\nThis method releases all resources related to the session. This method call is asynchronous. When this method returns, it does not necessarily mean that the user has left the channel.\n            A successful call of this method triggers the following callbacks:\n                    The local client: leaveChannel.\n                The remote client: userOffline, if the user joining the channel is in the Communication profile, or is a host in the Live-broadcasting profile.\n                \n            \n                \n                    If you call destroy immediately after calling this method, the SDK does not trigger the leaveChannel callback.\n                    If you call this method during a CDN live streaming, the SDK automatically calls the removePublishStreamUrl method.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_muteallremoteaudiostreams",
        "name": "muteAllRemoteAudioStreams",
        "description": "Stops or resumes subscribing to the audio streams of all remote users.\nAs of v3.3.0, after successfully calling this method, the local user stops or resumes subscribing to the audio streams of all remote users, including all subsequent users.\n   \n       \n  Call this method after joining a channel.",
        "parameters": [
            {
                "muted": "Whether to subscribe to the audio streams of all remote users:\n                                true: Do not subscribe to the audio streams of all remote users.\n                                false: (Default) Subscribe to the audio streams of all remote users by default.\n                            \n                        \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_muteallremotevideostreams",
        "name": "muteAllRemoteVideoStreams",
        "description": "Stops or resumes subscribing to the video streams of all remote users.\nAs of v3.3.0, after successfully calling this method, the local user stops or resumes subscribing to the video streams of all remote users, including all subsequent users.\n   \n       \n  Call this method after joining a channel.",
        "parameters": [
            {
                "muted": "Whether to stop subscribing to the video streams of all remote users.\n     true: Stop subscribing to the video streams of all remote users.\n     false: (Default) Subscribe to the audio streams of all remote users by default.\n \n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_mutelocalaudiostream",
        "name": "muteLocalAudioStream",
        "description": "Stops or resumes publishing the local audio stream.\nThis method does not affect any ongoing audio recording, because it does not disable the microphone.",
        "parameters": [
            {
                "muted": "Whether to stop publishing the local audio stream.\n  \n      true: Stop publishing the local audio stream.\n      false: (Default) Resumes publishing the local audio stream.\n  \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_mutelocalvideostream",
        "name": "muteLocalVideoStream",
        "description": "Stops or resumes publishing the local video stream.\nA successful call of this method triggers the userMuteVideo callback on the remote client.\n            \n                    \n                        This method executes faster than the enableLocalVideo(false) method, which controls the sending of the local video stream.\n                        This method does not affect any ongoing video recording, because it does not disable the camera.",
        "parameters": [
            {
                "muted": "Whether to stop publishing the local video stream.\n                            true: Stop publishing the local video stream.\n                            false: (Default) Publish the local video stream.\n                        \n                        \n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_muteremoteaudiostream",
        "name": "muteRemoteAudioStream",
        "description": "Stops or resumes subscribing to the audio stream of a specified user.\nCall this method after joining a channel.\n  See recommended settings in Set the Subscribing State.",
        "parameters": [
            {
                "uid": "The user ID of the specified user."
            },
            {
                "muted": "Whether to stop subscribing to the audio stream of the specified user.\n      \n true: Stop subscribing to the audio stream of the specified user.\n false: (Default) Subscribe to the audio stream of the specified user.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_muteremotevideostream",
        "name": "muteRemoteVideoStream",
        "description": "Stops or resumes subscribing to the video stream of a specified user.\nCall this method after joining a channel.\n  See recommended settings in Set the Subscribing State.",
        "parameters": [
            {
                "userId": "The ID of the specified user."
            },
            {
                "muted": "Whether to stop subscribing to the video stream of the specified user.\n      true: Stop subscribing to the video streams of the specified user.\n      false: (Default) Subscribe to the video stream of the specified user.\n  \n      "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_pauseallchannelmediarelay",
        "name": "pauseAllChannelMediaRelay",
        "description": "Pauses the media stream relay to all destination channels.\nAfter the cross-channel media stream relay starts, you can call this method to pause relaying media streams to all destination channels; after the pause, if you want to resume the relay, call resumeAllChannelMediaRelay.\n            After a successful method call, the SDK triggers the channelMediaRelayEvent callback to report whether the media stream relay is successfully paused.\n            Call this method after startChannelMediaRelay.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_pausealleffects",
        "name": "pauseAllEffects",
        "description": "Pauses all audio effects.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_pauseaudiomixing",
        "name": "pauseAudioMixing",
        "description": "Pauses playing and mixing the music file.\nCall this method when you are in a channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_pauseeffect",
        "name": "pauseEffect",
        "description": "Pauses a specified audio effect.\n",
        "parameters": [
            {
                "soundId": "The audio effect ID. The ID of each audio effect file is unique."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_playeffect3",
        "name": "playEffect",
        "description": "Plays the specified local or online audio effect file.\nTo play multiple audio effect files at the same time, call this method multiple times with different soundId and filePath. For the best user experience, Agora recommends playing no more than three audio effect files at the same time. After the playback of an audio effect file completes, the SDK triggers the audioEffectFinished callback.Call this method after joining a channel.",
        "parameters": [
            {
                "soundId": "The audio effect ID. The ID of each audio effect file is unique.If you have preloaded an audio effect into memory by calling preloadEffect, ensure that this parameter is set to the same value as soundId in preloadEffect.\n                    "
            },
            {
                "filePath": "The absolute path or URL address (including the suffixes of the filename) of the audio effect file. For example: Android: /sdcard/emulated/0/audio.mp4, iOS: /var/mobile/Containers/Data/audio.mp4. Supported audio formats include MP3, AAC, M4A, MP4, WAV, and 3GP. See supported audio formats.\n                        If you have preloaded an audio effect into memory by calling preloadEffect, ensure that this parameter is set to the same value as filePath in preloadEffect.\n                    "
            },
            {
                "loopCount": "The number of times the audio effect loops:\n                        ≥ 0: The number of playback times. For example, 1 means loop one time, which means play the audio effect two times in total.\n                        -1: Play the music effect in an infinite loop.\n                    \n                    "
            },
            {
                "pitch": "The pitch of the audio effect. The value range is 0.5 to 2.0. The default value is 1.0, which means the original pitch. The lower the value, the lower the pitch."
            },
            {
                "pan": "The spatial position of the audio effect. The value range is 1 to10000.\n                        -1.0: The audio effect displays to the left.\n                        0.0: The audio effect displays ahead.\n                        1.0: The audio effect displays to the right.\n                    \n                    "
            },
            {
                "gain": "The volume of the audio effect. The value range is 1 to10000. The default value is 100.0, which means the original volume. The smaller the value, the lower the volume."
            },
            {
                "publish": "Whether to publish the audio effect to the remote users.\n                        true: Publish the audio effect to the remote users. Both the local user and remote users can hear the audio effect.\n                        false: Do not publish the audio effect to the remote users. Only the local user can hear the audio effect.\n                    \n                    "
            },
            {
                "startPos": "The playback position (ms) of the audio effect file.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_preloadeffect",
        "name": "preloadEffect",
        "description": "Preloads a specified audio effect file into the memory.\nTo ensure smooth communication, limit the size of the audio effect file. We recommend using this method to preload the audio effect before calling joinChannel.\n            \n                This method does not support online audio effect files.\n                For the audio file formats supported by this method, see What formats of audio files does the Agora RTC SDK support.",
        "parameters": [
            {
                "soundId": "The audio effect ID. The ID of each audio effect file is unique."
            },
            {
                "filePath": "File path:\n            Android: The file path, which needs to be accurate to the file name and suffix. Agora supports using a URI address, an absolute path, or a path that starts with /assets/. \n                You might encounter permission issues if you use an absolute path to access a local file, so Agora recommends using a URI address instead. For example:                     content://com.android.providers.media.documents/document/audio%203A14441\n            Windows: The absolute path or URL address (including the suffixes of the filename) of the audio effect file. For example: C:\\music\\audio.mp4.\n            iOS or macOS: The absolute path or URL address (including the suffixes of the filename) of the audio effect file. For example: /var/mobile/Containers/Data/audio.mp4.\n        "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_rate",
        "name": "rate",
        "description": "Allows a user to rate a call after the call ends.\nEnsure that you call this method after leaving a channel.",
        "parameters": [
            {
                "callId": "The current call ID. You can get the call ID by calling getCallId."
            },
            {
                "rating": "The rating of the call. The value is between 1 (lowest score) and 5 (highest score). If you set a value out of this range, the SDK returns the -2 (ERR_INVALID_ARGUMENT) error."
            },
            {
                "description": "(Optional) A description of the call. The string length should be less than 800 bytes."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_registerlocaluseraccount",
        "name": "registerLocalUserAccount",
        "description": "Registers a user account.\nOnce registered, the user account can be used to identify the local user when the user joins the channel. After the registration is successful, the user account can identify the identity of the local user, and the user can use it to join the channel.\n   After the user successfully registers a user account, the SDK triggers the localUserRegistered callback on the local client, reporting the user ID and user account of the local user.\n   This method is optional. To join a channel with a user account, you can choose either of the following ways:\n       Call registerLocalUserAccount to to create a user account, and then call joinChannelWithUserAccount to join the channel.\n       Call the joinChannelWithUserAccount method to join the channel.\n   \n   The difference between the two ways is that the time elapsed between calling the registerLocalUserAccount method and joining the channel is shorter than directly calling joinChannelWithUserAccount.\n   \n       \n  Ensure that you set the userAccount parameter; otherwise, this method does not take effect.\n           Ensure that the userAccount is unique in the channel.\n  To ensure smooth communication, use the same parameter type to identify the user. For example, if a user joins the channel with a user ID, then ensure all the other users use the user ID too. The same applies to the user account.  If a user joins the channel with the Agora Web SDK, ensure that the ID of the user is set to the same parameter type.",
        "parameters": [
            {
                "appId": "The App ID of your project on Agora Console."
            },
            {
                "userAccount": "The user account. This parameter is used to identify the user in the channel for real-time audio and video engagement. You need to set and manage user accounts yourself and ensure that each user account in the same channel is unique.  The maximum length of this parameter is 255 bytes. Ensure that you set this parameter and do not set it as null. Supported characters are (89 in total):\n      The 26 lowercase English letters: a to z.\n      The 26 uppercase English letters: A to Z.\n      All numeric characters: 0 to 9.\n      Space\n      \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\", \".\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \"{\", \"}\", \"|\", \"~\", \",\"\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_registermediametadataobserver",
        "name": "registerMediaMetadataObserver",
        "description": "Registers the metadata observer.\nCall this method before joinChannel.\n      This method applies only to interactive live streaming.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_release",
        "name": "destroy",
        "description": "Releases the RtcEngine instance.\nThis method releases all resources used by the Agora SDK. Use this method for apps in which users occasionally make voice or video calls. When users do not make calls, you can free up resources for other operations.\n   If you want to create a new RtcEngine instance after destroying the current one, ensure that you wait till the destroy method execution to complete.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_removeinjectstreamurl",
        "name": "removeInjectStreamUrl",
        "description": "Removes the voice or video stream URL address from the live streaming.\nAgora will soon stop the service for injecting online media streams on the client. If you have not implemented this service, Agora recommends that you do not use it. For details, see Service Sunset Plans.\n   After a successful method, the SDK triggers the userOffline callback\n                with the uid of 666.",
        "parameters": [
            {
                "url": "The URL address of the injected stream to be removed."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_removepublishstreamurl",
        "name": "removePublishStreamUrl",
        "description": "Removes an RTMP or RTMPS stream from the CDN.\nAfter a successful method call, the SDK triggers rtmpStreamingStateChanged on the local client to report the result of deleting the address.\n   \n       \n           Ensure that you enable the RTMP Converter service before using this function.\n           This method takes effect only when you are a host in live interactive streaming.\n           Call this method after joining a channel.\n           This method removes only one CDN streaming URL each time it is called. To remove multiple URLs, call this method multiple times.",
        "parameters": [
            {
                "url": "The CDN streaming URL to be removed. The maximum length of this parameter is 1024 bytes. The CDN streaming URL must not contain special characters, such as Chinese characters."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_renewtoken",
        "name": "renewToken",
        "description": "Gets a new token when the current token expires after a period of time.\nPasses a new token to the SDK. A token expires after a certain period of time. In the following two cases, the app should call this method to pass in a new token. Failure to do so will result in the SDK disconnecting from the server.\n       The SDK triggers the tokenPrivilegeWillExpire callback.\n       The connectionStateChanged callback reports TokenExpired(9).",
        "parameters": [
            {
                "token": "The new token."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_resumeallchannelmediarelay",
        "name": "resumeAllChannelMediaRelay",
        "description": "Resumes the media stream relay to all destination channels.\nAfter calling the pauseAllChannelMediaRelay method, you can call this method to resume relaying media streams to all destination channels.\n            After a successful method call, the SDK triggers the channelMediaRelayEvent callback to report whether the media stream relay is successfully resumed.\n            Call this method after the pauseAllChannelMediaRelay method.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_resumealleffects",
        "name": "resumeAllEffects",
        "description": "Resumes playing all audio effects.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_resumeaudiomixing",
        "name": "resumeAudioMixing",
        "description": "Resumes playing and mixing the music file.\nThis method resumes playing and mixing the music file. Call this method when you are in a channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_resumeeffect",
        "name": "resumeEffect",
        "description": "Resumes playing a specified audio effect.\n",
        "parameters": [
            {
                "soundId": "The audio effect ID. The ID of each audio effect file is unique."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_sendcustomreportmessage",
        "name": "sendCustomReportMessage",
        "description": "Reports customized messages.\nAgora supports reporting and analyzing customized messages. This function is in the beta stage with a free trial. The ability provided in its beta test version is reporting a maximum of 10 message pieces within 6 seconds, with each message piece not exceeding 256 bytes and each string not exceeding 100 bytes. To try out this function, contact  and discuss the format of customized messages with us.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_sendmetadata",
        "name": "sendMetadata",
        "description": "Sends media metadata.\nIf the metadata is sent successfully, the SDK triggers the metadataReceived callback on the receiver.",
        "parameters": [
            {
                "metadata": "Media metadata See Metadata."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_sendstreammessage",
        "name": "sendStreamMessage",
        "description": "Sends data stream messages.\nSends data stream messages to all users in a channel. The SDK has the following restrictions on this method:Up to 30 packets can be sent per second in a channel with each packet having a maximum size of 1 KB.Each client can send up to 6 KB of data per second.Each user can have up to five data streams simultaneously.\n   A successful method call triggers the streamMessage callback on the remote client, from which the remote user gets the stream message. A failed method call triggers the streamMessageError callback on the remote client.\n   \n       Ensure that you call createDataStreamWithConfig to create a data channel before calling this method.\n       In live streaming scenarios, this method only applies to hosts.",
        "parameters": [
            {
                "streamId": "The data stream ID. You can get the data stream ID by calling createDataStreamWithConfig."
            },
            {
                "message": "The message to be sent."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setaudioeffectparameters",
        "name": "setAudioEffectParameters",
        "description": "Sets parameters for SDK preset audio effects.\nCall this method to set the following parameters for the local user who sends an audio stream:\n  3D voice effect: Sets the cycle period of the 3D voice effect.\n  Pitch correction effect: Sets the basic mode and tonic pitch of the pitch correction effect. Different songs have different modes and tonic pitches. Agora recommends bounding this method with interface elements to enable users to adjust the pitch correction interactively.\n       \n   \n   After setting the audio parameters, all users in the channel can hear the effect.\n   \n       \n  You can call this method either before or after joining a channel.\n  To get better audio effect quality, Agora recommends calling and setting scenario in setAudioProfile as GameStreaming(3) before calling this method.\n  Do not set the profile parameter in setAudioProfile to SpeechStandard (1), or the method does not take effect.\n  This method works best with the human voice. Agora does not recommend using this method for audio containing music.\n  After calling setAudioEffectParameters, Agora recommends not calling the following methods, or the settings in setAudioEffectParameters are overridden :\n setAudioEffectPreset\n setVoiceBeautifierPreset\n setLocalVoiceReverbPreset\n setLocalVoiceChanger\n setLocalVoicePitch\n setLocalVoiceEqualization\n setLocalVoiceReverb\n setVoiceBeautifierParameters\n          setVoiceConversionPreset",
        "parameters": [
            {
                "preset": "The options for SDK preset audio effects:\n                            RoomAcoustics3DVoice, 3D voice effect:\n                                    Call and set the profile parameter in setAudioProfile to MusicStandardStereo (3) or MusicHighQualityStereo(5) before setting this enumerator; otherwise, the enumerator setting does not take effect.\n                                    If the 3D voice effect is enabled, users need to use stereo audio playback devices to hear the anticipated voice effect.\n                                \n                            \n                            PitchCorrection, Pitch correction effect: To achieve better audio effect quality, Agora recommends calling setAudioProfile and setting the profile parameter to MusicHighQuality (4) or MusicHighQualityStereo(5) before setting this enumerator.\n                        \n                    "
            },
            {
                "param1": "\n If you set preset to RoomAcoustics3DVoice , param1 sets the cycle period of the 3D voice effect. The value range is [1,60] and the unit is seconds. The default value is 10, indicating that the voice moves around you every 10 seconds.\n If you set preset to PitchCorrection , param1 sets the basic mode of the pitch correction effect:\n1: (Default) Natural major scale.\n2: Natural minor scale.\n3: Japanese pentatonic scale.\n     \n \n      \n  "
            },
            {
                "param2": "\n If you set preset to RoomAcoustics3DVoice, you need to set param2 to 0.\n If you set preset to PitchCorrection, param2 sets the tonic pitch of the pitch correction effect:\n1: A\n2: A#\n3: B\n4: (Default) C\n5: C#\n6: D\n7: D#\n8: E\n9: F\n10: F#\n11: G\n12: G#\n     \n \n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setaudioeffectpreset",
        "name": "setAudioEffectPreset",
        "description": "Sets an SDK preset audio effect.\nCall this method to set an SDK preset audio effect for the local user who sends an audio stream. This audio effect does not change the gender characteristics of the original voice. After setting an audio effect, all users in the channel can hear the effect.\n   To get better audio effect quality, Agora recommends calling setAudioProfile and setting the scenario parameter as GameStreaming (3) before calling this method.\n   \n       \n  You can call this method either before or after joining a channel.\n  Do not set the profile parameter in setAudioProfile to SpeechStandard (1), or the method does not take effect.\n  This method works best with the human voice. Agora does not recommend using this method for audio containing music.\n  If you call setAudioEffectPreset and set enumerators except for RoomAcoustics3DVoice or PitchCorrection, do not call setAudioEffectParameters; otherwise, setAudioEffectPreset is overridden.\n  After calling setAudioEffectPreset, Agora recommends not calling the following methods, because they can override setAudioEffectPreset:\n         setVoiceBeautifierPreset\n         setLocalVoiceReverbPreset\n         setLocalVoiceChanger\n         setLocalVoicePitch\n         setLocalVoiceEqualization\n         setLocalVoiceReverb\n         setVoiceBeautifierParameters\n         setVoiceConversionPreset",
        "parameters": [
            {
                "preset": "The options for SDK preset audio effects. See AudioEffectPreset."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setaudiomixingpitch",
        "name": "setAudioMixingPitch",
        "description": "Sets the pitch of the local music file.\nWhen a local music file is mixed with a local human voice, call this method to set the pitch of the local music file only.\n            You need to call this method after calling startAudioMixing and receiving the audioMixingStateChanged(Playing) callback.",
        "parameters": [
            {
                "pitch": "Sets the pitch of the local music file by the chromatic scale. The default value is 0, which means keeping the original pitch. The value ranges from -12 to 12, and the pitch value between consecutive values is a chromatic value. The greater the absolute value of this parameter, the higher or lower the pitch of the local music file."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setaudiomixingplaybackspeed",
        "name": "setAudioMixingPlaybackSpeed",
        "description": "Sets the channel mode of the current music file.\nCall this method after calling startAudioMixing and receiving the audioMixingStateChanged(Playing) callback.",
        "parameters": [
            {
                "speed": "The playback speed. Agora recommends that you limit this value to between 50 and 400, defined as follows:\n                        50: Half the original speed.\n                        100: The original speed.\n                        400: 4 times the original speed.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setaudiomixingposition",
        "name": "setAudioMixingPosition",
        "description": "Sets the audio mixing position.\nCall this method to set the playback position of the music file to a different starting position (the default plays from the beginning).\n            You need to call this method after calling startAudioMixing and receiving the audioMixingStateChanged(PLAY) callback.",
        "parameters": [
            {
                "pos": "Integer. The playback position (ms)."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setaudioprofile",
        "name": "setAudioProfile",
        "description": "Sets the audio profile and audio scenario.\nIn scenarios requiring high-quality audio, such as online music tutoring, Agora recommends you set profile as MusicHighQuality (4), and scenario as GameStreaming (3)",
        "parameters": [
            {
                "profile": "The audio profile, including the sampling rate, bitrate, encoding mode, and the number of channels. See AudioProfile.\n  "
            },
            {
                "scenario": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setaudiosessionoperationrestriction",
        "name": "setAudioSessionOperationRestriction",
        "description": "Sets the operational permission of the SDK on the audio session.\nThe SDK and the app can both configure the audio session by default. If you need to only use the app to configure the audio session, this method restricts the operational permission of the SDK on the audio session.\n   You can call this method either before or after joining a channel. Once you call this method to restrict the operational permission of the SDK on the audio session, the restriction takes effect when the SDK needs to change the audio session.\n   \n       This method is for iOS only.\n       This method does not restrict the operational permission of the app on the audio session.",
        "parameters": [
            {
                "restriction": "The operational permission of the SDK on the audio session. See AudioSessionOperationRestriction. This parameter is in bit mask format, and each bit corresponds to a permission."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setbeautyeffectoptions",
        "name": "setBeautyEffectOptions",
        "description": "Sets the image enhancement options.\nEnables or disables image enhancement, and sets the options.",
        "parameters": [
            {
                "enabled": "Whether to enable the image enhancement function:\n      true: Enable the image enhancement function.\n      false: (Default) Disable the image enhancement function.\n  "
            },
            {
                "options": "The image enhancement options. See BeautyOptions."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setcameraautofocusfacemodeenabled",
        "name": "setCameraAutoFocusFaceModeEnabled",
        "description": "Enables the camera auto-face focus function.\nCall this method before calling joinChannel, enableVideo, or enableLocalVideo, depending on which method you use to turn on your local camera.",
        "parameters": [
            {
                "": ""
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setcameracapturerconfiguration",
        "name": "setCameraCapturerConfiguration",
        "description": "Sets the camera capture configuration.\nCall this method before calling joinChannel, enableVideo, or enableLocalVideo, depending on which method you use to turn on your local camera.",
        "parameters": [
            {
                "config": "The camera capturer configuration. See CameraCapturerConfiguration."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setcameraexposureposition",
        "name": "setCameraExposurePosition",
        "description": "Sets the camera exposure position.\nThis method needs to be called after the camera is started (for example, by calling startPreview or joinChannel).\n   After a successful method call, the SDK triggers the cameraExposureAreaChanged callback.\n            This method is for Android and iOS only.",
        "parameters": [
            {
                "positionXinView": "The horizontal coordinate of the touchpoint in the view."
            },
            {
                "positionYinView": "The vertical coordinate of the touchpoint in the view."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setcamerafocuspositioninpreview",
        "name": "setCameraFocusPositionInPreview",
        "description": "Sets the camera manual focus position.\nThis method needs to be called after the camera is started (for example, by calling startPreview or joinChannel).\n       After a successful method call, the SDK triggers the cameraFocusAreaChanged callback.\n            This method is for Android and iOS only.",
        "parameters": [
            {
                "positionX": "The horizontal coordinate of the touchpoint in the view."
            },
            {
                "positionY": "The vertical coordinate of the touchpoint in the view."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setcameratorchon",
        "name": "setCameraTorchOn",
        "description": "Enables the camera flash.\nCall this method before calling joinChannel, enableVideo, or enableLocalVideo, depending on which method you use to turn on your local camera.",
        "parameters": [
            {
                "isOn": "Whether to turn on the camera flash:\n      true: Turn on the flash.\n      false: (Default) Turn off the flash.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setcamerazoomfactor",
        "name": "setCameraZoomFactor",
        "description": "Sets the camera zoom ratio.\nCall this method before calling joinChannel, enableVideo, or enableLocalVideo, depending on which method you use to turn on your local camera.",
        "parameters": [
            {
                "factor": "The camera zoom ratio. The value ranges between 1.0 and the maximum zoom supported by the device. You can get the maximum zoom ratio supported by the device by calling the getCameraMaxZoomFactor method."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setchannelprofile",
        "name": "setChannelProfile",
        "description": "Sets the channel profile.\nSets the profile of the Agora channel. The Agora SDK differentiates channel profiles and applies optimization algorithms accordingly. For example, it prioritizes smoothness and low latency for a video call and prioritizes video quality for interactive live video streaming.\n   \n       \n  To ensure the quality of real-time communication, Agora recommends that all users in a channel use the same channel profile.\n  This method must be called and set before joinChannel, and cannot be set again after entering the channel.",
        "parameters": [
            {
                "profile": "The channel profile. For details, see ChannelProfile.\n      "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setclientrole2",
        "name": "setClientRole",
        "description": "Sets the user role and level in an interactive live streaming channel.\nIn the interactive live streaming profile, the SDK sets the user role as audience by default. You can call this method to set the user role as host.\n            You can call this method either before or after joining a channel. If you call this method to switch the user role after joining a channel, the SDK automatically does the following:\n                Calls muteLocalAudioStream and muteLocalVideoStream to change the publishing state.\n                    Triggers clientRoleChanged on the local client.\n                    Triggers userJoined or userOffline on the remote client.\n                \n            This method applies to the interactive live streaming profile (the profile parameter of setChannelProfile is LiveBroadcasting) only.",
        "parameters": [
            {
                "role": "The user role in the interactive live streaming. See ClientRole.\n               "
            },
            {
                "options": "The detailed options of a user, including the user level. See ClientRoleOptions."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setcloudproxy",
        "name": "setCloudProxy",
        "description": "Sets the Agora cloud proxy service.\nWhen the user's firewall restricts the IP address and port, refer to Use Cloud Proxy to add the specific IP addresses and ports to the firewall whitelist; then, call this method to enable the cloud proxy and set the cloud proxyType as UDP.\n            After successfully connecting to the cloud proxy, the SDK triggers the connectionStateChanged (Connecting, SettingProxyServer) callback.\n            To disable the cloud proxy that has been set, call setCloudProxy(NONE_PROXY).\n            To change the cloud proxy type, call setCloudProxy(NONE_PROXY), and call setCloudProxy to set the proxyType you want.\n            \n                \n                    Agora recommends that you call this method before joining the channel or after leaving the channel.\n                    Cloud proxy for the UDP protocol does not apply to pushing streams to CDN or co-hosting across channels.",
        "parameters": [
            {
                "proxyType": "The type of the cloud proxy. See CloudProxyType . This parameter is mandatory. The SDK reports an error if you do not pass in a value."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setdefaultaudioroutetospeakerphone",
        "name": "setDefaultAudioRouteToSpeakerphone",
        "description": "Sets the default audio playback route.\nThis method sets whether the received audio is routed to the earpiece or speakerphone by default before joining a channel. If a user does not call this method, the audio is routed to the earpiece by default.\n            The default settings for each profile:\n                    For the COMMUNICATION profile:\n                            In a voice call, the default audio route is the earpiece.\n                            In a video call, the default audio route is the speakerphone. If a user calls the disableVideo, muteLocalVideoStream, or muteAllRemoteVideoStreams method, the default audio route switches back to the earpiece automatically.\n                        \n                    For the live broadcasting profile: Speakerphone.\n                \n            \n            \n                \n                    This method is for Android and iOS only.\n                    This method needs to be set before joining a channel, otherwise, it will not take effect.",
        "parameters": [
            {
                "defaultToSpeaker": "The default audio playback route.\n                            true: The audio routing is speakerphone. If the device connects to the earpiece or Bluetooth, the audio cannot be routed to the speakerphone.\n                            false: (Default) Route the audio to the earpiece. If a headset is plugged in, the audio is routed to the headset.\n                        \n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setdefaultmuteallremoteaudiostreams",
        "name": "setDefaultMuteAllRemoteAudioStreams",
        "description": "Stops or resumes subscribing to the audio streams of all remote users by default.\nCall this method after joining a channel. After successfully calling this method, the local user stops or resumes subscribing to the audio streams of all subsequent users.\n   \n       If you need to resume subscribing to the audio streams of remote users in the channel after calling this method, do the following:\n  To resume subscribing to the audio stream of a specified user, call muteRemoteAudioStream(false), and specify the user ID.\n  To resume subscribing to the audio streams of multiple remote users, call muteRemoteAudioStream (false)multiple times.",
        "parameters": [
            {
                "muted": "Whether to stop subscribing to the audio streams of all remote users by default.\n true: Stop subscribing to the audio streams of all remote users by default.\n false: (Default) Subscribe to the audio streams of all remote users by default.\n      \n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setdefaultmuteallremotevideostreams",
        "name": "setDefaultMuteAllRemoteVideoStreams",
        "description": "Stops or resumes subscribing to the video streams of all remote users by default.\nCall this method after joining a channel. After successfully calling this method, the local user stops or resumes subscribing to the audio streams of all subsequent users.\n            If you need to resume subscribing to the audio streams of remote users in the channel after calling this method, do the following:To resume subscribing to the audio stream of a specified user, call muteRemoteVideoStream(false), and specify the user ID.\n                    To resume subscribing to the audio streams of multiple remote users, call muteRemoteVideoStream(false)multiple times.",
        "parameters": [
            {
                "muted": "Whether to stop subscribing to the audio streams of all remote users by default.\n     true: Stop subscribing to the audio streams of all remote users by default.\n     false: (Default) Resume subscribing to the audio streams of all remote users by default.\n \n \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_seteffectposition",
        "name": "setEffectPosition",
        "description": "Sets the playback position of an audio effect file.\nAfter a successful setting, the local audio effect file starts playing at the specified position.\n            Call this method after playEffect.",
        "parameters": [
            {
                "soundId": "The audio effect ID. The ID of each audio effect file is unique."
            },
            {
                "pos": "The playback position (ms) of the audio effect file."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_seteffectsvolume",
        "name": "setEffectsVolume",
        "description": "Sets the volume of the audio effects.\n",
        "parameters": [
            {
                "volume": "The playback volume. The value ranges from 0 to 100. The default value is 100, which represents the original volume."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setenablespeakerphone",
        "name": "setEnableSpeakerphone",
        "description": "Enables/Disables the audio playback route to the speakerphone.\nThis method sets whether the audio is routed to the speakerphone or earpiece. After a successful method call, the SDK triggers the audioRouteChanged callback.\n            \n                \n                    Ensure that you have joined a channel before calling this method.",
        "parameters": [
            {
                "defaultToSpeaker": "Whether the audio is routed to the speakerphone or earpiece.\n                            true: Route the audio to the speakerphone. If the device connects to the earpiece or Bluetooth, the audio cannot be routed to the speakerphone.\n                            false: Route the audio to the earpiece. If a headset is plugged in, the audio is routed to the headset.\n                        \n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setencryptionmode",
        "name": "setEncryptionMode",
        "description": "Sets the built-in encryption mode.\nDeprecated:\n  Use enableEncryption instead.\n       \n   \n            secret. Refer to the information related to the AES encryption algorithm on the differences between the encryption modes.\n    Before calling this method, please call setEncryptionSecret to enable the built-in encryption function.",
        "parameters": [
            {
                "encryptionMode": "Encryption mode.\n     \"aes-128-xts\": 128-bit AES encryption, XTS mode.\n     \"aes-128-ecb\": 128-bit AES encryption, ECB mode.\n          \"aes-256-xts\": 256-bit AES encryption, XTS mode.\n          \"sm4-128-ecb\": 128-bit SM4 encryption, ECB mode.\n          \"aes-128-gcm\": 128-bit AES encryption, GCM mode.\n          \"aes-256-gcm\": 256-bit AES encryption, GCM mode.\n          \n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setencryptionsecret",
        "name": "setEncryptionSecret",
        "description": "Enables built-in encryption with an encryption password before users join a channel.\nDeprecated:\n  This method is deprecated from v3.2.0. Please use enableEncryption instead.\n       \n   \n   Before joining the channel, you need to call this method to set the secret parameter to enable the built-in encryption. All users in the same channel should use the same secret. The secret is automatically cleared once a user leaves the channel. If you do not specify the secret or secret is set as null, the built-in encryption is disabled.\n   \n       \n  Do not use this method for CDN live streaming.\n  For optimal transmission, ensure that the encrypted data size does not exceed the original data size + 16 bytes. 16 bytes is the maximum padding size for AES encryption.",
        "parameters": [
            {
                "secret": "The encryption password."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setinearmonitoringvolume",
        "name": "setInEarMonitoringVolume",
        "description": "Sets the volume of the in-ear monitor.\nThis method is for Android and iOS only.\n      Users must use wired earphones to hear their own voices.\n      You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "volume": "The volume of the in-ear monitor. The value ranges between 0 and 100. The default value is 100."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setlivetranscoding",
        "name": "setLiveTranscoding",
        "description": "Sets the transcoding configurations for CDN live streaming.\nThis method sets the video layout and audio settings for CDN live streaming. The SDK triggers the transcodingUpdated callback when you call this method to update the transcoding settings.\n   \n       \n  This method takes effect only when you are a host in live interactive streaming.\n  Ensure that you enable the RTMP Converter service before using this function. See Prerequisites in the advanced guide Push Streams to CDN.\n  If you call this method to set the transcoding configuration for the first time, the SDK does not trigger the transcodingUpdated callback.\n  Call this method after joining a channel.\n  Agora supports pushing media streams in RTMPS protocol to the CDN only when you enable transcoding.",
        "parameters": [
            {
                "transcoding": "The transcoding configurations for CDN live streaming. For details, see LiveTranscoding."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setlocalpublishfallbackoption",
        "name": "setLocalPublishFallbackOption",
        "description": "Sets the fallback option for the published video stream based on the network conditions.\nAn unstable network affects the audio and video quality in a video call or interactive live video streaming. If option is set as AudioOnly(2), the SDK disables the upstream video but enables audio only when the network conditions deteriorate and cannot support both video and audio. The SDK monitors the network quality and restores the video stream when the network conditions improve. When the published video stream falls back to audio-only or when the audio-only stream switches back to the video, the SDK triggers the localPublishFallbackToAudioOnly callback.\n   \n       \n  Agora does not recommend using this method for CDN live streaming, because the remote CDN live user will have a noticeable lag when the published video stream falls back to AudioOnly(2).\n  Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "option": "The stream fallback option. For details, see StreamFallbackOptions."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setlocalvoicechanger",
        "name": "setLocalVoiceChanger",
        "description": "Sets the local voice changer option.\nDeprecated:\n           Deprecated from v3.2.0. Use the following methods instead:\n                   setAudioEffectPreset : Audio effects.\n                   setVoiceBeautifierPreset : Voice beautifier effects.\n                   setVoiceConversionPreset : Voice conversion effects.\n               \n            \n       \n   \n   This method can be used to set the local voice effect for users in a COMMUNICATION channel or hosts in a LIVE_BROADCASTING channel. After successfully calling this method, all users in the channel can hear the voice with reverberation.\n  VOICE_CHANGER_XXX: Changes the local voice to an old man, a little boy, or the Hulk. Applies to the voice talk scenario.\n  VOICE_BEAUTY_XXX: Beautifies the local voice by making it sound more vigorous, resounding, or adding spacial resonance. Applies to the voice talk and singing scenario.\n  GENERAL_VOICE_BEAUTY_XXX: Adds gender-based beautification effect to the local voice. Applies to the voice talk scenario. For a male voice: Adds magnetism to the voice. For a male voice: Adds magnetism to the voice. For a female voice: Adds freshness or vitality to the voice.\n       \n   \n   \n       \n  To achieve better voice effect quality, Agora recommends setting the setAudioProfileprofile parameter in asMusicHighQuality (4) orMusicHighQualityStereo (5).\n  This method works best with the human voice, and Agora does not recommend using it for audio containing music and a human voice.\n  Do not use this method with setLocalVoiceReverbPreset, because the method called later overrides the one called earlier. For detailed considerations, see the advanced guide Set the Voice Effect.\n  You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "voiceChanger": "The local voice changer option. The default value is Off , which means the original voice. For more details, see AudioVoiceChanger. The gender-based beatification effect works best only when assigned a proper gender. Use GENERAL_BEAUTY_VOICE_MALE_MAGNETIC for male and use GENERAL_BEAUTY_VOICE_FEMALE_FRESH and GENERAL_BEAUTY_VOICE_FEMALE_VITALITY for female. Failure to do so can lead to voice distortion.\n      "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setlocalvoiceequalization",
        "name": "setLocalVoiceEqualization",
        "description": "Sets the local voice equalization effect.\nYou can call this method either before or after joining a channel.",
        "parameters": [
            {
                "bandFrequency": "The band frequency. The value ranges between 0 and 9; representing the respective 10-band center frequencies of the voice effects, including 31, 62, 125, 250, 500, 1k, 2k, 4k, 8k, and 16k Hz. For more details, see AudioEqualizationBandFrequency."
            },
            {
                "bandGain": "The gain of each band in dB. The value ranges between -15 and 15. The default value is 0."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setlocalvoicepitch",
        "name": "setLocalVoicePitch",
        "description": "Changes the voice pitch of the local speaker.\nYou can call this method either before or after joining a channel.",
        "parameters": [
            {
                "pitch": "The local voice pitch. The value range is [0.5,2.0]. The lower the value, the lower the pitch. The default value is 1 (no change to the pitch)."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setlocalvoicereverb",
        "name": "setLocalVoiceReverb",
        "description": "Sets the local voice reverberation.\nYou can call this method either before or after joining a channel.",
        "parameters": [
            {
                "reverbKey": "The reverberation key. Agora provides 5 reverberation keys: AudioReverbType."
            },
            {
                "value": "The value of the reverberation key."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setlocalvoicereverbpreset",
        "name": "setLocalVoiceReverbPreset",
        "description": "Sets the local voice reverberation option, including the virtual stereo.\nThis method sets the local voice reverberation for users in a COMMUNICATION channel or hosts in a LIVE_BROADCASTING channel. After successfully calling this method, all users in the channel can hear the voice with reverberation.\n   \n       \n  When using the enumeration value prefixed with AUDIO_REVERB_FX, ensure that you set the profile parameter in setAudioProfile toMusicHighQuality(4) or MusicHighQualityStereo(5) before calling this method. Otherwise, the method setting is invalid.\n  When calling the VIRTUAL_STEREO method, Agora recommends setting the profile parameter in setAudioProfile as MusicHighQualityStereo(5).\n  This method works best with the human voice, and Agora does not recommend using it for audio containing music and a human voice.\n  Do not use this method with setLocalVoiceChanger, because the method called later overrides the one called earlier. For detailed considerations, see the advanced guide Set the Voice Effect.\n  You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "reverbPreset": "The local voice reverberation option. The default value is Off, which means the original voice. For more details, see AudioReverbPreset. To achieve better voice effects, Agora recommends the enumeration whose name begins with AUDIO_REVERB_FX."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setlogfile",
        "name": "setLogFile",
        "description": "Sets the log files that the SDK outputs.\nBy default, the SDK outputs five log files: agorasdk.log, agorasdk_1.log, agorasdk_2.log, agorasdk_3.log, and agorasdk_4.log. Each log file has a default size of 512 KB. These log files are encoded in UTF-8. The SDK writes the latest log in agorasdk.log. When agorasdk.log is full, the SDK deletes the log file with the earliest modification time among the other four, renames agorasdk.log to the name of the deleted log file, and create a new agorasdk.log to record the latest logs.\n   Ensure that you call this method immediately after initializing RtcEngine, otherwise, the output log may not be complete.",
        "parameters": [
            {
                "filePath": "The absolute path of the log files. The default file path is C: \\Users\\<user_name>\\AppData\\Local\\Agora\\<process_name>\\agorasdk.log. Ensure that the directory for the log files exists and is writable. You can use this parameter to rename the log files.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setlogfilesize",
        "name": "setLogFileSize",
        "description": "Sets the size of a log file that the SDK outputs.\nBy default, the SDK outputs five log files: agorasdk.log, agorasdk_1.log, agorasdk_2.log, agorasdk_3.log, and agorasdk_4.log. Each log file has a default size of 512 KB. These log files are encoded in UTF-8. The SDK writes the latest log in agorasdk.log. When agorasdk.log is full, the SDK deletes the log file with the earliest modification time among the other four, renames agorasdk.log to the name of the deleted log file, and create a new agorasdk.log to record the latest logs.\n            If you want to set the size of the log file, you need to call this method before setLogFile, otherwise, the log will be cleared.",
        "parameters": [
            {
                "fileSizeInKBytes": "The size (KB) of a log file. The default value is 1024 KB. If you set fileSizeInKByte to 1024 KB, the maximum aggregate size of the log files output by the SDK is 5 MB. if you set fileSizeInKByte to less than 1024 KB, the setting is invalid, and the maximum size of a log file is still 1024 KB."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setlogfilter",
        "name": "setLogFilter",
        "description": "Sets the log output level of the SDK.\nThis method sets the output log level of the SDK. You can use one or a combination of the log filter levels. The log level follows the sequence of OFF, CRITICAL, ERROR, WARNING, INFO, and DEBUG. Choose a level to see the logs preceding that level.\n   If, for example, you set the log level to WARNING, you see the logs within levels CRITICAL, ERROR, and WARNING.",
        "parameters": [
            {
                "filter": "The output log level of the SDK. For details, see LogFilter."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setmaxmetadatasize",
        "name": "setMaxMetadataSize",
        "description": "Sets the maximum size of the media metadata.\nAfter calling registerMediaMetadataObserver, you can call this method to set the maximum size of the media metadata.",
        "parameters": [
            {
                "size": "The maximum size of media metadata."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setremotedefaultvideostreamtype",
        "name": "setRemoteDefaultVideoStreamType",
        "description": "Sets the default stream type of remote video streams.\nUnder limited network conditions, if the publisher has not disabled the dual-stream mode using (),the receiver can choose to receive either the high-quality video stream or the low-quality video stream. The high-quality video stream has a higher resolution and bitrate, and the low-quality video stream has a lower resolution and bitrate.enableDualStreamModefalse\n   By default, users receive the high-quality video stream. Call this method if you want to switch to the low-quality video stream. This method allows the app to adjust the corresponding video stream type based on the size of the video window to reduce the bandwidth and resources. The aspect ratio of the low-quality video stream is the same as the high-quality video stream. Once the resolution of the high-quality video stream is set, the system automatically sets the resolution, frame rate, and bitrate of the low-quality video stream.\n   The result of this method returns in the apiCallExecuted callback.\n   You can call this method either before or after joining a channel. If you call both setRemoteVideoStreamType and setRemoteDefaultVideoStreamType, the settings in setRemoteVideoStreamType take effect.",
        "parameters": [
            {
                "streamType": "The default stream type of the remote video, see VideoStreamType.\n               "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setremotesubscribefallbackoption",
        "name": "setRemoteSubscribeFallbackOption",
        "description": "Sets the fallback option for the remote video stream based on the network conditions.\nUnreliable network conditions affect the overall quality of the interactive live streaming. If option is set as VideoStreamLow(1) or AudioOnly(2), the SDK automatically switches the video from a high stream to a low stream or disables the video when the downlink network conditions cannot support both audio and video to guarantee the quality of the audio. The SDK monitors the network quality and restores the video stream when the network conditions improve. When the remote video stream falls back to audio-only or when the audio-only stream switches back to the video, the SDK triggers the remoteSubscribeFallbackToAudioOnly callback.\n               Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "option": "See StreamFallbackOptions. The default value is VideoStreamLow(1)."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setremoteuserpriority",
        "name": "setRemoteUserPriority",
        "description": "Prioritizes a remote user's stream.\nPrioritizes a remote user's stream. The SDK ensures the high-priority user gets the best possible stream quality. The SDK ensures the high-priority user gets the best possible stream quality.\n               \n                    \n                         The SDK supports setting only one user as high priority.\n                         Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "userPriority": "The priority of the remote user. See UserPriority."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setremotevideostreamtype",
        "name": "setRemoteVideoStreamType",
        "description": "          Sets the stream type of the remote video.\nUnder limited network conditions, if the publisher has not disabled the dual-stream mode using enableDualStreamMode(false), the receiver can choose to receive either the high-quality video stream (the high resolution, and high bitrate video stream) or the low-quality video stream (the low resolution, and low bitrate video stream). The high-quality video stream has a higher resolution and bitrate, and the low-quality video stream has a lower resolution and bitrate.\n               By default, users receive the high-quality video stream. Call this method if you want to switch to the low-quality video stream. This method allows the app to adjust the corresponding video stream type based on the size of the video window to reduce the bandwidth and resources. The aspect ratio of the low-quality video stream is the same as the high-quality video stream. Once the resolution of the high-quality video stream is set, the system automatically sets the resolution, frame rate, and bitrate of the low-quality video stream.\n               \n                    The method result returns in the apiCallExecuted callback.\n               \n                    You can call this method either before or after joining a channel. If you call both setRemoteVideoStreamType and setRemoteDefaultVideoStreamType, the setting of setRemoteVideoStreamType takes effect.",
        "parameters": [
            {
                "streamType": "The video stream type: VideoStreamType.\n                              "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setremotevoiceposition",
        "name": "setRemoteVoicePosition",
        "description": "Sets the 2D position (the position on the horizontal plane) of the remote user's voice.\nThis method sets the 2D position and volume of a remote user, so that the local user can easily hear and identify the remote user's position.\n   When the local user calls this method to set the voice position of a remote user, the voice difference between the left and right channels allows the local user to track the real-time position of the remote user, creating a sense of space. This method applies to massive multiplayer online games, such as Battle Royale games.\n   \n       \n  For this method to work, enable stereo panning for remote users by calling the enableSoundPositionIndication method before joining a channel.\n           For the best voice positioning, Agora recommends using a wired headset.\n  Call this method after joining a channel.",
        "parameters": [
            {
                "uid": "The user ID of the remote user."
            },
            {
                "pan": "The voice position of the remote user. The value ranges from -1.0 to 1.0:\n 0.0: (Default) The remote voice comes from the front.\n -1.0: The remote voice comes from the left.\n 1.0: The remote voice comes from the right.\n      \n  "
            },
            {
                "gain": "The volume of the remote user. The value ranges from 0.0 to 100.0. The default value is 100.0 (the original volume of the remote user). The smaller the value, the lower the volume."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setscreencapturecontenthint",
        "name": "setScreenCaptureContentHint",
        "description": "Sets the content hint for screen sharing.\nA content hint suggests the type of the content being shared, so that the SDK applies different optimization algorithms to different types of content. If you don't call this method, the default content hint is None.\n   You can call this method either before or after you start screen sharing.",
        "parameters": [
            {
                "contentHint": "The content hint for screen sharing. For details, see VideoContentHint."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setvideoencoderconfiguration",
        "name": "setVideoEncoderConfiguration",
        "description": "Sets the video encoder configuration.\nSets the encoder configuration for the local video.\n   You can call this method either before or after joining a channel. If you don't need to set the video encoder configuration after joining a channel,\n   Agora recommends you calling this method before the enableVideo method to reduce the rendering time of the first video frame.",
        "parameters": [
            {
                "config": "Video profile. See VideoEncoderConfiguration."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setvoicebeautifierparameters",
        "name": "setVoiceBeautifierParameters",
        "description": "Sets parameters for the preset voice beautifier effects.\nCall this method to set a gender characteristic and a reverberation effect for the singing beautifier effect. This method sets parameters for the local user who sends an audio stream. After setting the audio parameters, all users in the channel can hear the effect.\n   For better voice effects, Agora recommends that you call setAudioProfile and setscenario to GameStreaming(3) and profile to MusicHighQuality(4) or MusicHighQualityStereo(5) before calling this method.\n   \n       \n  You can call this method either before or after joining a channel.\n  Do not set the profile parameter of setAudioProfile to SpeechStandard(1). Otherwise, the method does not take effect.\n  This method works best with the human voice. Agora does not recommend using this method for audio containing music.\n  After calling setVoiceBeautifierParameters, Agora recommends not calling the following methods, because they can override settings in setVoiceBeautifierParameters:\n setAudioEffectPreset\n setAudioEffectParameters\n setVoiceBeautifierPreset\n setLocalVoiceReverbPreset\n setLocalVoiceChanger\n setLocalVoicePitch\n setLocalVoiceEqualization\n setLocalVoiceReverb\n setVoiceConversionPreset",
        "parameters": [
            {
                "preset": "The option for the preset audio effect:\n SINGING_BEAUTIFIER: The singing beautifier effect.\n      \n  "
            },
            {
                "param1": "The gender characteristics options for the singing voice:\n 1: A male-sounding voice.\n 2: A female-sounding voice.\n      \n  "
            },
            {
                "param2": "The reverberation effect options for the singing voice:\n 1: The reverberation effect sounds like singing in a small room.\n 2: The reverberation effect sounds like singing in a large room.\n 3: The reverberation effect sounds like singing in a hall.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setvoicebeautifierpreset",
        "name": "setVoiceBeautifierPreset",
        "description": "Sets a preset voice beautifier effect.\nCall this method to set a preset voice beautifier effect for the local user who sends an audio stream. After setting a voice beautifier effect, all users in the channel can hear the effect. You can set different voice beautifier effects for different scenarios. \n   For better voice effects, Agora recommends that you call setAudioProfile and set scenario to GameStreaming (3) and profile to MusicHighQuality (4) or MusicHighQualityStereo (5) before calling this method.\n   \n       \n  You can call this method either before or after joining a channel.\n  Do not set the profile parameter in setAudioProfile to SpeechStandard(1), or the method does not take effect.\n  This method works best with the human voice. Agora does not recommend using this method for audio containing music.\n  After calling setVoiceBeautifierPreset, Agora recommends not calling the following methods, because they can override setVoiceBeautifierPreset:\n setAudioEffectPreset\n setAudioEffectParameters\n setLocalVoiceReverbPreset\n setLocalVoiceChanger\n setLocalVoicePitch\n setLocalVoiceEqualization\n setLocalVoiceReverb\n setVoiceBeautifierParameters\n          setVoiceConversionPreset",
        "parameters": [
            {
                "preset": "The preset voice beautifier effect options: VoiceBeautifierPreset.\n               "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setvoiceconversionpreset",
        "name": "setVoiceConversionPreset",
        "description": "Sets a preset voice beautifier effect.\nCall this method to set a preset voice beautifier effect for the local user who sends an audio stream. After setting an audio effect, all users in the channel can hear the effect. You can set different audio effects for different scenarios. See Set the Voice Beautifier and Audio Effects.\n            To achieve better audio effect quality, Agora recommends that you call setAudioProfile and set the profile to MusicHighQuality(4) or MusicHighQualityStereo(5) and scenario to GameStreaming(3) before calling this method.\n            \n                \n                    You can call this method either before or after joining a channel.\n                    Do not setsetAudioProfile the profile parameter in to SpeechStandard(1)\n                    This method works best with the human voice. Agora does not recommend using this method for audio containing music.\n                    After calling setVoiceConversionPreset, Agora recommends not calling the following methods, or the settings in setVoiceConversionPreset are overridden :\n                            setAudioEffectPreset\n                            setAudioEffectParameters\n                            setVoiceBeautifierPreset\n                            setVoiceBeautifierParameters\n                            setLocalVoiceReverbPreset\n                            setLocalVoiceChanger\n                            setLocalVoicePitch\n                            setLocalVoiceEqualization\n                            setLocalVoiceReverb",
        "parameters": [
            {
                "preset": "The options for the preset voice beautifier effects: VoiceConversionPreset.\n                        "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setvolumeofeffect",
        "name": "setVolumeOfEffect",
        "description": "Sets the volume of a specified audio effect.\n",
        "parameters": [
            {
                "soundId": "The audio effect ID. The ID of each audio effect file is unique."
            },
            {
                "volume": "The playback volume. The value ranges from 0 to 100. The default value is 100, which represents the original volume."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_startaudiomixing2",
        "name": "startAudioMixing",
        "description": "Starts playing the music file.\nThis method mixes the specified local or online audio file with the audio from the microphone, or replaces the microphone's audio with the specified local or remote audio file. A successful method call triggers the audioMixingStateChanged (PLAY) callback. When the audio mixing file playback finishes, the SDK triggers the audioMixingStateChanged (STOPPED) callback on the local client.\n   \n       \n           Call this method after joining a channel. If you need to call startAudioMixing multiple times, ensure that the time interval between calling this method is more than 500 ms.\n           If the local audio mixing file does not exist, or if the SDK does not support the file format or cannot access the music file URL, the SDK returns WARN_AUDIO_MIXING_OPEN_ERROR (701).",
        "parameters": [
            {
                "filePath": "The absolute path or URL address (including the suffixes of the filename) of the audio effect file. For example: Android: /sdcard/emulated/0/audio.mp4, iOS: /var/mobile/Containers/Data/audio.mp4. Supported audio formats include MP3, AAC, M4A, MP4, WAV, and 3GP. See supported audio formats."
            },
            {
                "loopcount": "Whether to only play music files on the local client:\n          true: Only play music files on the local client so that only the local user can hear the music.\n          false: Publish music files to remote clients so that both the local user and remote users can hear the music.\n      "
            },
            {
                "replace": "Whether to replace the audio captured by the microphone with a music file:\n          true: Replace the audio captured by the microphone with a music file. Users can only hear the music.\n          false: Do not replace the audio captured by the microphone with a music file. Users can hear both music and audio captured by the microphone.\n      "
            },
            {
                "cycle": "The number of times the music file plays.\n          ≥ 0: The number of playback times. For example, 0 means that the SDK does not play the music file while 1 means that the SDK plays once.\n          -1: Play the music effect in an infinite loop.\n      "
            },
            {
                "startPos": "The playback position (ms) of the music file."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_startaudiorecording2",
        "name": "startAudioRecording",
        "description": "Starts audio recording on the client.\nDeprecated:\n                    This method is deprecated as of v3.4.0. Please use startAudioRecordingWithConfig instead.\n                \n            \n            The Agora SDK allows recording during a call. After successfully calling this method, you can record the audio of all the users in the channel and get an audio recording file. Supported formats of the recording file are as follows:\n      .wav: Large file size with high fidelity.\n      .aac: Small file size with low fidelity.\n  \n       \n   \n       \n  Ensure that the directory you use to save the recording file exists and is writable.\n  This method should be called after the joinChannel method. The recording automatically stops when you call the leaveChannel method.\n  For better recording effects, set quality to Medium or High when sampleRate is 44.1 kHz or 48 kHz.",
        "parameters": [
            {
                "filePath": "The absolute path (including the filename extensions) of the recording file. For example: C:\\music\\audio.aac.\n                        Ensure that the directory for the log files exists and is writable.\n                    "
            },
            {
                "sampleRate": "The sample rate (kHz) of the recording file. Supported values are as follows:\n     16000\n     (Default) 32000\n     44100\n     48000\n \n      \n  "
            },
            {
                "quality": "Recording quality. For more details, see AudioRecordingQuality."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_startaudiorecording3",
        "name": "startAudioRecordingWithConfig",
        "description": "Starts audio recording on the client.\nThe Agora SDK allows recording during a call. After successfully calling this method, you can record the audio of users in the channel and get an audio recording file. Supported formats of the recording file are as follows:\n                WAV: Large file size with high fidelity. For example, if the sample rate is 32,000 Hz, the file size for a recording duration of 10 minutes is around 73 M.\n                AAC: Small file size with low fidelity. For example, if the sample rate is 32,000 Hz and the recording quality is Medium, the file size for a recording duration of 10 minutes is around 2 M.\n            \n            Once the user leaves the channel, the recording automatically stops.\n            Call this method after joining a channel.",
        "parameters": [
            {
                "config": "Recording configuration. See AudioRecordingConfiguration."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_startchannelmediarelay",
        "name": "startChannelMediaRelay",
        "description": "Starts relaying media streams across channels. This method can be used to implement scenarios such as co-host across channels.\nAfter a successful method call, the SDK triggers the channelMediaRelayStateChanged and channelMediaRelayEvent callbacks, and these callbacks return the state and events of the media stream relay.\n  If the channelMediaRelayStateChanged callback returns Running (2) and None (0), and the channelMediaRelayEvent callback returns SentToDestinationChannel (4), it means that the SDK starts relaying media streams between the source channel and the destination channel.\n  If the channelMediaRelayStateChanged callback returns Failure (3), an exception occurs during the media stream relay.\n       \n   \n   \n       \n  Call this method after joining the channel.\n  This method takes effect only when you are a host in a live streaming channel.\n  After a successful method call, if you want to call this method again, ensure that you call the stopChannelMediaRelay method to quit the current relay.\n  Contact support@agora.io (https://agora-ticket.agora.io/) before implementing this function.\n  We do not support string user accounts in this API.",
        "parameters": [
            {
                "channelMediaRelayConfiguration": "The configuration of the media stream relay. For details, see ChannelMediaRelayConfiguration."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_startechotest2",
        "name": "startEchoTest",
        "description": "Starts an audio call test.\nThis method starts an audio call test to determine whether the audio devices (for example, headset and speaker) and the network connection are working properly. To conduct the test, let the user speak for a while, and the recording is played back within the set interval. If the user can hear the recording within the interval, the audio devices and network connection are working properly.\n            \n                \n                    Call this method before joining a channel.\n                    After calling stopEchoTest, you must call startEchoTest to end the test. Otherwise, the app cannot perform the next echo test, and you cannot join the channel.\n                    In the live streaming channels, only a host can call this method.",
        "parameters": [
            {
                "intervalInSeconds": "The time interval (s) between when you speak and when the recording plays back."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_startlastmileprobetest",
        "name": "startLastmileProbeTest",
        "description": "Starts the last mile network probe test.\nThis method starts the last-mile network probe test before joining a channel to get the uplink and downlink last mile network statistics, including the bandwidth, packet loss, jitter, and round-trip time (RTT).\n            Once this method is enabled, the SDK returns the following callbacks:\n                    lastmileQuality: The SDK triggers this callback within two seconds depending on the network conditions. This callback rates the network conditions and is more closely linked to the user experience.\n                    lastmileProbeResult: The SDK triggers this callback within 30 seconds depending on the network conditions. This callback returns the real-time statistics of the network conditions and is more objective.\n                \n            \n            This method applies to the following scenarios:\n                    Before a user joins a channel, call this method to check the uplink network quality.\n                    In a live streaming channel, call this method to check the uplink network quality before an audience member switches to a host.\n                \n            \n            \n                \n                    Do not call other methods before receiving the lastmileQuality and lastmileProbeResult callbacks. Otherwise, the callbacks may be interrupted.\n                    A host should not call this method after joining a channel (when in a call).",
        "parameters": [
            {
                "config": "The configurations of the last-mile network probe test. See LastmileProbeConfig."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_startpreview",
        "name": "startPreview",
        "description": "Enables the local video preview.\nThis method starts the local video preview before joining the channel. Before calling this method, ensure that you do the following:\n   \n       Call enableVideo to enable the video.\n   \n   \n       \n           The local preview enables the mirror mode by default.\n       After the local video preview is enabled, if you call leaveChannel to exit the channel, the local preview remains until you call stopPreview to disable it.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_startrhythmplayer",
        "name": "startRhythmPlayer",
        "description": "Enables the virtual metronome.\nIn music education, physical education and other scenarios, teachers usually need to use a metronome so that students can practice with the correct beat.  The meter is composed of a downbeat and upbeats. The first beat of each measure is called a downbeat, and the rest are called upbeats.\n            In this method, you need to set the paths of the upbeat and downbeat files, the number of beats per measure, the tempo, and whether to send the sound of the metronome to remote users.\n            \n                After enabling the virtual metronome, the SDK plays the specified audio effect file from the beginning, and controls the playback duration of each file according to beatsPerMinute you set in RhythmPlayerConfig. For example, if you set beatsPerMinute as 60, the SDK plays one beat every second. If the file duration exceeds the beat duration, the SDK only plays the audio within the beat duration.",
        "parameters": [
            {
                "sound1": "The absolute path or URL address (including the filename extensions) of the file for the downbeat. For example: Android: /sdcard/emulated/0/audio.mp4, iOS: /var/mobile/Containers/Data/audio.mp4. For the audio file formats supported by this method, see What formats of audio files does the Agora RTC SDK support."
            },
            {
                "sound2": "The absolute path or URL address (including the filename extensions) of the file for the upbeats. For example: Android: /sdcard/emulated/0/audio.mp4, iOS: /var/mobile/Containers/Data/audio.mp4. For the audio file formats supported by this method, see What formats of audio files does the Agora RTC SDK support."
            },
            {
                "config": "The metronome configuration. See RhythmPlayerConfig."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_startscreencapture",
        "name": "startScreenCapture",
        "description": "Starts screen sharing.\nDeprecated:\n  This method is deprecated as of v2.4.0. See the following methods instead:\n      startScreenCaptureByDisplayId\n      startScreenCaptureByWindowId\n  \n       \n   \n   This method shares the whole screen, a specified window, or the specified region:\n       Whole screen: Set windowId as 0 and rect as null.\n       A specified window: Set windowId as a value other than 0. Each window has a windowId that is not 0.\n       The specified region: Set windowId as 0 and rect as a value other than null. In this case, you can share the specified region, for example by dragging the mouse or implementing your own logic. The specified region is a region on the whole screen. Currently, sharing a specified region in a specific window is not supported.\n   \n   captureFreq is the captured frame rate once the screen-sharing function is enabled. The mandatory value ranges between 1 fps and 15 fps. No matter which of the above functions you enable, the SDK returns 0 when the execution succeeds, and an error code when the execution fails.",
        "parameters": [
            {
                "windowId": "The screen sharing area."
            },
            {
                "captureFreq": "(Mandatory) The captured frame rate. The value ranges between 1 fps and 15 fps."
            },
            {
                "rect": "Specifies the screen-sharing region: Rect. This parameter is valid when windowsId is set as 0. When rect is set as null, the whole screen is shared."
            },
            {
                "bitrate": "The bitrate of the screen share."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_startscreencapturebydisplayid",
        "name": "startScreenCaptureByDisplayId",
        "description": "Shares the screen by specifying the display ID.\nThis method shares a screen or part of the screen. You need to specify the ID of the screen to be shared in this method.\n   \n       \n           This method applies to macOS only.\n           Call this method after joining a channel.",
        "parameters": [
            {
                "displayId": "The display ID of the screen to be shared. This parameter specifies which screen you want to share."
            },
            {
                "regionRect": "(Optional) Sets the relative location of the region to the screen. If you do not set this parameter, the SDK shares the whole screen. For details, see Rectangle. If the specified region overruns the screen, the SDK shares only the region within it; if you set width or height as 0, the SDK shares the whole screen."
            },
            {
                "captureParams": "Screen sharing configurations. The default video dimension is 1920 x 1080, that is, 2,073,600 pixels. Agora uses the value of this parameter to calculate the charges. For details, see ScreenCaptureParameters."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_startscreencapturebyscreenrect",
        "name": "startScreenCaptureByScreenRect",
        "description": "Shares the whole or part of a screen by specifying the screen rect.\nThis method shares a screen or part of the screen. You need to specify the area of the screen to be shared.\n   Call this method after joining a channel.",
        "parameters": [
            {
                "screenRect": "Sets the relative location of the screen to the virtual screen."
            },
            {
                "regionRect": "(Optional) Sets the relative location of the region to the screen. If you do not set this parameter, the SDK shares the whole screen. See Rectangle. If the specified region overruns the screen, the SDK shares only the region within it; if you set width or height as 0, the SDK shares the whole screen."
            },
            {
                "captureParams": "The screen sharing encoding parameters. The default video dimension is 1920 x 1080, that is, 2,073,600 pixels. Agora uses the value of this parameter to calculate the charges. See ScreenCaptureParameters."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_startscreencapturebywindowid",
        "name": "startScreenCaptureByWindowId",
        "description": "Shares the whole or part of a window by specifying the window ID.\nThis method shares a window or part of the window. You need to specify the ID of the window to be shared.\n   \n       \n  Call this method after joining a channel.\n           This method applies to macOS and Windows only.",
        "parameters": [
            {
                "windowId": "The ID of the window to be shared."
            },
            {
                "regionRect": "(Optional) Sets the relative location of the region to the screen. If you do not set this parameter, the SDK shares the whole screen. For details, see Rectangle. If the specified region overruns the window, the SDK shares only the region within it; if you set width or height as 0, the SDK shares the whole window."
            },
            {
                "captureParams": "Screen sharing configurations. The default video dimension is 1920 x 1080, that is, 2,073,600 pixels. Agora uses the value of this parameter to calculate the charges. For details, see ScreenCaptureParameters."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_stopalleffects",
        "name": "stopAllEffects",
        "description": "Stops playing all audio effects.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_stopaudiomixing",
        "name": "stopAudioMixing",
        "description": "Stops playing and mixing the music file.\nThis method stops the audio mixing. Call this method when you are in a channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_stopaudiorecording",
        "name": "stopAudioRecording",
        "description": "Stops the audio recording on the client.\nIf you call startAudioRecordingWithConfig to start recording, you can call this method to stop the recording.\n            Once the user leaves the channel, the recording automatically stops.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_stopchannelmediarelay",
        "name": "stopChannelMediaRelay",
        "description": "Stops the media stream relay. Once the relay stops, the host quits all the destination channels.\nAfter a successful method call, the SDK triggers the channelMediaRelayStateChanged callback. If the callback reports Idle (0) and None (0), the host successfully stops the relay.\n   If the method call fails, the SDK triggers the channelMediaRelayStateChanged callback with the ServerNoResponse (2) or ServerConnectionLost (8) status code. You can call the leaveChannel method to leave the channel, and the media stream relay automatically stops.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_stopechotest",
        "name": "stopEchoTest",
        "description": "Stops the audio call test.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_stopeffect",
        "name": "stopEffect",
        "description": "Stops playing a specified audio effect.\n",
        "parameters": [
            {
                "soundId": "The audio effect ID. The ID of each audio effect file is unique."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_stoplastmileprobetest",
        "name": "stopLastmileProbeTest",
        "description": "Stops the last mile network probe test.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_stoppreview",
        "name": "stopPreview",
        "description": "Stops the local video preview.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_stoprhythmplayer",
        "name": "stopRhythmPlayer",
        "description": "Disables the virtual metronome.\nAfter calling startRhythmPlayer, you can call this method to disable the virtual metronome.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_stopscreencapture",
        "name": "stopScreenCapture",
        "description": "Stops screen sharing.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_switchcamera",
        "name": "switchCamera",
        "description": "Switches between front and rear cameras.\nThis method needs to be called after the camera is started (for example, by calling startPreview or joinChannel).",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_switchchannel2",
        "name": "switchChannel",
        "description": "Switches to a different channel, and configures whether to automatically subscribe to audio or video streams in the target channel.\nThis method allows the audience of a LIVE_BROADCASTING channel to switch to a different channel.\n   After the user successfully switches to another channel, the leaveChannel and joinChannelSuccess callbacks are triggered to indicate that the user has left the original channel and joined a new one.\n   Once the user switches to another channel, the user subscribes to the audio and video streams of all the other users in the channel by default, giving rise to usage and billing calculation. If you do not want to subscribe to a specified stream or all remote streams, call the mute methods accordingly.",
        "parameters": [
            {
                "token": "The token generated at your server.\n      In scenarios with low security requirements, token is optional and can be set as null.\n      In scenarios with high security requirements, set the value to the token generated from your server. If you enable the App Certificate, you must use a token to join the channel.\n  \n      Ensure that the App ID used for creating the token is the same App ID used by the createWithContext method for initializing the RTC engine.\n  "
            },
            {
                "channelName": "The name of the channel. This parameter signifies the channel in which users engage in real-time audio and video interaction. Under the premise of the same App ID, users who fill in the same channelId enter the same channel for audio and video interaction. The string length must be less than 64 bytes. Supported characters:\n All lowercase English letters: a to z.\n All uppercase English letters: A to Z.\n All numeric characters: 0 to 9.\n Space\n \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n      \n  "
            },
            {
                "options": "The channel media options. See ChannelMediaOptions."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_takesnapshot",
        "name": "takeSnapshot",
        "description": "Takes a snapshot of a video stream.\nThis method takes a snapshot of a video stream from the specified user, generates a JPG image, and saves it to the specified path.\n            The method is asynchronous, and the SDK has not taken the snapshot when the method call returns.  After a successful method call, the SDK triggers snapshotTaken callback to report whether the snapshot is successfully taken as well as the details for the snapshot taken.\n                        Call this method after joining a channel.\n                        If the video of the specified user is pre-processed, for example, added with watermarks or image enhancement effects, the generated snapshot also includes the pre-processing effects.",
        "parameters": [
            {
                "channel": "The channel name."
            },
            {
                "uid": "The user ID. Set uid as 0 if you want to take a snapshot of the local user's video."
            },
            {
                "filePath": "The local path (including the filename extensions) of the snapshot. For example,\n                    \n                        Windows: C:\\Users\\<user_name>\\AppData\\Local\\Agora\\<process_name>\\example.jpg\n                        iOS: /App Sandbox/Library/Caches/example.jpg\n                        macOS: ～/Library/Logs/example.jpg\n                        Android: /storage/emulated/0/Android/data/<package name>/files/example.jpg\n                    Ensure that the path you specify exists and is writable.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_unloadeffect",
        "name": "unloadEffect",
        "description": "Releases a specified preloaded audio effect from the memory.\n",
        "parameters": [
            {
                "soundId": "The audio effect ID. The ID of each audio effect file is unique."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_unregistermediametadataobserver",
        "name": "unregisterMediaMetadataObserver",
        "description": "Unregisters the specified metadata observer.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_updatechannelmediarelay",
        "name": "updateChannelMediaRelay",
        "description": "Updates the channels for media stream relay.\nAfter the media relay starts, if you want to relay the media stream to more channels, or leave the current relay channel, you can call the updateChannelMediaRelay method.\n   After a successful method call, the SDK triggers the channelMediaRelayEvent callback with the UpdateDestinationChannel (7) state code.\n   Call this method after the startChannelMediaRelay method to update the destination channel.",
        "parameters": [
            {
                "channelMediaRelayConfiguration": "The configuration of the media stream relay. For more details, see ChannelMediaRelayConfiguration."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_updatescreencaptureparameters",
        "name": "updateScreenCaptureParameters",
        "description": "Updates the screen sharing parameters.\n",
        "parameters": [
            {
                "captureParams": "The screen sharing encoding parameters. The default video dimension is 1920 x 1080, that is, 2,073,600 pixels. Agora uses the value of this parameter to calculate the charges. For details, see ScreenCaptureParameters."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_updatescreencaptureregion",
        "name": "updateScreenCaptureRegion",
        "description": "Updates the screen sharing region.\n",
        "parameters": [
            {
                "regionRect": "The relative location of the screen-shared area to the screen or window. If you do not set this parameter, the SDK shares the whole screen or window. See Rectangle. If the specified region overruns the screen or window, the SDK shares only the region within it; if you set width or height as 0, the SDK shares the whole screen or window."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_uploadlogfile",
        "name": "uploadLogFile",
        "description": "Uploads all SDK log files.\nSince\n  v3.3.0\n       \n   \n   Uploads all SDK log files from the client to the Agora server. After calling this method successfully, the SDK triggers the uploadLogResult callback to report whether the log file is successfully uploaded to the Agora server.\n   For easier debugging, Agora recommends that you bind the uploadLogFile method to the UI element of your app, to instruct the user to upload a log file when a quality issue occurs.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onactivespeaker",
        "name": "activeSpeaker",
        "description": "Occurs when the most active speaker is detected.\nAfter a successful call of enableAudioVolumeIndication, the SDK continuously detects which remote user has the loudest volume. During the current period, the remote user, who is detected as the loudest for the most times, is the most active user.\n   When the number of users exceeds two (included) and an active speaker is detected, the SDK triggers this callback and reports the uid of the most active speaker.\n  If the most active speaker remains the same, the SDK triggers the activeSpeaker callback only once.\n  If the most active speaker changes to another user, the SDK triggers this callback again and reports the uid of the new active speaker.",
        "parameters": [
            {
                "uid": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onaudiopublishstatechanged",
        "name": "audioPublishStateChanged",
        "description": "Occurs when the audio publishing state changes.\n",
        "parameters": [
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            },
            {
                "newState": "For the current publishing state, see StreamPublishState."
            },
            {
                "oldState": ""
            },
            {
                "channel": "The channel name."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onaudiosubscribestatechanged",
        "name": "audioSubscribeStateChanged",
        "description": "Occurs when the audio subscribing state changes.\n",
        "parameters": [
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            },
            {
                "newState": "The current subscribing status, see StreamSubscribeState for details."
            },
            {
                "oldState": ""
            },
            {
                "channel": "The channel name."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onchannelerror",
        "name": "error",
        "description": "The error code RtcChannel reported.\n",
        "parameters": [
            {
                "": ""
            },
            {
                "err": "The error code. For details, see Error Codes and Warning Codes."
            },
            {
                "msg": "The error message."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onchannelmediarelayevent",
        "name": "channelMediaRelayEvent",
        "description": "Reports events during the media stream relay.\n",
        "parameters": [
            {
                "code": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onchannelmediarelaystatechanged",
        "name": "channelMediaRelayStateChanged",
        "description": "Occurs when the state of the media stream relay changes.\nThe SDK returns the state of the current media relay with any error message.",
        "parameters": [
            {
                "code": " The error code of the channel media\n                        replay. For details, see ChannelMediaRelayError. "
            },
            {
                "state": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onchannelwarning",
        "name": "warning",
        "description": "Reports the warning code of RtcChannel.\n",
        "parameters": [
            {
                "": ""
            },
            {
                "warn": "Warning codes. For details, see Error Codes and Warning Codes."
            },
            {
                "msg": "The warning message."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onclientrolechanged",
        "name": "clientRoleChanged",
        "description": "Occurs when the user role switches in the interactive live streaming.\nThe SDK triggers this callback when the local user changes the user role after joining the channel.",
        "parameters": [
            {
                "newRole": "Role that the user switches to: ClientRole."
            },
            {
                "oldRole": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onconnectionlost",
        "name": "connectionLost",
        "description": "Occurs when the SDK cannot reconnect to Agora's edge server 10 seconds after its connection to the server is interrupted.\nThe SDK triggers this callback when it cannot connect to the server 10 seconds after calling the joinChannel method, regardless of whether it is in the channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onconnectionstatechanged",
        "name": "connectionStateChanged",
        "description": "Occurs when the network connection state changes.\nWhen the network connection state changes, the SDK triggers this callback and reports the current connection state and the reason for the change.",
        "parameters": [
            {
                "reason": "The reason for a connection state change.\n\n               "
            },
            {
                "state": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onjoinchannelsuccess",
        "name": "joinChannelSuccess",
        "description": "Occurs when a user joins a channel.\nThis callback notifies the application that a user joins a specified channel.",
        "parameters": [
            {
                "": ""
            },
            {
                "uid": "User ID. If you have specified a user ID in joinChannel, the ID will be returned here; otherwise, the SDK returns an ID automatically assigned by the Agora server."
            },
            {
                "elapsed": "The time elapsed (in milliseconds) from the local user calling joinChannel till this event."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onleavechannel",
        "name": "leaveChannel",
        "description": "Occurs when a user leaves a channel.\nWhen a user leaves the channel by using the leaveChannel method, the SDK uses this callback to notify the app when the user leaves the channel. With this callback, the app gets the channel information, such as the call duration and quality statistics.",
        "parameters": [
            {
                "stats": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onlocalpublishfallbacktoaudioonly",
        "name": "localPublishFallbackToAudioOnly",
        "description": "Occurs when the published media stream falls back to an audio-only stream.\nIf you call setLocalPublishFallbackOption and set option as AudioOnly, the SDK triggers this callback when the remote media stream falls back to audio-only mode due to poor uplink conditions, or when the remote media stream switches back to the video after the uplink network condition improves.\n   If the local stream falls back to the audio-only stream, the remote user receives the userMuteVideo callback.",
        "parameters": [
            {
                "isFallbackOrRecover": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onmetadatareceived",
        "name": "metadataReceived",
        "description": "Occurs when the local user receives Metadata.\n",
        "parameters": [
            {
                "buffer": "The recevied metadata."
            },
            {
                "uid": "The ID of the user who sent the metadata."
            },
            {
                "timeStampMs": "The timestamp (ms) of the received metadata."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onnetworkquality",
        "name": "networkQuality",
        "description": "Reports the last mile network quality of each user in the channel.\nThis callback reports the last mile network conditions of each user in the channel. Last mile refers to the connection between the local device and Agora's edge server.\n   The SDK triggers this callback once every two seconds. If a channel includes multiple users, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "rxQuality": "Downlink network quality rating of the user in terms of packet loss rate,\n                        average RTT, and jitter of the downlink network."
            },
            {
                "txQuality": "Uplink network quality rating of the user in terms of the transmission bit\n                        rate, packet loss rate, average RTT (Round-Trip Time) and jitter of the\n                        uplink network. This parameter is a quality rating helping you understand\n                        how well the current uplink network conditions can support the selected\n                        video encoder configuration. For example, a 1000 Kbps uplink network may be\n                        adequate for video frames with a resolution of 640 × 480 and a frame rate of\n                        15 fps in the LIVE_BROADCASTING profile, but might be inadequate for\n                        resolutions higher than 1280 × 720."
            },
            {
                "uid": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onrejoinchannelsuccess",
        "name": "rejoinChannelSuccess",
        "description": "Occurs when a user rejoins the channel.\nWhen a user loses connection with the server because of network problems, the SDK automatically tries to reconnect and triggers this callback upon reconnection.",
        "parameters": [
            {
                "elapsed": "Time elapsed (ms) from starting to reconnect until the SDK triggers this\n                        callback."
            },
            {
                "uid": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onremoteaudiostatechanged",
        "name": "remoteAudioStateChanged",
        "description": "Occurs when the remote audio state changes.\nWhen the audio state of a remote user (in the voice/video call channel) or host (in the live streaming channel) changes, the SDK triggers this callback to report the current state of the remote audio stream.\n               This callback does not work properly when the number of users (in the voice/video call channel) or hosts (in the live streaming channel) in the channel exceeds 17.",
        "parameters": [
            {
                "reason": "The reason of the remote audio state change, see AudioRemoteStateReason."
            },
            {
                "state": "The state of the remote audio, see AudioRemoteState."
            },
            {
                "uid": ""
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling the joinChannel method until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onremoteaudiostats",
        "name": "remoteAudioStats",
        "description": "Reports the transport-layer statistics of each remote audio stream.\nThe SDK triggers this callback once every two seconds for each remote user who is sending audio streams. If a channel includes multiple remote users, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "stats": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onremotesubscribefallbacktoaudioonly",
        "name": "remoteSubscribeFallbackToAudioOnly",
        "description": "Occurs when the remote media stream falls back to audio-only stream due to poor network conditions or switches back to the video stream after the network conditions improve.\nIf you call setRemoteSubscribeFallbackOption and set option as AudioOnly, the SDK triggers this callback when the remote media stream falls back to audio-only mode due to poor downlink conditions, or when the remote media stream switches back to the video after the downlink network condition improves.\n   Once the remote media stream switches to the low stream due to poor network conditions, you can monitor the stream switch between a high and low stream in the RemoteVideoStats callback.",
        "parameters": [
            {
                "isFallbackOrRecover": "\n true: The remotely subscribed media stream falls back to audio-only due to poor network conditions.\n false: The remotely subscribed media stream switches back to the video stream after the network conditions improved.\n      \n  "
            },
            {
                "uid": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onremotevideostatechanged",
        "name": "remoteVideoStateChanged",
        "description": "Occurs when the remote video state changes.\nThis callback does not work properly when the number of users (in the voice/video call channel) or hosts (in the live streaming channel) in the channel exceeds 17.",
        "parameters": [
            {
                "reason": " The reason for the remote video state\n                              change, see VideoRemoteStateReason. "
            },
            {
                "state": " The state of the remote video, see\n                              VideoRemoteState. "
            },
            {
                "uid": ""
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling the joinChannel method until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onremotevideostats",
        "name": "remoteVideoStats",
        "description": "Reports the transport-layer statistics of each remote video stream.\nReports the statistics of the video stream from the remote users. The SDK triggers this callback once every two seconds for each remote user. If a channel has multiple users/hosts sending video streams, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "stats": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onrequesttoken",
        "name": "requestToken",
        "description": "Occurs when the token expires.\nWhen the token expires during a call, the SDK triggers this callback to remind the app to renew the token.\n            Once you receive this callback, generate a new token on your app server, and call joinChannel to rejoin the channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onrtcstats",
        "name": "rtcStats",
        "description": "Reports the statistics of the current call.\nThe SDK triggers this callback once every two seconds after the user joins the channel.",
        "parameters": [
            {
                "stats": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onrtmpstreamingevent",
        "name": "rtmpStreamingEvent",
        "description": "Reports events during the RTMP or RTMPS streaming.\n",
        "parameters": [
            {
                "eventCode": "The event code of the streaming. For details, see RtmpStreamingEvent."
            },
            {
                "url": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onrtmpstreamingstatechanged",
        "name": "rtmpStreamingStateChanged",
        "description": "Occurs when the state of the RTMP or RTMPS streaming changes.\nThe SDK triggers this callback to report the result of the local user calling the addPublishStreamUrl or removePublishStreamUrl method. When the RTMP/RTMPS streaming status changes, the SDK triggers this callback and report the URL address and the current status of the streaming. This callback indicates the state of the RTMP or RTMPS streaming. When exceptions occur, you can troubleshoot issues by referring to the detailed error descriptions in the error code parameter.",
        "parameters": [
            {
                "errCode": "The detailed error information for streaming, see RtmpStreamingErrorCode."
            },
            {
                "state": "The RTMP or RTMPS streaming state, see RtmpStreamingState. When the streaming status is Failure(4), you can view the error information in the errorCode parameter."
            },
            {
                "url": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onstreaminjectedstatus",
        "name": "streamInjectedStatus",
        "description": "Occurs when a media stream URL address is added to the interactive live streaming.\n",
        "parameters": [
            {
                "status": "State of the externally injected stream: InjectStreamStatus."
            },
            {
                "uid": "User ID."
            },
            {
                "url": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onstreammessage",
        "name": "streamMessage",
        "description": "Occurs when the local user receives the data stream from the remote user.\nThe SDK triggers this callback when the local user receives the stream message that the remote user sends by calling the sendStreamMessage method.",
        "parameters": [
            {
                "data": "The data received."
            },
            {
                "streamId": "The stream ID of the received message."
            },
            {
                "uid": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onstreammessageerror",
        "name": "streamMessageError",
        "description": "Occurs when the local user does not receive the data stream from the remote user.\nThe SDK triggers this callback when the local user fails to receive the stream message that the remote user sends by calling the sendStreamMessage method.",
        "parameters": [
            {
                "cached": "Number of incoming cached messages when the data stream is interrupted."
            },
            {
                "missed": "The number of lost messages."
            },
            {
                "error": "The error code."
            },
            {
                "streamId": "The stream ID of the received message."
            },
            {
                "uid": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_ontokenprivilegewillexpire",
        "name": "tokenPrivilegeWillExpire",
        "description": "Occurs when the token expires in 30 seconds.\nWhen the token is about to expire in 30 seconds, the SDK triggers this callback to remind the app to renew the token. Upon receiving this callback, generate a new token on your server, and call renewToken to pass the new token to the SDK.",
        "parameters": [
            {
                "token": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_ontranscodingupdated",
        "name": "transcodingUpdated",
        "description": "Occurs when the publisher's transcoding is updated.\nIf you call the setLiveTranscoding\n                method to set the LiveTranscoding class for the first time, the\n                SDK does not trigger this callback.\n        When the LiveTranscoding class in the setLiveTranscoding method updates, the SDK triggers the transcodingUpdated callback to report the update information.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onuserjoined",
        "name": "userJoined",
        "description": "Occurs when a remote user (COMMUNICATION)/ host (LIVE_BROADCASTING) joins the channel.\nIn a communication channel, this callback indicates that a remote user joins the channel. The SDK also triggers this callback to report the existing users in the channel when a user joins the channel.\n   In a live-broadcast channel, this callback indicates that a host joins the channel. The SDK also triggers this callback to report the existing hosts in the channel when a host joins the channel. Agora recommends limiting the number of hosts to 17.\n        \n  The SDK triggers this callback under one of the following circumstances:\n  A remote user/host joins the channel by calling the joinChannel method.\n  A remote user switches the user role to the host after joining the channel.\n  A remote user/host rejoins the channel after a network interruption.\n  The host injects an online media stream into the channel by calling the addInjectStreamUrl method.",
        "parameters": [
            {
                "uid": ""
            },
            {
                "elapsed": "Time delay (ms) fromthe local user calling joinChannel until this callback is triggered."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onuseroffline",
        "name": "userOffline",
        "description": "Occurs when a remote user (COMMUNICATION)/ host (LIVE_BROADCASTING) leaves the channel.\nThere are two reasons for users to become offline:\n                    Leave the channel: When a user/host leaves the channel, the user/host sends a goodbye message. When this message is received, the SDK determines that the user/host leaves the channel.\n                    Drop offline: When no data packet of the user or host is received for a certain period of time (20 seconds for the communication profile, and more for the live broadcast profile), the SDK assumes that the user/host drops offline. A poor network connection may lead to false detections. It's recommended to use the Agora RTM SDK for reliable offline detection.",
        "parameters": [
            {
                "reason": "Reasons why the user goes offline: UserOfflineReason. "
            },
            {
                "uid": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onusersuperresolutionenabled",
        "name": "userSuperResolutionEnabled",
        "description": "Reports whether the super resolution feature is successfully enabled.\nAfter calling enableRemoteSuperResolution, the SDK triggers the callback to report whether super resolution is successfully enabled. If it is not successfully enabled, use reason for troubleshooting.",
        "parameters": [
            {
                "reason": "The reason why super resolution algorithm is not successfully enabled. For details, see SuperResolutionStateReason."
            },
            {
                "enabled": "Whether super resolution is successfully enabled:\n                        true: Super resolution is successfully enabled.\n                        false: Super resolution is not successfully enabled.\n                    "
            },
            {
                "uid": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onvideopublishstatechanged",
        "name": "videoPublishStateChanged",
        "description": "Occurs when the video publishing state changes.\n",
        "parameters": [
            {
                "null": ""
            },
            {
                "channel": "The channel name."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onvideosizechanged",
        "name": "videoSizeChanged",
        "description": "Occurs when the video size or rotation of a specified user changes.\n",
        "parameters": [
            {
                "rotation": "The rotation information. The value range is [0,360)."
            },
            {
                "height": "The height (pixels) of the video stream."
            },
            {
                "width": "The width (pixels) of the video stream."
            },
            {
                "uid": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ichanneleventhandler_onvideosubscribestatechanged",
        "name": "videoSubscribeStateChanged",
        "description": "Occurs when the video subscribing state changes.\n",
        "parameters": [
            {
                "null": ""
            },
            {
                "channel": "The channel name."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_imetadataobserver_onmetadatareceived",
        "name": "metadataReceived",
        "description": "Occurs when the local user receives the metadata.\n",
        "parameters": [
            {
                "uid": "The user ID."
            },
            {
                "timeStampMs": "The timestamp."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onactivespeaker",
        "name": "activeSpeaker",
        "description": "Occurs when the most active speaker is detected.\nAfter a successful call of enableAudioVolumeIndication, the SDK continuously detects which remote user has the loudest volume. During the current period, the remote user, who is detected as the loudest for the most times, is the most active user.\n   When the number of users exceeds two (included) and an active speaker is detected, the SDK triggers this callback and reports the uid of the most active speaker.\n  If the most active speaker remains the same, the SDK triggers the activeSpeaker callback only once.\n  If the most active speaker changes to another user, the SDK triggers this callback again and reports the uid of the new active speaker.",
        "parameters": [
            {
                "uid": "The user ID of the most active speaker."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onapicallexecuted",
        "name": "apiCallExecuted",
        "description": "Occurs when a method is executed by the SDK.\n",
        "parameters": [
            {
                "error": "The error code returned by the SDK when the method call fails. "
            },
            {
                "api": "The method executed by the SDK."
            },
            {
                "result": "The result of the method call."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onaudiodevicestatechanged",
        "name": "audioDeviceStateChanged",
        "description": "Occurs when the audio device state changes.\nThis callback notifies the application that the system's audio device state is changed. For example, a headset is unplugged from the device.\n            This method is for Windows and macOS only.",
        "parameters": [
            {
                "deviceId": "The device ID."
            },
            {
                "deviceType": "The device type. For details, see MediaDeviceType."
            },
            {
                "deviceState": "The device state.\n      on macOS: \n          0: The device is ready for use.\n          8: The device is not connected.\n      \n      On Windows: MediaDeviceStateType.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onaudiodevicevolumechanged",
        "name": "audioDeviceVolumeChanged",
        "description": "Occurs when the volume on the playback or audio capture device, or the volume in the application changes.\n",
        "parameters": [
            {
                "deviceType": "The device type. For details, see MediaDeviceType."
            },
            {
                "volume": "The volume value. The range is [0, 255]."
            },
            {
                "muted": "Whether the audio device is muted:\n      true: The audio device is muted.\n      false: The audio device is not muted.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onaudioeffectfinished",
        "name": "audioEffectFinished",
        "description": "Occurs when the playback of the local audio effect file finishes.\nThis callback occurs when the local audio effect file finishes playing.",
        "parameters": [
            {
                "soundId": "The audio effect ID. The ID of each audio effect file is unique."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onaudiomixingfinished",
        "name": "audioMixingFinished",
        "description": "Occurs when the playback of the local music file finishes.\nDeprecated:\n                    This method is deprecated as of v2.4.0. Use audioMixingStateChanged instead.\n                \n            \n            After you call startAudioMixing to play a local music\n                file, this callback occurs when the playback finishes. If the call of startAudioMixing fails, the callback returns the error code\n                    WARN_AUDIO_MIXING_OPEN_ERROR.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "callback_onaudiomixingstatechanged",
        "name": "audioMixingStateChanged",
        "description": "Occurs when the playback state of the music file changes.\nThis callback occurs when the playback state of the music file changes, and reports the current state and error code.",
        "parameters": [
            {
                "state": "The playback state of the music file. "
            },
            {
                "reason": "The reason why the playback state of the music file changes. "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onaudiopublishstatechanged",
        "name": "audioPublishStateChanged",
        "description": "Occurs when the audio publishing state changes.\n",
        "parameters": [
            {
                "channel": "The name of the channel."
            },
            {
                "oldState": "For the previous publishing state, see StreamPublishState."
            },
            {
                "newState": "For the current publishing state, see StreamPublishState."
            },
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onaudioquality",
        "name": "audioQuality",
        "description": "Reports the statistics of the audio stream from each remote user.\nDeprecated:\n      remoteAudioStats instead.\n  \n       \n   \n   The SDK triggers this callback once every two seconds to report the audio quality of each remote user/host sending an audio stream. If a channel has multiple users/hosts sending audio streams, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "uid": "The user ID of the remote user sending the audio stream."
            },
            {
                "quality": "Audio quality of the user. \n                                Unknown (0): The quality is unknown.\n                                Excellent (1): The quality is excellent.\n                                Good (2): The network quality seems excellent, but the bitrate can be slightly lower than excellent.\n                                Poor (3): Users can feel the communication is slightly impaired.\n                                Bad (4): Users cannot communicate smoothly.\n                                VBad (5): The quality is so bad that users can barely communicate.\n                                Down (6): The network is down, and users cannot communicate at all.\n                            \n                        "
            },
            {
                "delay": "The network delay (ms) from the sender to the receiver, including the delay\n                        caused by audio sampling pre-processing, network transmission, and network\n                        jitter buffering."
            },
            {
                "lost": "Packet loss rate (%) of the audio packet sent from the sender to the\n                        receiver."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onaudioroutechanged",
        "name": "audioRouteChanged",
        "description": "Occurs when the local audio route changes.\n",
        "parameters": [
            {
                "routing": "The current audio routing. For details, see AudioOutputRouting.\n               "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onaudiosubscribestatechanged",
        "name": "audioSubscribeStateChanged",
        "description": "Occurs when the audio subscribing state changes.\n",
        "parameters": [
            {
                "channel": "The name of the channel."
            },
            {
                "oldState": "The previous subscribing status, see StreamSubscribeState\n                        for details."
            },
            {
                "newState": "The current subscribing status, see StreamSubscribeState for details."
            },
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onaudiovolumeindication",
        "name": "audioVolumeIndication",
        "description": "Reports the volume information of users.\nBy default, this callback is disabled. You can enable it by calling enableAudioVolumeIndication. Once this callback is enabled and users send streams in the channel, the SDK triggers the enableAudioVolumeIndication callback at the time interval set in audioVolumeIndication. The SDK triggers two independent audioVolumeIndication callbacks simultaneously, which separately report the volume information of the local user who sends a stream and the remote users (up to three) whose instantaneous volumes are the highest.\n   After you enable this callback, calling muteLocalAudioStream affects the SDK's behavior as follows:\n  If the local user stops publishing the audio stream, the SDK stops triggering the local user's callback.\n  20 seconds after a remote user whose volume is one of the three highest stops publishing the audio stream, the callback excludes this user's information; 20 seconds after all remote users stop publishing audio streams, the SDK stops triggering the callback for remote users.",
        "parameters": [
            {
                "speakers": "The volume information of the users, see AudioVolumeInfo. An empty speakers array in the callback indicates that no remote user is in the channel or sending a stream at the moment."
            },
            {
                "totalVolume": "The volume of the speaker. The value range is [0,255].\n     In the callback for the local user, totalVolume is the volume of the local user who sends a stream.\n     In the callback for remote users, totalVolume is the sum of the volume of all remote users (up to three) whose instantaneous volumes are the highest. If the user calls startAudioMixing, then totalVolume is the volume after audio mixing.\n \n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_oncameraexposureareachanged",
        "name": "cameraExposureAreaChanged",
        "description": "Occurs when the camera exposure area changes.\nThe SDK triggers this callback when the local user changes the camera exposure position by calling setCameraExposurePosition.\n            This method is for Android and iOS only.",
        "parameters": [
            {
                "rect": "The focus rectangle in the local preview."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_oncamerafocusareachanged",
        "name": "cameraFocusAreaChanged",
        "description": "Occurs when the camera focus area changes.\nThe SDK triggers this callback when the local user changes the camera focus position by calling setCameraFocusPositionInPreview.\n            This method is for Android and iOS only.",
        "parameters": [
            {
                "rect": "The focus rectangle in the local preview."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_oncameraready",
        "name": "cameraReady",
        "description": "Occurs when the camera turns on and is ready to capture the video.\nDeprecated:\n                    \n                        Please use Capturing(1) in \n         instead.\n                    \n                \n            \n            This callback indicates that the camera has been successfully turned on and\n                you can start to capture video.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "callback_onchannelmediarelayevent",
        "name": "channelMediaRelayEvent",
        "description": "Reports events during the media stream relay.\n",
        "parameters": [
            {
                "code": "The event code of channel media relay:\n                                Disconnect(0): The user disconnects from the server due to a poor network connection.\n                                Connected(1): The user is connected to the server.\n                                JoinedSourceChannel(2): The user joins the source channel.\n                                JoinedDestinationChannel(3): The user joins the destination channel.\n                                SentToDestinationChannel(4): The SDK starts relaying the media stream to the destination channel.\n                                ReceivedVideoPacketFromSource(5): The server receives the video stream from the source channel.\n                                ReceivedAudioPacketFromSource(6): The server receives the audio stream from the source channel.\n                                UpdateDestinationChannel(7): The destination channel is updated.\n                                UpdateDestinationChannelRefused(8): The destination channel update fails due to internal reasons.\n                                UpdateDestinationChannelNotChange(9): The destination channel does not change, which means that the destination channel fails to be updated.\n                                UpdateDestinationChannelIsNil(10): The destination channel name is null.\n                                VideoProfileUpdate(11): The video profile is sent to the server.\n                            PauseSendPacketToDestChannelSuccess(12): The SDK successfully pauses relaying the media stream to destination channels.\n                            PauseSendPacketToDestChannelFailed(13): The SDK fails to pause relaying the media stream to destination channels.\n                            ResumeSendPacketToDestChannelSuccess(14): The SDK successfully resumes relaying the media stream to destination channels.\n                            ResumeSendPacketToDestChannelFailed(15): The SDK fails to resume relaying the media stream to destination channels.\n                            \n                        \n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onchannelmediarelaystatechanged",
        "name": "channelMediaRelayStateChanged",
        "description": "Occurs when the state of the media stream relay changes.\nThe SDK returns the state of the current media relay with any error message.",
        "parameters": [
            {
                "state": " The state code. For details, see ChannelMediaRelayState. "
            },
            {
                "code": " The error code of the channel media\n                        replay. For details, see ChannelMediaRelayError. "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onclientrolechanged",
        "name": "clientRoleChanged",
        "description": "Occurs when the user role switches in the interactive live streaming.\nThe SDK triggers this callback when the local user switches the user role after joining the channel.",
        "parameters": [
            {
                "oldRole": "Role that the user switches from: ClientRole."
            },
            {
                "newRole": "Role that the user switches to: ClientRole."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onconnectionbanned",
        "name": "connectionBanned",
        "description": "Occurs when the connection is banned by the Agora server.\nDeprecated:\n                    Please use connectionStateChanged instead.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "callback_onconnectioninterrupted",
        "name": "connectionInterrupted",
        "description": "Occurs when the connection between the SDK and the server is interrupted.\nDeprecated:\n  Please use connectionStateChanged instead.\n       \n   \n   The SDK triggers this callback when it loses connection with the server for more than four seconds after the connection is established. After triggering this callback, the SDK tries to reconnect to the server. You can use this callback to implement pop-up reminders. The difference between this callback and connectionLost is:\n       The SDK triggers the connectionInterrupted callback when it loses connection with the server for more than four seconds after it successfully joins the channel.\n       The SDK triggers the connectionLost callback when it loses connection with the server for more than 10 seconds, whether or not it joins the channel.\n   If the SDK fails to rejoin the channel 20 minutes after being disconnected from Agora's edge server, the SDK stops rejoining the channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "callback_onconnectionlost",
        "name": "connectionLost",
        "description": "Occurs when the SDK cannot reconnect to Agora's edge server 10 seconds after its connection to the server is interrupted.\nThe SDK triggers this callback when it cannot connect to the server 10 seconds after\n                calling the joinChannel method, regardless of whether it is in\n                the channel. If the SDK fails to rejoin the channel 20 minutes after being\n                disconnected from Agora's edge server, the SDK stops rejoining the channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "callback_onconnectionstatechanged",
        "name": "connectionStateChanged",
        "description": "Occurs when the network connection state changes.\nWhen the network connection state changes, the SDK triggers this callback and reports the current connection state and the reason for the change.",
        "parameters": [
            {
                "state": "The current connection state.\n      "
            },
            {
                "reason": "The reason for a connection state change.\n\n               "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onerror",
        "name": "error",
        "description": "Reports an error during SDK runtime.\nThis callback indicates that an error (concerning network or media) occurs during SDK runtime. In most cases, the SDK cannot fix the issue and resume running. The SDK requires the application to take action or informs the user about the issue. For example, the SDK reports an ERR_START_CALL error when failing to initialize a call. The app informs the user that the call initialization failed and calls leaveChannel to leave the channel.",
        "parameters": [
            {
                "err": "The error code."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onfacepositionchanged",
        "name": "facePositionChanged",
        "description": "Reports the face detection result of the local user.\nOnce you enable face detection by calling enableFaceDetection(true), you can get the following information on the local user in real-time:\n  The width and height of the local video.\n  The position of the human face in the local video.\n  The distance between the human face and the screen.\n       \n   \n   The distance between the human face and the screen is based on the fitting calculation of the local video size and the position of the human face captured by the camera.\n   \n       \n           If the SDK does not detect a face, it reduces the frequency of this callback to reduce power consumption on the local device.\n  The SDK stops triggering this callback when a human face is in close proximity to the screen.",
        "parameters": [
            {
                "imageWidth": "The width (px) of the video image captured by the local camera."
            },
            {
                "imageHeight": "The height (px) of the video image captured by the local camera."
            },
            {
                "faces": "For the information of the detected face, see FacePositionInfo for details. If several faces are detected,\n                        this callback reports several FacePositionInfo\n                        arrays. The length of the array can be 0, which means that no human face is\n                        detected in front of the camera."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onfirstlocalaudioframe",
        "name": "firstLocalAudioFrame",
        "description": "Occurs when the engine sends the first local audio frame.\nDeprecated:\n  Please use \n         instead.",
        "parameters": [
            {
                "elapsed": "The time elapsed (ms) from the local user calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onfirstlocalaudioframepublished",
        "name": "firstLocalAudioFramePublished",
        "description": "        Occurs when the first audio frame is published.\nThe SDK triggers this callback under one of the following circumstances: \n                    The local client enables the audio module and calls joinChannel successfully.\n                    The local client calls muteLocalAudioStream(true) and muteLocalAudioStream(false) in sequence.\n                    The local client calls disableAudio and enableAudio in sequence.",
        "parameters": [
            {
                "elapsed": "The time elapsed (ms) from the local client calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onfirstlocalvideoframe",
        "name": "firstLocalVideoFrame",
        "description": "Occurs when the first local video frame is rendered.\nThe SDK triggers this callback when the first local video frame is displayed/rendered on the local video view.",
        "parameters": [
            {
                "width": "The width (px) of the first local video frame."
            },
            {
                "height": "The height (px) of the first local video frame."
            },
            {
                "elapsed": "The time elapsed (ms) from the local user calling joinChanneluntil the SDK triggers this callback. If you\n                              call startPreview before calling joinChannel, then this parameter is the time elapsed from\n                              calling the startPreview method until the SDK\n                              triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onfirstlocalvideoframepublished",
        "name": "firstLocalVideoFramePublished",
        "description": "Occurs when the first video frame is published.\nThe SDK triggers this callback under one of the following circumstances:\n  The local client enables the video module and calls joinChannel successfully.\n  The local client calls muteLocalVideoStream(true) and muteLocalVideoStream(false) in sequence.\n  The local client calls disableVideo and enableVideo in sequence.",
        "parameters": [
            {
                "elapsed": "The time elapsed(ms) from the local client calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onfirstremoteaudiodecoded",
        "name": "firstRemoteAudioDecoded",
        "description": "Occurs when the SDK decodes the first remote audio frame for playback.\nDeprecated:\n  Please use remoteAudioStateChanged instead.\n       \n   \n   The SDK triggers this callback under one of the following circumstances: \n                    The remote user joins the channel and sends the audio stream for the first time.\n                    The remote user's audio is offline and then goes online to re-send audio. It means the local user cannot receive audio in 15 seconds. Reasons for such an interruption include:\n                            The remote user leaves channel.\n                            The remote user drops offline.\n                            The remote user calls muteLocalAudioStream to stop sending the audio stream.\n                            The remote user calls disableAudio to disable audio.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "elapsed": "The time elapsed (ms) from the local user calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onfirstremoteaudioframe",
        "name": "firstRemoteAudioFrame",
        "description": "Occurs when the SDK receives the first audio frame from a specific remote user.\nDeprecated:\n  Please use remoteAudioStateChanged instead.",
        "parameters": [
            {
                "uid": "The user ID of the remote user."
            },
            {
                "elapsed": "The time elapsed (ms) from the local user calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onfirstremotevideodecoded",
        "name": "firstRemoteVideoDecoded",
        "description": "Occurs when the first remote video frame is received and decoded.\nDeprecated:\n  Please use the remoteVideoStateChanged callback with the following parameters:\n      Starting (1).\n      Decoding (2).\n  \n  \n       \n   \n   The SDK triggers this callback under one of the following circumstances:\n                    The remote user joins the channel and sends the video stream.\n                    The remote user stops sending the video stream and re-sends it after 15 seconds. Reasons for such an interruption include:\n                            The remote user leaves the channel.\n                            The remote user drops offline.\n                            The remote user calls muteLocalVideoStream to stop sending the video stream.\n                            The remote user calls disableVideo to disable video.",
        "parameters": [
            {
                "uid": "The user ID of the remote user sending the video stream."
            },
            {
                "width": "The width (px) of the video stream."
            },
            {
                "height": "The height (px) of the video stream."
            },
            {
                "elapsed": "The time elapsed (ms) from the local user calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onfirstremotevideoframe",
        "name": "firstRemoteVideoFrame",
        "description": "          Occurs when the first remote video frame is rendered.\nThe SDK triggers this callback when the first local video frame is displayed/rendered on the local video view.  The application can retrieve the time elapsed (the elapsed parameter) from a user joining the channel until the first video frame is displayed.",
        "parameters": [
            {
                "uid": "The user ID of the remote user sending the video stream."
            },
            {
                "width": "The width (px) of the video stream."
            },
            {
                "height": "The height (px) of the video stream."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onjoinchannelsuccess",
        "name": "joinChannelSuccess",
        "description": "Occurs when a user joins a channel.\nThis callback notifies the application that a user joins a specified channel.",
        "parameters": [
            {
                "channel": "The name of the channel."
            },
            {
                "uid": "The ID of the user who joins the channel."
            },
            {
                "elapsed": "The time elapsed (ms) from the local user calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onlastmileproberesult",
        "name": "lastmileProbeResult",
        "description": "Reports the last mile network probe result.\nThe SDK triggers this callback within 30 seconds after the app calls startLastmileProbeTest.",
        "parameters": [
            {
                "result": "The uplink and downlink last-mile network probe test result. For details,\n                        see LastmileProbeResult."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onlastmilequality",
        "name": "lastmileQuality",
        "description": "Reports the last-mile network quality of the local user once every two seconds.\nThis callback reports the last-mile network conditions of the local user before the user joins the channel. Last mile refers to the connection between the local device and Agora's edge server.\n   Before the user joins the channel, this callback is triggered by the SDK once startLastmileProbeTest is called and reports the last-mile network conditions of the local user.",
        "parameters": [
            {
                "quality": "The last mile network quality.\n                                Unknown (0): The quality is unknown.\n                                Excellent (1): The quality is excellent.\n                                Good (2): The network quality seems excellent, but the bitrate can be slightly lower than excellent.\n                                Poor (3): Users can feel the communication is slightly impaired.\n                                Bad (4): Users cannot communicate smoothly.\n                                VBad (5): The quality is so bad that users can barely communicate.\n                                Down (6): The network is down, and users cannot communicate at all.\n                            \n                         See\n                        NetworkQuality. "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onleavechannel",
        "name": "leaveChannel",
        "description": "Occurs when a user leaves a channel.\nThis callback notifies the app that the user leaves the channel by calling leaveChannel. From this callback, the app can get information such as the call duration and quality statistics.",
        "parameters": [
            {
                "stats": "The statistics of the call, see RtcStats ."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onlocalaudiostatechanged",
        "name": "localAudioStateChanged",
        "description": "Occurs when the local audio stream state changes.\nWhen the state of the local audio stream changes (including the state of the audio capture and encoding), the SDK triggers this callback to report the current state. This callback indicates the state of the local audio stream, and allows you to troubleshoot issues when audio exceptions occur.\n            When the state isFailed (3), you can view the error information in the error parameter.",
        "parameters": [
            {
                "state": "The state of the local audio. For details, see AudioLocalState."
            },
            {
                "error": "Local audio state error codes. For details, see AudioLocalError."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onlocalaudiostats",
        "name": "localAudioStats",
        "description": "Reports the statistics of the local audio stream.\nThe SDK triggers this callback once every two seconds.",
        "parameters": [
            {
                "stats": "Local audio statistics. For details, see LocalAudioStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onlocalpublishfallbacktoaudioonly",
        "name": "localPublishFallbackToAudioOnly",
        "description": "Occurs when the published media stream falls back to an audio-only stream.\nIf you call setLocalPublishFallbackOption and set option as AudioOnly, the SDK triggers this callback when the remote media stream falls back to audio-only mode due to poor uplink conditions, or when the remote media stream switches back to the video after the uplink network condition improves.\n   If the local stream falls back to the audio-only stream, the remote user receives the userMuteVideo callback.",
        "parameters": [
            {
                "isFallbackOrRecover": "\n                            true: The published stream falls\n                                back to audio-only due to poor network conditions.\n                            false: The published stream switches\n                                back to the video after the network conditions improve.\n                        \n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onlocaluserregistered",
        "name": "localUserRegistered",
        "description": "Occurs when the local user registers a user account.\nAfter the local user successfully calls registerLocalUserAccount to register the user account or calls joinChannelWithUserAccount to join a channel, the SDK triggers the callback and informs the local user's UID and User Account.",
        "parameters": [
            {
                "uid": "The ID of the local user."
            },
            {
                "userAccount": "The user account of the local user."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onlocalvideostatechanged",
        "name": "localVideoStateChanged",
        "description": "        Occurs when the local video stream state changes.\nWhen the state of the local video stream changes (including the state of the video capture and encoding), the SDK triggers this callback to report the current state. This callback indicates the state of the local video stream, including camera capturing and video encoding, and allows you to troubleshoot issues when exceptions occur.\n            The SDK triggers the localVideoStateChanged callback with the state code Failed and error code CaptureFailure in the following situations:\n                    The app switches to the background, and the system gets the camera resource.\n                    The camera starts normally, but does not output video for four consecutive seconds.\n                \n            When the camera outputs the captured video frames, if the video frames are the same for 15 consecutive frames, the SDK triggers the localVideoStateChanged callback with the state code Capturing and error code CaptureFailure. Note that the video frame duplication detection is only available for video frames with a resolution greater than 200 × 200, a frame rate greater than or equal to 10 fps, and a bitrate less than 20 Kbps.\n            For some device models, the SDK does not trigger this callback when the state of the local video changes while the local video capturing device is in use, so you have to make your own timeout judgment.",
        "parameters": [
            {
                "localVideoState": "The state of the local video, see LocalVideoStreamState.\n                        "
            },
            {
                "error": "The detailed error information, see LocalVideoStreamError.\n                        "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onlocalvideostats",
        "name": "localVideoStats",
        "description": "Reports the statistics of the local video stream.\nThe SDK triggers this callback once every two seconds to report the statistics of the local video stream.",
        "parameters": [
            {
                "stats": "The statistics of the local video stream. For details, see LocalVideoStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onmediaengineloadsuccess",
        "name": "mediaEngineLoadSuccess",
        "description": "Occurs when the media engine loads.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "callback_onmediaenginestartcallsuccess",
        "name": "mediaEngineStartCallSuccess",
        "description": "Occurs when the media engine call starts.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "callback_onmicrophoneenabled",
        "name": "microphoneEnabled",
        "description": "Occurs when the microphone is enabled/disabled.\nDeprecated:\n                    \n                        Please use the localAudioStateChanged callback:\n                                Stopped(0).\n                                Recording(1).\n                            \n                    \n                \n            \n            The SDK triggers this callback when the local userenableLocalAudio resumes or stops capturing the local audio stream by calling the method.",
        "parameters": [
            {
                "enabled": "Whether the microphone is enabled/disabled:\n                                true: The microphone is enabled.\n                                false: The microphone is disabled.\n                            \n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onnetworkquality",
        "name": "networkQuality",
        "description": "Reports the last mile network quality of each user in the channel.\nThis callback reports the last mile network conditions of each user in the channel. Last mile refers to the connection between the local device and Agora's edge server.\n   The SDK triggers this callback once every two seconds. If a channel includes multiple users, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "uid": "User ID. The network quality of the user with this user ID is\n                            reported.\n                        "
            },
            {
                "txQuality": "Uplink network quality rating of the user in terms of the transmission bit\n                        rate, packet loss rate, average RTT (Round-Trip Time) and jitter of the\n                        uplink network. This parameter is a quality rating helping you understand\n                        how well the current uplink network conditions can support the selected\n                        video encoder configuration. For example, a 1000 Kbps uplink network may be\n                        adequate for video frames with a resolution of 640 × 480 and a frame rate of\n                        15 fps in the LIVE_BROADCASTING profile, but might be inadequate for\n                        resolutions higher than 1280 × 720.\n                                Unknown (0): The quality is unknown.\n                                Excellent (1): The quality is excellent.\n                                Good (2): The network quality seems excellent, but the bitrate can be slightly lower than excellent.\n                                Poor (3): Users can feel the communication is slightly impaired.\n                                Bad (4): Users cannot communicate smoothly.\n                                VBad (5): The quality is so bad that users can barely communicate.\n                                Down (6): The network is down, and users cannot communicate at all.\n                            \n                        "
            },
            {
                "rxQuality": "Downlink network quality rating of the user in terms of packet loss rate,\n                        average RTT, and jitter of the downlink network.\n                                Unknown (0): The quality is unknown.\n                                Excellent (1): The quality is excellent.\n                                Good (2): The network quality seems excellent, but the bitrate can be slightly lower than excellent.\n                                Poor (3): Users can feel the communication is slightly impaired.\n                                Bad (4): Users cannot communicate smoothly.\n                                VBad (5): The quality is so bad that users can barely communicate.\n                                Down (6): The network is down, and users cannot communicate at all.\n                            \n                        "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onnetworktypechanged",
        "name": "networkTypeChanged",
        "description": "Occurs when the local network type changes.\nThis callback occurs when the connection state of the local user changes. You can get the connection state and reason for the state change in this callback. When the network connection is interrupted, this callback indicates whether the interruption is caused by a network type change or poor network conditions.",
        "parameters": [
            {
                "type": "The type of the local network connection.\n                        For details, see NetworkType. "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onrejoinchannelsuccess",
        "name": "rejoinChannelSuccess",
        "description": "Occurs when a user rejoins the channel.\nWhen a user loses connection with the server because of network problems, the SDK automatically tries to reconnect and triggers this callback upon reconnection.",
        "parameters": [
            {
                "channel": "The name of the channel."
            },
            {
                "uid": "The ID of the user who rejoins the channel."
            },
            {
                "elapsed": "Time elapsed (ms) from starting to reconnect until the SDK triggers this\n                        callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onremoteaudiomixingbegin",
        "name": "remoteAudioMixingBegin",
        "description": "Occurs when a remote user starts audio mixing.\nWhen a remote user calls startAudioMixing to play the background music, the SDK reports this callback.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "callback_onremoteaudiomixingend",
        "name": "remoteAudioMixingEnd",
        "description": "Occurs when a remote user finishes audio mixing.\nThe SDK triggers this callback when a remote user finishes audio mixing.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "callback_onremoteaudiostatechanged",
        "name": "remoteAudioStateChanged",
        "description": "Occurs when the remote audio state changes.\nWhen the audio state of a remote user (in the voice/video call channel) or host (in the live streaming channel) changes, the SDK triggers this callback to report the current state of the remote audio stream.\n               This callback does not work properly when the number of users (in the voice/video call channel) or hosts (in the live streaming channel) in the channel exceeds 17.",
        "parameters": [
            {
                "uid": "The ID of the remote user whose audio state changes."
            },
            {
                "state": "The state of the remote audio, see AudioRemoteState."
            },
            {
                "reason": "The reason of the remote audio state change, see AudioRemoteStateReason."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling the joinChannel method until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onremoteaudiostats",
        "name": "remoteAudioStats",
        "description": "Reports the transport-layer statistics of each remote audio stream.\nThe SDK triggers this callback once every two seconds for each remote user who is sending audio streams. If a channel includes multiple remote users, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "stats": "The statistics of the received remote audio streams. See RemoteAudioStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onremoteaudiotransportstats",
        "name": "remoteAudioTransportStats",
        "description": "Reports the transport-layer statistics of each remote audio stream.\nDeprecated:\n      Please use remoteAudioStats instead.\n  \n       \n   \n            This callback reports the transport-layer statistics, such as the packet loss rate and network time delay, once every two seconds after the local user receives an audio packet from a remote user. During a call, when the user receives the audio packet sent by the remote user/host, the callback is triggered every 2 seconds.",
        "parameters": [
            {
                "uid": "The ID of the remote user sending the audio streams."
            },
            {
                "delay": "The network delay (ms) from the sender to the receiver."
            },
            {
                "lost": "Packet loss rate (%) of the audio packet sent from the sender to the\n                        receiver."
            },
            {
                "rxKBitrate": "Bitrate of the received audio (Kbps)."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onremotesubscribefallbacktoaudioonly",
        "name": "remoteSubscribeFallbackToAudioOnly",
        "description": "Occurs when the remote media stream falls back to audio-only stream due to poor network conditions or switches back to the video stream after the network conditions improve.\nIf you call setRemoteSubscribeFallbackOption and set option as AudioOnly, the SDK triggers this callback when the remote media stream falls back to audio-only mode due to poor downlink conditions, or when the remote media stream switches back to the video after the downlink network condition improves.\n   Once the remote media stream switches to the low stream due to poor network conditions, you can monitor the stream switch between a high and low stream in the RemoteVideoStats callback.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "isFallbackOrRecover": "\n true: The remotely subscribed media stream falls back to audio-only due to poor network conditions.\n false: The remotely subscribed media stream switches back to the video stream after the network conditions improved.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onremotevideostatechanged",
        "name": "remoteVideoStateChanged",
        "description": "Occurs when the remote video state changes.\nThis callback does not work properly when the number of users (in the voice/video call channel) or hosts (in the live streaming channel) in the channel exceeds 17.",
        "parameters": [
            {
                "uid": "The ID of the remote user whose video state changes."
            },
            {
                "state": " The state of the remote video, see\n                              VideoRemoteState. "
            },
            {
                "reason": " The reason for the remote video state\n                              change, see VideoRemoteStateReason. "
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling the joinChannel method until the SDK triggers this\n                              callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onremotevideostats",
        "name": "remoteVideoStats",
        "description": "Reports the transport-layer statistics of each remote video stream.\nReports the statistics of the video stream from the remote users. The SDK triggers this callback once every two seconds for each remote user. If a channel has multiple users/hosts sending video streams, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "stats": "Statistics of the remote video stream. For details, see RemoteVideoStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onremotevideotransportstats",
        "name": "remoteVideoTransportStats",
        "description": "Reports the transport-layer statistics of each remote video stream.\nDeprecated:\n  Please use remoteVideoStats instead.\n       \n   \n   This callback reports the transport-layer statistics, such as the packet loss rate and network time delay, once every two seconds after the local user receives a video packet from a remote user.\n   During a call, when the user receives the video packet sent by the remote user/host, the callback is triggered every 2 seconds.",
        "parameters": [
            {
                "uid": "The ID of the remote user sending the video packets."
            },
            {
                "delay": "The network delay (ms) from the sender to the receiver."
            },
            {
                "lost": "The packet loss rate (%) of the video packet sent from the remote user."
            },
            {
                "rxKBitRate": "The bitrate of the received video (Kbps)."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onrequestaudiofileinfo",
        "name": "requestAudioFileInfoCallback",
        "description": "Reports the information of an audio file.\nAfter successfully calling getAudioFileInfo, the SDK triggers this callback to report the information of the audio file, such as the file path and duration.",
        "parameters": [
            {
                "info": "The information of an audio file. See AudioFileInfo."
            },
            {
                "error": "The information acquisition state. See AudioFileInfoError."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onrequesttoken",
        "name": "requestToken",
        "description": "Occurs when the token expires.\nWhen the token expires during a call, the SDK triggers this callback to\n                remind the app to renew the token.\n            Once you receive this callback, generate a new token on your app server, and call\n                joinChannel to rejoin the channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "callback_onrtcstats",
        "name": "rtcStats",
        "description": "Reports the statistics of the current call.\nThe SDK triggers this callback once every two seconds after the user joins the channel.",
        "parameters": [
            {
                "stats": "Statistics of the RTC engine, see RtcStats for\n                            details.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onrtmpstreamingevent",
        "name": "rtmpStreamingEvent",
        "description": "Reports events during the RTMP or RTMPS streaming.\n",
        "parameters": [
            {
                "url": "The RTMP or RTMPS streaming URL."
            },
            {
                "eventCode": "The event code of the streaming. For details, see RtmpStreamingEvent."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onrtmpstreamingstatechanged",
        "name": "rtmpStreamingStateChanged",
        "description": "Occurs when the state of the RTMP or RTMPS streaming changes.\nThe SDK triggers this callback to report the result of the local user calling the addPublishStreamUrl or removePublishStreamUrl method. When the RTMP/RTMPS streaming status changes, the SDK triggers this callback and report the URL address and the current status of the streaming. This callback indicates the state of the RTMP or RTMPS streaming. When exceptions occur, you can troubleshoot issues by referring to the detailed error descriptions in the error code parameter.",
        "parameters": [
            {
                "url": "The CDN streaming URL."
            },
            {
                "state": "The RTMP or RTMPS streaming state, see RtmpStreamingState. When the streaming status is Failure(4), you can view the error information in the errorCode parameter."
            },
            {
                "errCode": "The detailed error information for streaming, see RtmpStreamingErrorCode."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onsnapshottaken",
        "name": "snapshotTaken",
        "description": "Reports the result of taking a video snapshot.\ntakeSnapshot method call, the SDK triggers this callback to report whether the snapshot is successfully taken as well as the details for the snapshot taken.",
        "parameters": [
            {
                "channel": "The channel name."
            },
            {
                "uid": "The user ID. A uid of 0 indicates the local user."
            },
            {
                "filePath": "The local path of the snapshot."
            },
            {
                "width": "The width (px) of the snapshot."
            },
            {
                "height": "The height (px) of the snapshot."
            },
            {
                "errCode": "The message that confirms success or the reason why the snapshot is not successfully taken:\n                            0: Success.\n                            < 0: Failure:\n                                    -1: The SDK fails to write data to a file or encode a JPEG image.\n                                    -2: The SDK does not find the video stream of the specified user within one second after the takeSnapshot method call succeeds.\n                                \n                        "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onstreaminjectedstatus",
        "name": "streamInjectedStatus",
        "description": "Occurs when a media stream URL address is added to the interactive live streaming.\nAgora will soon stop the service for injecting online media streams on the client. If you have not implemented this service, Agora recommends that you do not use it. For details, see Service Sunset Plans.",
        "parameters": [
            {
                "url": "The URL address of the externally injected stream."
            },
            {
                "uid": "User ID."
            },
            {
                "status": "State of the externally injected stream: InjectStreamStatus."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onstreammessage",
        "name": "streamMessage",
        "description": "Occurs when the local user receives the data stream from the remote user.\nThe SDK triggers this callback when the local user receives the stream message that the remote user sends by calling the sendStreamMessage method.",
        "parameters": [
            {
                "uid": "The ID of the remote user sending the message."
            },
            {
                "streamId": "The stream ID of the received message."
            },
            {
                "data": "The data received."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onstreammessageerror",
        "name": "streamMessageError",
        "description": "Occurs when the local user does not receive the data stream from the remote user.\nThe SDK triggers this callback when the local user fails to receive the stream message that the remote user sends by calling the sendStreamMessage method.",
        "parameters": [
            {
                "uid": "The ID of the remote user sending the message."
            },
            {
                "streamId": "The stream ID of the received message."
            },
            {
                "error": "The error code."
            },
            {
                "missed": "The number of lost messages."
            },
            {
                "cached": "Number of incoming cached messages when the data stream is interrupted."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onstreampublished",
        "name": "streamPublished",
        "description": "Occurs when an RTMP or RTMPS stream is published.\nDeprecated:\n  Please use rtmpStreamingStateChanged instead.\n       \n   \n   Reports the result of publishing an RTMP or RTMPS stream.",
        "parameters": [
            {
                "url": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onstreamunpublished",
        "name": "streamUnpublished",
        "description": "Occurs when an RTMP or RTMPS stream is removed.\nDeprecated:\n  Please use rtmpStreamingStateChanged instead.",
        "parameters": [
            {
                "url": "The URL of the removed RTMP or RTMPS stream."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ontokenprivilegewillexpire",
        "name": "tokenPrivilegeWillExpire",
        "description": "Occurs when the token expires in 30 seconds.\nWhen the token is about to expire in 30 seconds, the SDK triggers this callback to remind the app to renew the token.\n   Upon receiving this callback, generate a new token on your server, and call renewToken to pass the new token to the SDK.",
        "parameters": [
            {
                "token": "The token that expires in 30 seconds."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_ontranscodingupdated",
        "name": "transcodingUpdated",
        "description": "Occurs when the publisher's transcoding is updated.\nWhen the LiveTranscoding class in the setLiveTranscoding method updates, the SDK triggers the transcodingUpdated callback to report the update information.\n            If you call the setLiveTranscoding\n                method to set the LiveTranscoding class for the first time, the\n                SDK does not trigger this callback.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "callback_onuploadlogresult",
        "name": "uploadLogResult",
        "description": "Reports the result of uploading the SDK log files.\nSince\n  v3.3.0\n       \n   \n   After uploadLogFile is called, the SDK triggers the callback to report the result of uploading the SDK log files. If the upload fails, refer to the reason parameter to troubleshoot.",
        "parameters": [
            {
                "requestId": "The request ID. The request ID is the same as the requestId returned in uploadLogFile. You can use the requestId to match a specific upload with a callback."
            },
            {
                "success": "Whether the log file is uploaded successfully:\n      true: Successfully upload the log files.\n      false: Fails to upload the log files. For details, see the reason parameter.\n  "
            },
            {
                "reason": "The reason for the upload failure. For details, see UploadErrorReason."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onuserenablelocalvideo",
        "name": "userEnableLocalVideo",
        "description": "Occurs when a specific remote user enables/disables the local video capturing function.\nThe SDK triggers this callback when the remote user resumes or stops capturing the video stream by calling the enableLocalVideo method.",
        "parameters": [
            {
                "uid": "The user ID of the remote user."
            },
            {
                "enabled": "Whether the specified remote user enables/disables the local video\n                            capturing function:\n                            true: Enable. Other users in the\n                                channel can see the video of this remote user.\n                            false: Disable. Other users in the\n                                channel can no longer receive the video stream from this remote\n                                user, while this remote user can still receive the video streams\n                                from other users.\n                            \n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onuserenablevideo",
        "name": "userEnableVideo",
        "description": "Occurs when a remote user enables/disables the video module.\nOnce the video module is disabled, the user can only use a voice call. The user cannot send or receive any video.\n   The SDK triggers this callback when a remote user enables or disables the video module by calling the enableVideo or disableVideo method.",
        "parameters": [
            {
                "uid": "The user ID of the remote user."
            },
            {
                "enabled": "\n                            true: Enable.\n                            false: Disable.\n                        \n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onuserinfoupdated",
        "name": "userInfoUpdated",
        "description": "Occurs when the SDK gets the user ID and user account of the remote user.\nAfter a remote user joins the channel, the SDK gets the UID and user account of the remote user, caches them in a mapping table object, and triggers this callback on the local client.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "userInfo": "The UserInfo object that contains the user ID and user account of the remote user. See UserInfo for details."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onuserjoined",
        "name": "userJoined",
        "description": "Occurs when a remote user (COMMUNICATION)/ host (LIVE_BROADCASTING) joins the channel.\nIn a communication channel, this callback indicates that a remote user joins the channel. The SDK also triggers this callback to report the existing users in the channel when a user joins the channel.\n   In a live-broadcast channel, this callback indicates that a host joins the channel. The SDK also triggers this callback to report the existing hosts in the channel when a host joins the channel. Agora recommends limiting the number of hosts to 17.\n        \n  The SDK triggers this callback under one of the following circumstances:\n   A remote user/host joins the channel by calling the joinChannel method.\n   A remote user switches the user role to the host after joining the channel.\n   A remote user/host rejoins the channel after a network interruption.",
        "parameters": [
            {
                "uid": "The ID of the user or host who joins the channel."
            },
            {
                "elapsed": "Time delay (ms) from the local user calling joinChannel\n                        until this callback is triggered."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onusermuteaudio",
        "name": "userMuteAudio",
        "description": "Occurs when a remote user (in the communication profile)/ host (in the live streaming profile) joins the channel.\nThe SDK triggers this callback when the remote user stops or resumes sending the audio stream by calling the muteLocalAudioStream method.\n   This callback does not work properly when the number of users (in the communication profile) or hosts (in the live streaming profile) in the channel exceeds 17.",
        "parameters": [
            {
                "uid": "User ID."
            },
            {
                "muted": "Whether the remote user's audio stream is muted/unmuted:\n      true: Muted.\n      false: Unmuted.\n  \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onusermutevideo",
        "name": "userMuteVideo",
        "description": "Occurs when a remote user's video stream playback pauses/resumes.\nThe SDK triggers this callback when the remote user stops or resumes sending the video stream by calling the muteLocalVideoStream method.\n   This callback does not work properly when the number of users (in the COMMUNICATION profile) or hosts (in the LIVE_BROADCASTING profile) in the channel exceeds 17.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "muted": "Whether the remote user's video stream playback is paused/resumed:\n                        true: Paused.\n                        false: Resumed.\n                         "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onuseroffline",
        "name": "userOffline",
        "description": "Occurs when a remote user (COMMUNICATION)/ host (LIVE_BROADCASTING) leaves the channel.\nThere are two reasons for users to become offline:\n                    Leave the channel: When a user/host leaves the channel, the user/host sends a goodbye message. When this message is received, the SDK determines that the user/host leaves the channel.\n                    Drop offline: When no data packet of the user or host is received for a certain period of time (20 seconds for the communication profile, and more for the live broadcast profile), the SDK assumes that the user/host drops offline. A poor network connection may lead to false detections. It's recommended to use the Agora RTM SDK for reliable offline detection.",
        "parameters": [
            {
                "uid": "The ID of the user who leaves the channel or goes offline."
            },
            {
                "reason": "Reasons why the user goes offline: UserOfflineReason. "
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onusersuperresolutionenabled",
        "name": "userSuperResolutionEnabled",
        "description": "Reports whether the super resolution feature is successfully enabled.\nAfter calling enableRemoteSuperResolution, the SDK triggers the callback to report whether super resolution is successfully enabled. If it is not successfully enabled, use reason for troubleshooting.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "enabled": "Whether super resolution is successfully enabled:\n                        true: Super resolution is successfully enabled.\n                        false: Super resolution is not successfully enabled.\n                    "
            },
            {
                "reason": "The reason why super resolution algorithm is not successfully enabled. For details, see SuperResolutionStateReason."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onvideodevicestatechanged",
        "name": "videoDeviceStateChanged",
        "description": "Occurs when the video device state changes.\nThis callback reports the change of system video devices, such as being unplugged or removed. On a Windows device with an external camera for video capturing, the video disables once the external camera is unplugged.",
        "parameters": [
            {
                "deviceId": "The device ID."
            },
            {
                "deviceType": "Media device types. For details, see MediaDeviceType."
            },
            {
                "deviceState": "Media device states. For details, see MediaDeviceStateType."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onvideopublishstatechanged",
        "name": "videoPublishStateChanged",
        "description": "Occurs when the video publishing state changes.\n",
        "parameters": [
            {
                "channel": "The name of the channel."
            },
            {
                "oldState": "For the previous publishing state, see StreamPublishState."
            },
            {
                "newState": "For the current publishing state, see StreamPublishState."
            },
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onvideosizechanged",
        "name": "videoSizeChanged",
        "description": "Occurs when the video size or rotation of a specified user changes.\n",
        "parameters": [
            {
                "uid": "The ID of the user whose video size or rotation changes.\n                        uid is 0 for the local user."
            },
            {
                "width": "The width (pixels) of the video stream."
            },
            {
                "height": "The height (pixels) of the video stream."
            },
            {
                "rotation": "The rotation information. The value range is [0,360)."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onvideostopped",
        "name": "videoStopped",
        "description": "Occurs when the video stops playing.\nDeprecated:\n                    Please use Stopped(0) in the \n         callback instead.\n                \n            \n            The application can use this callback to change the configuration of the\n                view (for example, displaying other pictures in the view) after\n                the video stops playing.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "callback_onvideosubscribestatechanged",
        "name": "videoSubscribeStateChanged",
        "description": "Occurs when the video subscribing state changes.\n",
        "parameters": [
            {
                "channel": "The name of the channel."
            },
            {
                "oldState": "The previous subscribing status, see StreamSubscribeState\n                        for details."
            },
            {
                "newState": "The current subscribing status, see StreamSubscribeState for details."
            },
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onvirtualbackgroundsourceenabled",
        "name": "virtualBackgroundSourceEnabled",
        "description": "Reports whether virtual background is successfully enabled. (Beta feature)\nAfter you call enableVirtualBackground, the SDK triggers this callback to report whether virtual background is successfully enabled.\n            If the background image customized in the virtual background is in the PNG or JPG format, this callback is triggered after the image is read.",
        "parameters": [
            {
                "enabled": "Whether virtual background is successfully enabled:\n                        true: Virtual background is successfully enabled.\n                        false: Virtual background is not successfully enabled.\n                    "
            },
            {
                "reason": "The reason why virtual background is not successfully enabled. See VirtualBackgroundSourceStateReason."
            }
        ],
        "returns": ""
    },
    {
        "id": "callback_onwarning",
        "name": "warning",
        "description": "Reports a warning during SDK runtime.\nOccurs when a warning occurs during SDK runtime. In most cases, the app can ignore the warnings reported by the SDK because the SDK can usually fix the issue and resume running. For example, when losing connection with the server, the SDK may report WARN_LOOKUP_CHANNEL_TIMEOUT and automatically try to reconnect.",
        "parameters": [
            {
                "warn": "Warning codes."
            },
            {
                "msg": "Warning description."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_agorafacepositioninfo",
        "name": "FacePositionInfo",
        "description": "The information of the detected human face.\n",
        "parameters": [
            {
                "x": "The x coordinate (px) of the human face in the local video. Taking the top left corner of the captured video as the origin, the x coordinate represents the relative lateral displacement of the top left corner of the human face to the origin.\n                    "
            },
            {
                "y": "The y coordinate (px) of the human face in the local video. Taking the top left corner of the captured video as the origin, the y coordinate represents the relative longitudinal displacement of the top left corner of the human face to the origin.\n                    "
            },
            {
                "width": "The width (px) of the human face in the captured video.\n                    "
            },
            {
                "height": "The height (px) of the human face in the captured video.\n                    "
            },
            {
                "distance": "The distance between the human face and the device screen (cm).\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_agorarhythmplayerconfig",
        "name": "RhythmPlayerConfig",
        "description": "The metronome configuration.\n",
        "parameters": [
            {
                "beatsPerMeasure": "The number of beats per measure, which ranges from 1 to 9. The default value is 4, which means that each measure contains one downbeat and three upbeats."
            },
            {
                "beatsPerMinute": "The beat speed (beats/minute), which ranges from 60 to 360. The default value is 60, which means that the metronome plays 60 beats in one minute."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_audiofileinfo",
        "name": "AudioFileInfo",
        "description": "The information of an audio file. This struct is reported in requestAudioFileInfoCallback.\n",
        "parameters": [
            {
                "filePath": "The file path."
            },
            {
                "durationMs": "The file duration (ms)."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_audiorecordingconfiguration",
        "name": "AudioRecordingConfiguration",
        "description": "The configuration of audio recording on the app client.\n",
        "parameters": [
            {
                "filePath": "The absolute path (including the filename extensions) of the recording file. For example: C:\\music\\audio.aac.\n                        Ensure that the directory for the log files exists and is writable.\n                    "
            },
            {
                "recordingQuality": "Recording quality. For details, see AudioRecordingQuality.\n                    Note: This parameter applies to AAC files only."
            },
            {
                "recordingPosition": "The recording content. For details, see AudioRecordingPosition."
            },
            {
                "recordingSampleRate": "Recording sample rate (Hz).\n                        16000\n                        (Default) 32000\n                        44100\n                        48000\n                    \n                        If you set this parameter as 44100 or 48000, Agora recommends recording WAV files or AAV files whose recordingQuality is Medium or High for better recording quality."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_audiovolumeinfo",
        "name": "AudioVolumeInfo",
        "description": "The volume information of users.\n",
        "parameters": [
            {
                "uid": "The user ID.\n                                In the local user's callback, uid = 0.\n                                In the remote users' callback, uid is the user ID of a remote user whose instantaneous volume is one of the three highest.\n                            \n                    "
            },
            {
                "volume": "The volume of the user. The value ranges between 0 (lowest volume) and 255 (highest volume). If the user calls startAudioMixing, the value of volume is the volume after audio mixing."
            },
            {
                "vad": "The voice activity status of the local user.\n                            0: The local user is not speaking.\n                            1: The local user is speaking.\n                             \n                        \n                            \n                                The vad parameter does not report the voice activity status of remote users. In the remote users' callback, the value of vad is always 0.\n                                \n                        \n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_beautyoptions",
        "name": "BeautyOptions",
        "description": "Image enhancement options.\n",
        "parameters": [
            {
                "lighteningContrastLevel": "The contrast level. For details, see LighteningContrastLevel."
            },
            {
                "lighteningLevel": "The brightness level. The value ranges from 0.0 (original) to 1.0. The default value is "
            },
            {
                "smoothnessLevel": "The smoothness level. The value ranges from 0.0 (original) to 1.0. The default value is "
            },
            {
                "rednessLevel": "The redness level. The value ranges from 0.0 (original) to 1.0. The default value is "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_cameracapturerconfiguration",
        "name": "CameraCapturerConfiguration",
        "description": "The camera capturer preference.\n",
        "parameters": [
            {
                "preference": "The camera capture preference. For details, see CameraCaptureOutputPreference."
            },
            {
                "captureWidth": "The width (px) of the video image captured by the local camera. To customize the width of the video image, set preference as Manual(3) first, and then use captureWidth to set the video width.\n                    "
            },
            {
                "captureHeight": "The height (px) of the video image captured by the local camera. To customize the height of the video image, set preference as Manual(3) first, and then use captureHeight.\n                    "
            },
            {
                "cameraDirection": "The camera direction. For details, see CameraDirection.\n      "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_channelmediainfo",
        "name": "ChannelMediaInfo",
        "description": "The definition of ChannelMediaInfo.\n",
        "parameters": [
            {
                "channelName": "The name of the channel."
            },
            {
                "token": "The token that enables the user to join the channel."
            },
            {
                "uid": "User ID."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_channelmediaoptions",
        "name": "ChannelMediaOptions",
        "description": "The channel media options.\n",
        "parameters": [
            {
                "autoSubscribeAudio": "Whether to automatically subscribe to all remote audio streams when the user joins a channel:\n      true: (Default) Subscribe.\n      false: Do not subscribe.\n  This member serves a similar function to the muteAllRemoteAudioStreams method. After joining the channel, you can call the muteAllRemoteAudioStreams method to set whether to subscribe to audio streams in the channel."
            },
            {
                "audioSubscribeVideo": "Whether to subscribe to video streams when the user joins the channel:\n      true: (Default) Subscribe.\n      false: Do not subscribe.\n  This member serves a similar function to the muteAllRemoteVideoStreams method. After joining the channel, you can call the muteAllRemoteVideoStreams method to set whether to subscribe to video streams in the channel."
            },
            {
                "publishLocalAudio": "true: (Default) Publish the local audio.\n               false: Do not publish the local audio.\n           \n           This member serves a similar function to the muteLocalAudioStream method. After the user joins the channel, you can call the muteLocalAudioStream method to set whether to publish the local audio stream in the channel."
            },
            {
                "publishLocalVideo": "true: (Default) Publish the local video.\n               false: Do not publish the local video.\n           \n           This member serves a similar function to the muteLocalVideoStream method. After the user joins the channel, you can call the muteLocalVideoStream method to set whether to publish the local audio stream in the channel."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_channelmediarelayconfiguration",
        "name": "ChannelMediaRelayConfiguration",
        "description": "The definition of ChannelMediaRelayConfiguration.\n",
        "parameters": [
            {
                "srcInfo": "The information of the source channel ChannelMediaInfo. It contains the following members:\n                                channelName: The name of the source channel. The default value is , which means the SDK applies the name of the current channel.null\n                                uid: The unique ID to identify the relay stream in the source channel. The default value is 0, which means the SDK generates a random UID. You must set it as 0.\n                                token: The token for joining the source channel. It is generated with the channelName and uid you set in srcInfo.\n                                        If you have not enabled the App Certificate, set this parameter as the default value null , which means the SDK applies the App ID.\n                                        If you have enabled the App Certificate, you must use the token generated with the channelName and uid, and the uid must be set as 0.\n                                    \n                            \n                        \n                    "
            },
            {
                "destInfos": "The information of the destination channel ChannelMediaInfo. It contains the following members:\n                                channelName: The name of the destination channel.\n                                uid: The unique ID to identify the relay stream in the destination channel. The value ranges from 0 to (232-1). To avoid UID conflicts, this `UID` must be different from any other `UID` in the destination channel. The default value is 0, which means the SDK generates a random `UID`. Do not set this parameter as the `UID` of the host in the destination channel, and ensure that this `UID` is different from any other `UID` in the channel.\n                                token: The token for joining the destination channel. It is generated with the channelName and uid you set in destInfos.\n                                        If you have not enabled the App Certificate, set this parameter as the default value null , which means the SDK applies the App ID.\n                                        If you have enabled the App Certificate, you must use the token generated with the channelName and uid.\n                                    \n                            \n                        \n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_clientroleoptions",
        "name": "ClientRoleOptions",
        "description": "The detailed options of a user.\n",
        "parameters": [
            {
                "audienceLatencyLevel": "The latency level of an audience member in interactive live streaming. "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_datastreamconfig",
        "name": "DataStreamConfig",
        "description": "The configurations for the data stream.\nThe following table shows the SDK behaviors under different parameter settings:",
        "parameters": [
            {
                "syncWithAudio": "Whether to synchronize the data packet with the published audio packet.\n                                true: Synchronize the data packet with the audio packet.\n                                false: Do not synchronize the data packet with the audio packet.\n                            When you set the data packet to synchronize with the audio, then if the data packet delay is within the audio delay, the SDK triggers the streamMessage callback when the synchronized audio packet is played out. Do not set this parameter as true if you need the receiver to receive the data packet immediately. Agora recommends that you set this parameter to `true` only when you need to implement specific functions, for example lyric synchronization.\n                    "
            },
            {
                "ordered": "Whether the SDK guarantees that the receiver receives the data in the sent order.\n                                true: Guarantee that the receiver receives the data in the sent order.\n                                false: Do not guarantee that the receiver receives the data in the sent order.\n                            Do not set this parameter as true if you need the receiver to receive the data packet immediately.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_encryptionconfig",
        "name": "EncryptionConfig",
        "description": "Built-in encryption configurations.\n",
        "parameters": [
            {
                "encryptionMode": "The built-in encryption mode. See EncryptionMode. Agora recommends using AES128GCM2 or AES256GCM2 encrypted mode. These two modes support the use of salt for higher security.\n  "
            },
            {
                "encryptionKey": "Encryption key in string type.\n       If you do not set an encryption key or set it as null, you cannot use the built-in encryption, and the SDK returns -2.\n  "
            },
            {
                "encryptionKdfSalt": "Salt, 32 bytes in length. Agora recommends that you use OpenSSL to generate salt on the server side. See Media Stream Encryption for details.\n                        This parameter takes effect only in AES128GCM2 or AES256GCM2 encrypted mode. In this case, ensure that this parameter is not 0.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_ichannel",
        "name": "RtcChannel",
        "description": "Provides methods that enable real-time communications in an RtcChannel channel.\nCall create to create an RtcChannel object.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_ichanneleventhandler",
        "name": "RtcChannelEventHandler",
        "description": "The SDK uses RtcChannelEventHandler to send RtcChannel event notifications to your app.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_injectstreamconfig",
        "name": "LiveInjectStreamConfig",
        "description": "Configurations of injecting an external audio or video stream.\nAgora will soon stop the service for injecting online media streams on the client. If you have not implemented this service, Agora recommends that you do not use it. For details, see Service Sunset Plans.",
        "parameters": [
            {
                "width": "The width of the external video stream after injecting. The default value is 0, which represents the same width as the original."
            },
            {
                "height": "The height of the external video stream after injecting. The default value is 0, which represents the same height as the original."
            },
            {
                "videoGop": "The GOP (in frames) of injecting the external video stream. The default value is 30 frames."
            },
            {
                "videoFramerate": "The frame rate (fps) of injecting the external video stream. The default rate is 15 fps."
            },
            {
                "videoBitrate": "The bitrate (Kbps) of injecting the external video stream. The default value is 400 Kbps.\n                        The bitrate setting is closely linked to the video resolution. If the bitrate you set is beyond a reasonable range, the SDK sets it within a reasonable range.\n                    "
            },
            {
                "audioSampleRate": "The sampling rate (Hz) of injecting the external audio stream. The default value is 48000 Hz. See AudioSampleRateType.\n                        Agora recommends using the default value.\n                    "
            },
            {
                "audioBitrate": "The bitrate (Kbps) of injecting the external audio stream. The default value is 48 Kbps.\n                        Agora recommends using the default value.\n                    "
            },
            {
                "audioChannels": "The number of channels of the external audio stream after injecting.\n                                1:  (Default) Mono.\n                                2: Stereo.\n                            \n                        \n                        Agora recommends using the default value.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_irtcengine",
        "name": "RtcEngine",
        "description": "The basic interface of the Agora SDK that implements the core functions of real-time communication.\nRtcEngine provides the main methods that your app can call.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_irtcengineeventhandler",
        "name": "RtcEngineEventHandler",
        "description": " The SDK uses the RtcEngineEventHandler interface to send event notifications to your app. Your app can get those notifications through methods that inherit this interface.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_lastmileprobeconfig",
        "name": "LastmileProbeConfig",
        "description": "Configurations of the last-mile network test.\n",
        "parameters": [
            {
                "probeUplink": "Sets whether to test the uplink network. Some users, for example, the audience members in a LIVE_BROADCASTING channel, do not need such a test.\n true: Test.\n false: Not test.\n      \n      \n  "
            },
            {
                "probeDownlink": "Sets whether to test the downlink network:\n     true: Test.\n     false: Not test.\n \n      \n  "
            },
            {
                "expectedUplinkBitrate": "The expected maximum uplink bitrate (bps) of the local user. The value range is [100000, 5000000]. Agora recommends referring to setVideoEncoderConfiguration to set the value."
            },
            {
                "expectedDownlinkBitrate": "The expected maximum downlink bitrate (bps) of the local user. The value range is [100000,5000000]."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_lastmileprobeonewayresult",
        "name": "LastmileProbeOneWayResult",
        "description": "Results of the uplink or downlink last-mile network test.\n",
        "parameters": [
            {
                "packetLossRate": "The packet loss rate (%)."
            },
            {
                "jitter": "The network jitter (ms)."
            },
            {
                "availableBandwidth": "The estimated available bandwidth (bps)."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_lastmileproberesult",
        "name": "LastmileProbeResult",
        "description": "Results of the uplink and downlink last-mile network tests.\n",
        "parameters": [
            {
                "state": ""
            },
            {
                "uplinkReport": "Results of the uplink last-mile network test. For details, see LastmileProbeOneWayResult."
            },
            {
                "downlinkReport": "Results of the downlink last-mile network test. For details, see LastmileProbeOneWayResult."
            },
            {
                "rtt": "The round-trip time (ms)."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_livetranscoding",
        "name": "LiveTranscoding",
        "description": "Transcoding configurations for CDN live streaming.\n",
        "parameters": [
            {
                "videoBitrate": "The video bitrate (Kbps) of the output media stream. The default value is 400. "
            },
            {
                "videoFrameRate": "The video frame rate (fps) of the output media stream. The default value is 15, and the value range is [1, 30].The Agora server adjusts\n                            any frame rate higher than 30 fps to 30 fps."
            },
            {
                "lowLatency": "\n                            \n                                Deprecated\n                                This attribute is deprecated since v2.8.0, and Agora does not recommend it.\n                            \n                        \n                        \n                            true: Low latency with unassured quality.\n                            false: (Default) High latency with assured quality.\n                        \n                    "
            },
            {
                "videoGop": "The video GOP (Group of Pictures) of the output media stream. The default value is 30."
            },
            {
                "videoCodecProfile": "The video encoding configuration of the output media stream. See VideoCodecProfileType.\n                        If you set this parameter to any other value, Agora adjusts it to the default value.\n                    "
            },
            {
                "transcodingUsers": "Transcoding configurations of each host. One live streaming channel supports up to 17 hosts. For details, see TranscodingUser.\n                    "
            },
            {
                "transcodingExtraInfo": "The user SEI information embedded in the output media stream. This parameter is used to send SEI information to the CDN. The maximum length is 4096 bytes. See How to solve SEI-related issues."
            },
            {
                "backgroundColor": "The video background color of the output media stream. The format is a hexadecimal integer defined by RGB without the # symbol. For example, 0xFFB6C1\n                        means light pink. The default value is 0x000000 (black)."
            },
            {
                "watermark": "The video watermark of the output media stream. Ensure that the format of the watermark image is PNG. For details, see AgoraImage."
            },
            {
                "backgroundImage": " The video background image of the output media stream. For details, see AgoraImage."
            },
            {
                "audioSampleRate": "The audio sampling rate (Hz) of the output media stream. See AudioSampleRateType."
            },
            {
                "audioBitrate": "The audio bitrate (Kbps) of the output media stream. The default value is 48, and the maximum is 128."
            },
            {
                "audioChannels": "The number of audio channels of the output media stream. The default value is 1. Agora recommends setting it to 1 or 2.\n                            1: (Default) Mono\n                            2: Stereo.\n                            3: Three audio channels.\n                            4: Four audio channels.\n                            5: Five audio channels.\n                        \n                    "
            },
            {
                "audioCodecProfile": "The audio codec of the output media stream. For details, see AudioCodecProfileType."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_localaudiostats",
        "name": "LocalAudioStats",
        "description": "Local audio statistics.\n",
        "parameters": [
            {
                "numChannels": "The number of audio channels."
            },
            {
                "sentSampleRate": "The sampling rate (Hz) of sending the local user's audio stream."
            },
            {
                "sentBitrate": "The average bitrate (Kbps) of sending the local user's audio stream."
            },
            {
                "txPacketLossRate": "The packet loss rate (%) from the local client to the Agora server before applying the anti-packet loss strategies."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_localvideostats",
        "name": "LocalVideoStats",
        "description": "The statistics of the local video stream.\n",
        "parameters": [
            {
                "sentBitrate": "The actual bitrate (Kbps) for sending the local video stream.This value does not include the bitrate for resending the video after packet loss.\n  "
            },
            {
                "sentFrameRate": "The actual frame rate (Kbps) while sending the local video stream.This value does not include the frame rate for resending the video after packet loss."
            },
            {
                "encoderOutputFrameRate": "The output frame rate (fps) of the local video encoder."
            },
            {
                "rendererOutputFrameRate": "The output frame rate (fps) of the local video renderer."
            },
            {
                "targetBitrate": "The target bitrate (Kbps) of the current encoder. This is an estimate made by the SDK based on the current network conditions."
            },
            {
                "targetFrameRate": "The target frame rate (fps) of the current encoder."
            },
            {
                "qualityAdaptIndication": ""
            },
            {
                "encodedBitrate": "The bitrate (Kbps) for encoding the local video stream.This value does not include the bitrate for resending the video after packet loss.\n  "
            },
            {
                "encodedFrameWidth": "The width of the encoded video (px)."
            },
            {
                "encodedFrameHeight": "The height of the encoded video (px)."
            },
            {
                "encodedFrameCount": "The number of the sent video frames, represented by an aggregate value."
            },
            {
                "codecType": "The codec type of the local video. "
            },
            {
                "txPacketLossRate": "The video packet loss rate (%) from the local client to the Agora server before applying the anti-packet loss strategies."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_logconfig",
        "name": "LogConfig",
        "description": "The configuration of the SDK log files.\n",
        "parameters": [
            {
                "filePath": "The absolute or relative path of the log file, which ends with \\ or /. Ensure that the path for the log file exists and is writable. You can use this parameter to rename the log files.\n                        "
            },
            {
                "fileSize": "The size (KB) of a log file. The default value is 2014 KB. If you set fileSize to 1024 KB, the maximum aggregate size of the log files output by the SDK is 5 MB. If you set fileSize to less than 1024 KB, the setting is invalid, and the maximum size of a log file is still 1024 KB."
            },
            {
                "level": "The output level of the SDK log file. See LogLevel."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_mediadeviceinfo",
        "name": "MediaDeviceInfo",
        "description": "The MediaDeviceInfo class, which contains the device ID and device name.\n",
        "parameters": [
            {
                "deviceId": "The device ID."
            },
            {
                "deviceName": "The device name."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_metadata",
        "name": "Metadata",
        "description": "Media metadata\n",
        "parameters": [
            {
                "uid": "User ID.\n For the receiver: The user ID of the user who sent the Metadata.\n     For the sender: Ignore this value.\n \n  "
            },
            {
                "buffer": "The buffer address of the sent or received Metadata."
            },
            {
                "timeStampMs": "The timestamp (ms) of the Metadata."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rect",
        "name": "Rect",
        "description": "The screen sharing region.\nDeprecated:\n  This class is deprecated. Please use the updateScreenCaptureRegion method to update the shared area.",
        "parameters": [
            {
                "top": "The coordinate of the top side of the shared area on the vertical axis."
            },
            {
                "left": "The coordinate of the left side of the shared area on the horizontal axis."
            },
            {
                "bottom": "The coordinate of the bottom side of the shared area on the vertical axis."
            },
            {
                "right": "The coordinate of the right side of the shared area on the horizontal axis."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rectangle",
        "name": "Rectangle",
        "description": "The location of the target area relative to the screen or window. If you do not set this parameter, the SDK selects the whole screen or window.\n",
        "parameters": [
            {
                "x": "The horizontal offset from the top-left corner."
            },
            {
                "y": "The vertical offset from the top-left corner."
            },
            {
                "width": "The width of the target area."
            },
            {
                "height": "The height of the target area."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_remoteaudiostats",
        "name": "RemoteAudioStats",
        "description": "Audio statistics of the remote user.\n",
        "parameters": [
            {
                "uid": "The user ID of the remote user."
            },
            {
                "quality": "The quality of the audio stream sent by the user.  See NetworkQuality."
            },
            {
                "networkTransportDelay": "The network delay (ms) from the sender to the receiver."
            },
            {
                "jitterBufferDelay": "The network delay (ms) from the receiver to the jitter buffer.This parameter does not take effect if the receiver is an audience member and audienceLatencyLevel of ClientRoleOptions is 1.\n  "
            },
            {
                "audioLossRate": "The frame loss rate (%) of the remote audio stream in the reported interval."
            },
            {
                "numChannels": "The number of audio channels."
            },
            {
                "receivedSampleRate": "The sampling rate of the received audio stream in the reported interval."
            },
            {
                "receivedBitrate": "The average bitrate (Kbps) of the received audio stream in the reported interval."
            },
            {
                "totalFrozenTime": "The total freeze time (ms) of the remote audio stream after the remote user joins the channel. In a session, audio freeze occurs when the audio frame loss rate reaches 4%."
            },
            {
                "frozenRate": "The total audio freeze time as a percentage (%) of the total time when the audio is available. The audio is considered available when the remote user neither stops sending the audio stream nor disables the audio module after joining the channel."
            },
            {
                "totalActiveTime": "The total active time (ms) between the start of the audio call and the callback of the remote user.\n                        The active time refers to the total duration of the remote user without the mute state."
            },
            {
                "publishDuration": "The total duration (ms) of the remote audio stream."
            },
            {
                "mosValue": "The quality of the remote audio stream in the reported interval. The quality is determined by the Agora real-time audio MOS (Mean Opinion Score) measurement method. The return value range is [0, 500]. Dividing the return value by 100 gets the MOS score, which ranges from 0 to 5. The higher the score, the better the audio quality.\n\n                The subjective perception of audio quality corresponding to the Agora real-time audio MOS scores is as follows:\n                                \n                                    MOS score\n                                    Perception of audio quality\n                                \n                                \n                                    Greater than 4\n                                    Excellent. The audio sounds clear and smooth.\n                                \n                                \n                                    From 3.5 to 4\n                                    Good. The audio has some perceptible impairment but still sounds clear.\n                                \n                                \n                                    From 3 to 3.5\n                                    Fair. The audio freezes occasionally and requires attentive listening.\n                                \n                                \n                                    From 2.5 to 3\n                                    Poor. The audio sounds choppy and requires considerable effort to understand.\n                                \n                                \n                                    From 2 to 2.5\n                                    Bad. The audio has occasional noise. Consecutive audio dropouts occur, resulting in some information loss. The users can communicate only with difficulty.\n                                \n                                \n                                    Less than 2\n                                    Very bad. The audio has persistent noise. Consecutive audio dropouts are frequent, resulting in severe information loss. Communication is nearly impossible.\n                                \n                            \n           "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_remotevideostats",
        "name": "RemoteVideoStats",
        "description": "Statistics of the remote video stream.\n",
        "parameters": [
            {
                "uid": "The user ID of the remote user sending the video stream."
            },
            {
                "delay": "\n \n     Deprecated:\n     In scenarios where audio and video are synchronized, you can get the video  delay data from networkTransportDelay and jitterBufferDelay in RemoteAudioStats.\n \n      \n      The video delay (ms).\n  "
            },
            {
                "width": "The width (pixels) of the video."
            },
            {
                "height": "The height (pixels) of the video."
            },
            {
                "receivedBitrate": "The bitrate (Kbps) of receiving the remote video since the last count."
            },
            {
                "decoderOutputFrameRate": "The frame rate (fps) of decoding the remote video."
            },
            {
                "rendererOutputFrameRate": "The frame rate (fps) of rendering the remote video."
            },
            {
                "packetLossRate": "The packet loss rate (%) of the remote video after using the anti-packet-loss technology."
            },
            {
                "rxStreamType": "The type of the video stream. "
            },
            {
                "totalFrozenTime": "The total freeze time (ms) of the remote video stream after the remote user joins the channel. In a video session where the frame rate is set to 5 fps or higher, video freeze occurs when the time interval between two adjacent video frames is more than 500\n      ms."
            },
            {
                "frozenRate": "The total video freeze time as a percentage (%) of the total time when the video is available. The video is available means that the remote user neither stops sending the video stream nor disables the video module after joining the channel."
            },
            {
                "totalActiveTime": "Total active time (ms) of the video.\n                        When the remote user/host neither stops sending the video stream nor disables the video module after joining the channel, the video is available."
            },
            {
                "publishDuration": "The total duration (ms) of the remote video stream."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rtcdevicemanager",
        "name": "RtcDeviceManager",
        "description": "The RTC device manager class, which manages the audio and video devices in the system.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_rtcengineconfig",
        "name": "RtcEngineContext",
        "description": "Configurations of initializing the SDK.\n",
        "parameters": [
            {
                "appId": "The App ID issued by Agora for your app development project. Only users who use the same App ID can join the same channel and communicate with each other.\n      An App ID can only be used to create one RtcEngineinstance. If you need to change the App ID, you\n                            must call destroy destroy the current IRtcEngine, and\n                            then call createWithContext to recreate RtcEngine.\n  "
            },
            {
                "areaCode": "The region for connection. This advanced feature applies to scenarios that have regional restrictions. See AreaCode for details about supported regions.\n  After specifying the region, the SDK connects to the Agora servers within that region."
            },
            {
                "logConfig": "The configuration of the log files. See LogConfig.\n  By default, the SDK outputs five log files: agorasdk.log, agorasdk_1.log, agorasdk_2.log, agorasdk_3.log, and agorasdk_4.log.\n  Each log file has a default size of 512 KB and is encoded in UTF-8 format. The SDK writes the latest log in agorasdk.log. When agorasdk.log is full, the SDK deletes the log file with the earliest modification time among the other four, renames agorasdk.log to the name of the deleted log file, and create a new agorasdk.log to record the latest  log."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rtcengineextension",
        "name": "RtcEngineExtension",
        "description": "The RtcEngineExtension class.\n",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_rtcimage",
        "name": "AgoraImage",
        "description": "Image properties.\nThis class sets the properties of the watermark and background images in the live video.",
        "parameters": [
            {
                "url": "The HTTP/HTTPS URL address of the image in the live video. The maximum length of this parameter is 1024 bytes."
            },
            {
                "x": "The x coordinate (pixel) of the image on the video frame (taking the upper left corner of the video frame as the origin)."
            },
            {
                "y": "The y coordinate (pixel) of the image on the video frame (taking the upper left corner of the video frame as the origin)."
            },
            {
                "width": "The width (pixel) of the image on the video frame."
            },
            {
                "height": "The height (pixel) of the image on the video frame."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rtcstats",
        "name": "RtcStats",
        "description": "Statistics of a call session.\n",
        "parameters": [
            {
                "duration": "Call duration of the local user in seconds, represented by an aggregate value."
            },
            {
                "txBytes": "The number of bytes sent."
            },
            {
                "rxBytes": "The number of bytes received."
            },
            {
                "txAudioBytes": "The total number of audio bytes sent, represented by an aggregate value."
            },
            {
                "txVideoBytes": "The total number of video bytes sent, represented by an aggregate value."
            },
            {
                "rxAudioBytes": "The total number of audio bytes received, represented by an aggregate value."
            },
            {
                "rxVideoBytes": "The total number of video bytes received, represented by an aggregate value."
            },
            {
                "txKBitRate": "Video transmission bitrate (Kbps), represented by an instantaneous value."
            },
            {
                "rxKBitRate": "The receiving bitrate (Kbps), represented by an instantaneous value."
            },
            {
                "rxAudioKBitRate": "Audio receive bitrate (Kbps), represented by an instantaneous value."
            },
            {
                "txAudioKBitRate": "The bitrate (Kbps) of sending the audio packet."
            },
            {
                "rxVideoKBitRate": "Video receive bitrate (Kbps), represented by an instantaneous value."
            },
            {
                "txVideoKBitRate": "The bitrate (Kbps) of sending the video."
            },
            {
                "lastmileDelay": "The client-to-server delay (milliseconds)."
            },
            {
                "txPacketLossRate": "The packet loss rate (%) from the client to the Agora server before applying the anti-packet-loss algorithm."
            },
            {
                "rxPacketLossRate": ""
            },
            {
                "cpuAppUsage": "The CPU usage (%) of the app."
            },
            {
                "cpuTotalUsage": "The system CPU usage (%).\n                         The value of cpuTotalUsage is always reported as 0 in the leaveChannel callback.\n                    "
            },
            {
                "gatewayRtt": "The round-trip time delay (ms) from the client to the local router."
            },
            {
                "memoryAppUsageRatio": "The memory ratio occupied by the app (%).\n                        This value is for reference only. Due to system limitations, you may not get this value.\n                    "
            },
            {
                "memoryTotalUsageRatio": "The memory occupied by the system (%).\n                        This value is for reference only. Due to system limitations, you may not get this value.\n                    "
            },
            {
                "memoryAppUsageInKbytes": "The memory size occupied by the app (KB).\n                        This value is for reference only. Due to system limitations, you may not get this value.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rtcsurfaceview",
        "name": "RtcSurfaceView",
        "description": "The RtcSurfaceView class, which is used for rendering the local and remote video.\nThis class corresponds to different classes on different platforms:\n                \n                    Android: SurfaceView (https://developer.android.com/reference/android/view/SurfaceView).\n                    iOS: UIView (https://developer.apple.com/documentation/uikit/uiview).\n                    Web: DivElement (https://api.dart.dev/stable/2.15.0/dart-html/DivElement-class.html).\n                    Does not apply to macOS or Windows.",
        "parameters": [
            {
                "uid": "The user ID."
            },
            {
                "channelId": "The channel name. This parameter signifies the channel in which users engage in real-time audio and video interaction. Under the premise of the same App ID, users who fill in the same channel ID enter the same channel for audio and video interaction. The string length must be less than 64 bytes. Supported characters:\n     The 26 lowercase English letters: a to z.\n     The 26 uppercase English letters: A to Z.\n     The 10 numeric characters: 0 to 9.\n     Space\n     \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\", \".\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \"{\", \"}\", \"|\", \"~\", \",\"\n \n  "
            },
            {
                "renderMode": "The video render mode. For details, see VideoRenderMode."
            },
            {
                "mirrorMode": "The video mirror mode. For details, see VideoMirrorMode."
            },
            {
                "zOrderOnTop": "Whether to place the surface on top of another surface view in the window, but still behind the window itsellf.\n                        This parameter is for Android only."
            },
            {
                "onPlatformViewCreated": "Occurs when a platform view is created."
            },
            {
                "gestureRecognizers": "The gesture object that should be consumed by the Web view. It is possible for other gesture recognizers to be competing\n                        with the web view on pointer events, e.g if the web view is inside a [ListView] the [ListView] will want to handle vertical\n                        drags. The web view will claim gestures that are recognized by any of the recognizers on this list.\n                        When this set is empty or null, the web view will only handle pointer events for gestures that were not claimed by any \n                            other gesture recognizer."
            },
            {
                "subProcess": "Whether to create a sub process."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rtctextureview",
        "name": "RtcTextureView",
        "description": "The RtcTextureView class, which is used for rendering\n        the local and remote video.\nThis class corresponds to different classes in on different platforms:\n            \n                Android: TextureView (https://developer.android.com/reference/android/view/TextureView)\n                    or FlutterTexture (https://api.flutter.dev/objcdoc/Protocols/FlutterTexture.html).\n                iOS/macOS/Windows: FlutterTexture (https://api.flutter.dev/objcdoc/Protocols/FlutterTexture.html).\n                Does not apply to Web.",
        "parameters": [
            {
                "subProcess": "Whether to create a sub process."
            },
            {
                "gestureRecognizers": "The gesture object that should be consumed by the Web view. It is possible for other gesture recognizers to be competing\n                        with the web view on pointer events, e.g if the web view is inside a [ListView] the [ListView] will want to handle vertical\n                        drags. The web view will claim gestures that are recognized by any of the recognizers on this list.\n                        When this set is empty or null, the web view will only handle pointer events for gestures that were not claimed by any \n                            other gesture recognizer."
            },
            {
                "onPlatformViewCreated": "Occurs when a platform view is created."
            },
            {
                "mirrorMode": "The video mirror mode. For details, see VideoMirrorMode."
            },
            {
                "renderMode": "The video render mode. For details, see VideoRenderMode."
            },
            {
                "channelId": ""
            },
            {
                "uid": "The user ID."
            },
            {
                "useFlutterTexture": "Whether to use FlutterTexture for rendering the view."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_screencaptureparameters",
        "name": "ScreenCaptureParameters",
        "description": "Screen sharing configurations.\n",
        "parameters": [
            {
                "dimensions": "The maximum dimensions of encoding the shared region.\n                        If the screen dimensions are different from the value of this parameter, Agora applies the following strategies for encoding. Suppose dimensions are set to 1,920 x 1,080:\n                                If the value of the screen dimensions is lower than that of dimensions, for example, 1,000 x 1,000 pixels, the SDK uses 1,000 x 1,000 pixels\n                                    for encoding.\n                                If the value of the screen dimensions is larger than that of dimensions, for example, 2,000 × 1,500, the SDK uses\n                                    the maximum value next to 1,920 × 1,080 with the aspect ratio of the screen dimension (4:3) for encoding, that is, 1,440 × 1,080.\n                            \n                    "
            },
            {
                "frameRate": "The frame rate (fps) of the shared region. The default value is 5. Agora does not recommend setting it to a value greater than 15."
            },
            {
                "bitrate": "The bitrate (Kbps) of the shared region. The default value is 0, which represents that the SDK works out a bitrate according to the dimensions of the current screen."
            },
            {
                "width": "The width of the region."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_transcodinguser",
        "name": "TranscodingUser",
        "description": "Transcoding configurations of each host.\n",
        "parameters": [
            {
                "uid": "The user ID of the host.\n       "
            },
            {
                "x": "The x coordinate (pixel) of the host's video on the output video frame (taking the upper left corner of the video frame as the origin). The value range is [0, width], where width is the LiveTranscodingwidth set in ."
            },
            {
                "y": "The y coordinate (pixel) of the host's video on the output video frame (taking the upper left corner of the video frame as the origin). The value range is [0, height], where height is the LiveTranscodingheight set in ."
            },
            {
                "width": "The width (pixel) of the host's video."
            },
            {
                "height": "The height (pixel) of the host's video.\n                    "
            },
            {
                "zOrder": "The layer index number of the host's video. The value range is [0, 100].\n                                0: (Default) The host's video is the bottom layer.\n                                100: The host's video is the top layer.\n                            \n                        \n                        \n                            \n                                If the value is beyond this range, the SDK reports the error code ERR_INVALID_ARGUMENT.\n                                As of v2.3, the SDK supports setting zOrder to 0.\n                            \n                        \n                    "
            },
            {
                "alpha": "The transparency of the host's video. The value range is [0.0, 1.0].\n                                0.0: Completely transparent.\n                                1.0: (Default) Opaque.\n                            \n                        \n                    "
            },
            {
                "audioChannel": "The audio channel used by the host's audio in the output audio. The default value is 0, and the value range is [0, 5].\n                                0: (Recommended) The defaut setting, which supports dual channels at most and depends on the upstream of the host.\n                                1: The host's audio uses the FL audio channel. If the host's upstream uses multiple audio channels, the Agora\n                                    server mixes them into mono first.\n                                2: The host's audio uses the FC audio channel. If the host's upstream uses multiple audio channels, the Agora\n                                    server mixes them into mono first.\n                                3: The host's audio uses the FR audio channel. If the host's upstream uses multiple audio channels, the Agora\n                                    server mixes them into mono first.\n                                4: The host's audio uses the BL audio channel. If the host's upstream uses multiple audio channels, the Agora\n                                    server mixes them into mono first.\n                                5: The host's audio uses the BR audio channel. If the host's upstream uses multiple audio channels, the Agora\n                                    server mixes them into mono first.\n                                0xFF or a value greater than 5: The host's audio is muted, and the Agora\n                                    server removes the host's audio.\n                            \n                            If the value is not 0, a special player is required.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_userinfo",
        "name": "UserInfo",
        "description": "The information of the user.\n",
        "parameters": [
            {
                "uid": "User ID"
            },
            {
                "userAccount": "The user account. "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_videodimensions",
        "name": "VideoDimensions",
        "description": "Video dimensions.\n",
        "parameters": [
            {
                "width": "The width (pixels) of the video.\n      "
            },
            {
                "height": "The height (pixels) of the video."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_videoencoderconfiguration",
        "name": "VideoEncoderConfiguration",
        "description": "Video encoder configurations.\n",
        "parameters": [
            {
                "dimensions": ""
            },
            {
                "frameRate": ""
            },
            {
                "minFramerate": "The minimum encoding frame rate of the video. The default value is -1."
            },
            {
                "bitrate": "The encoding bitrate (Kbps) of the video.\n      "
            },
            {
                "minBitrate": "The minimum encoding bitrate (Kbps) of the video.\n      The SDK automatically adjusts the encoding bitrate to adapt to the network conditions. Using a value greater than the default value forces the video encoder to output high-quality images but may cause more packet loss and sacrifice the smoothness of the video transmission. Unless you have special requirements for image quality, Agora does not recommend changing this value.\n      This parameter only applies to the interactive streaming profile.\n  "
            },
            {
                "orientationMode": "The orientation mode of the encoded video. See VideoOutputOrientationMode."
            },
            {
                "degradationPreference": "Video degradation preference under limited bandwidth. See DegradationPreference."
            },
            {
                "mirrorMode": "By default, the video is not mirrored.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_virtualbackgroundsource",
        "name": "VirtualBackgroundSource",
        "description": "The custom background image.\n",
        "parameters": [
            {
                "backgroundSourceType": "The type of the custom background image. See VirtualBackgroundSourceType."
            },
            {
                "color": "The type of the custom background image. The color of the custom background image. The format is a hexadecimal integer defined by RGB, without the # sign, such as 0xFFB6C1 for light pink.   The default value is 0xFFFFFF, which signifies white.  The value range is [0x000000, 0xffffff]. If the value is invalid, the SDK replaces the original background image with a white background image.This parameter takes effect only when the type of the custom background image is Color."
            },
            {
                "source": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "class_watermarkoptions",
        "name": "WatermarkOptions",
        "description": "Configurations of the watermark image.\n",
        "parameters": [
            {
                "visibleInPreview": "Whether the watermark image is visible in the local video preview:\n     true: (Default) The watermark image is visible in the local preview.\n     false: The watermark image is not visible in the local preview.\n \n      \n  "
            },
            {
                "positionInLandscapeMode": "The area to display the watermark image in landscape mode. \n  "
            },
            {
                "positionInPortraitMode": "The area to display the watermark image in portrait mode. \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_areacode",
        "name": "AreaCode",
        "description": "The region for connection, which is the region where\n            the server the SDK connects to is located.\n",
        "parameters": [
            {
                "CN": "Mainland China."
            },
            {
                "NA": "North America."
            },
            {
                "EU": "Europe."
            },
            {
                "AS": "Asia, excluding Mainland China."
            },
            {
                "JP": "Japan."
            },
            {
                "IN": "India."
            },
            {
                "GLOB": "(Default) Global."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiencelatencyleveltype",
        "name": "AudienceLatencyLevelType",
        "description": "The latency level of an audience member in interactive live streaming. This enum takes effect only when the user role is set to Audience.\n",
        "parameters": [
            {
                "LowLatency": "1: Low latency."
            },
            {
                "UltraLowLatency": "2: (Default) Ultra low latency."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiocodecprofiletype",
        "name": "AudioCodecProfileType",
        "description": "The codec type of the output audio stream for CDN live\n            streaming. The default value is LC-ACC.\n",
        "parameters": [
            {
                "LCAAC": "0: (Default) LC-AAC, which is the low-complexity audio codec type."
            },
            {
                "HEAAC": "1: HE-AAC, which is the high-efficiency audio codec type."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioeffectpreset",
        "name": "AudioEffectPreset",
        "description": "Preset voice effects.\nFor better voice effects, Agora recommends setting the profile parameter of setAudioProfile to MusicHighQuality or MusicHighQualityStereo before using the following presets:\n   \n       RoomAcousticsKTV\n       RoomAcousticsVocalConcert\n       RoomAcousticsStudio\n       RoomAcousticsPhonograph\n       RoomAcousticsSpacial\n       RoomAcousticsEthereal\n       VoiceChangerEffectUncle\n       VoiceChangerEffectOldMan\n       VoiceChangerEffectBoy\n       VoiceChangerEffectSister\n       VoiceChangerEffectGirl\n       VoiceChangerEffectPigKing\n       VoiceChangerEffectHulk\n       PitchCorrection",
        "parameters": [
            {
                "AudioEffectOff": "Turn off voice effects, that is, use the original voice."
            },
            {
                "RoomAcousticsKTV": "The voice effect typical of a KTV venue."
            },
            {
                "RoomAcousticsVocalConcert": "The voice effect typical of a concert hall."
            },
            {
                "RoomAcousticsStudio": "The voice effect typical of a recording studio."
            },
            {
                "RoomAcousticsPhonograph": "The voice effect typical of a vintage phonograph."
            },
            {
                "RoomAcousticsVirtualStereo": "The virtual stereo effect, which renders monophonic audio as stereo audio.\n      Before using this preset, set the profile parameter of setAudioProfile to MusicHighQuality or MusicHighQualityStereo; otherwise, the preset setting is invalid.\n  "
            },
            {
                "RoomAcousticsSpacial": "A more spatial voice effect."
            },
            {
                "RoomAcousticsEthereal": "A more ethereal voice effect."
            },
            {
                "RoomAcoustics3DVoice": "A 3D voice effect that makes the voice appear to be moving around the user. The default movement cycle is 10 seconds. After setting this effect, you can call setAudioEffectParameters to modify the movement period.\n      \n      \n Before using this preset, set the profile parameter of setAudioProfile to MusicStandardStereo or MusicHighQualityStereo; otherwise, the preset setting is invalid.\n If the 3D voice effect is enabled, users need to use stereo audio playback devices to hear the anticipated voice effect.\n      \n      \n  "
            },
            {
                "VoiceChangerEffectUncle": "A middle-aged man's voice.\n      Agora recommends using this preset to process a male-sounding voice; otherwise, you may not hear the anticipated voice effect.\n  "
            },
            {
                "VoiceChangerEffectOldMan": "A senior man's voice.\n      Agora recommends using this preset to process a male-sounding voice; otherwise, you may not hear the anticipated voice effect.\n  "
            },
            {
                "VoiceChangerEffectBoy": "A boy's voice.\n      Agora recommends using this preset to process a male-sounding voice; otherwise, you may not hear the anticipated voice effect.\n  "
            },
            {
                "VoiceChangerEffectSister": "A young woman's voice.\n      Agora recommends using this preset to process a female-sounding voice; otherwise, you may not hear the anticipated voice effect.\n  "
            },
            {
                "VoiceChangerEffectGirl": "A girl's voice.\n      Agora recommends using this preset to process a female-sounding voice; otherwise, you may not hear the anticipated voice effect.\n  "
            },
            {
                "VoiceChangerEffectPigKing": "The voice of Pig King, a character in Journey to the West who has a voice like a growling bear."
            },
            {
                "VoiceChangerEffectHulk": "The Hulk's voice."
            },
            {
                "StyleTransformationRnB": "The voice effect typical of R&B music.\n      Before using this preset, set the profile parameter of setAudioProfile to MusicHighQuality or MusicHighQualityStereo; otherwise, the preset setting is invalid.\n  "
            },
            {
                "StyleTransformationPopular": "The voice effect typical of popular music.\n      Before using this preset, set the profile parameter of setAudioProfile to MusicHighQuality or MusicHighQualityStereo; otherwise, the preset setting is invalid.\n  "
            },
            {
                "PitchCorrection": "A pitch correction effect that corrects the user's pitch based on the pitch of the natural C major scale. After setting this voice effect, you can call setAudioEffectParameters to adjust the basic mode of tuning and the pitch of the main tone."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioequalizationbandfrequency",
        "name": "AudioEqualizationBandFrequency",
        "description": "The midrange frequency for audio equalization.\n",
        "parameters": [
            {
                "Band31": "0: 31 Hz"
            },
            {
                "Band62": "1: 62 Hz"
            },
            {
                "Band125": "2: 125 Hz"
            },
            {
                "Band250": "3: 250 Hz"
            },
            {
                "Band500": "4: 500 Hz"
            },
            {
                "Band1K": "5: 1 kHz"
            },
            {
                "Band2K": "6: 2 kHz"
            },
            {
                "Band4K": "7: 4 kHz"
            },
            {
                "Band8K": "8: 8 kHz"
            },
            {
                "Band16K": "9: 16 kHz"
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiofileinfoerror",
        "name": "AudioFileInfoError",
        "description": "The information acquisition state. This enum is reported in requestAudioFileInfoCallback.\n",
        "parameters": [
            {
                "Ok": "0: Successfully get the information of an audio file."
            },
            {
                "Failure": "1: Fail to get the information of an audio file."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiomixingdualmonomode",
        "name": "AudioMixingDualMonoMode",
        "description": "The channel mode. Set in setAudioMixingDualMonoMode.\n",
        "parameters": [
            {
                "Auto": "0: Original mode."
            },
            {
                "L": "1: Left channel mode. This mode replaces the audio of the right channel with the audio of the left channel, which means the user can only hear the audio of the left channel."
            },
            {
                "R": "2: Right channel mode. This mode replaces the audio of the left channel with the audio of the right channel, which means the user can only hear the audio of the right channel."
            },
            {
                "MIX": "3: Mixed channel mode. This mode mixes the audio of the left channel and the right channel, which means the user can hear the audio of the left channel and the right channel at the same time."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiomixingerrortype",
        "name": "AudioMixingErrorType",
        "description": "Errors that might occur when playing a music\n        file.\n",
        "parameters": [
            {
                "CanNotOpen": "The SDK cannot open the music file."
            },
            {
                "TooFrequentCall": "The SDK opens the music file too frequently."
            },
            {
                "InterruptedEOF": "The playback of the music file is interrupted."
            },
            {
                "OK": "The music file is playing."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiomixingreasontype",
        "name": "AudioMixingReason",
        "description": "The reason why the playback state of the music file changes. Reported in the audioMixingStateChanged callback.\n",
        "parameters": [
            {
                "CanNotOpen": "701: The SDK cannot open the music file. For example, the local music file\n                        does not exist, the SDK does not support the file format, or  the SDK cannot\n                        access the music file URL."
            },
            {
                "TooFrequentCall": "702: The SDK opens the music file too frequently. If you need to call startAudioMixing multiple times, ensure that the call interval is more than 500 ms."
            },
            {
                "InterruptedEOF": "703: The music file playback is interrupted."
            },
            {
                "StartedByUser": "720: The method call of startAudioMixing to play music\n                        files succeeds."
            },
            {
                "OneLoopCompleted": "721: The music file completes a loop playback."
            },
            {
                "StartNewLoop": "722: The music file starts a new loop playback."
            },
            {
                "AllLoopsCompleted": "723: The music file completes all loop playbacks."
            },
            {
                "StoppedByUser": "724: The method call of stopAudioMixing to stop playing the\n                        music file succeeds."
            },
            {
                "PausedByUser": "725: The method call of pauseAudioMixing to pause playing\n                        the music file succeeds."
            },
            {
                "ResumedByUser": "726: The method call of resumeAudioMixing to resume playing\n                        the music file succeeds."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiomixingstatetype",
        "name": "AudioMixingStateCode",
        "description": "The playback state of the music file.\n",
        "parameters": [
            {
                "Playing": "710: The music file is playing.\n      "
            },
            {
                "Paused": "711: The music file pauses playing.\n      "
            },
            {
                "Stopped": "713: The music file stops playing.\n      "
            },
            {
                "Failed": "714: An error occurs during the playback of the audio mixing file.\n      "
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioprofiletype",
        "name": "AudioProfile",
        "description": "The audio profile.\n",
        "parameters": [
            {
                "Default": "0: The default audio profile.\n                                For the interactive streaming profile: A sample rate of 48 kHz, music encoding, mono, and a bitrate of up to 64 Kbps.\n                                For the communication profile: \n      \n      \n  "
            },
            {
                "SpeechStandard": "1: A sample rate of 32 kHz, audio encoding, mono, and a bitrate of up to 18 Kbps."
            },
            {
                "MusicStandard": "2: A sample rate of 48 kHz, music encoding, mono, and a bitrate of up to 64 Kbps."
            },
            {
                "MusicStandardStereo": "3: A sample rate of 48 kHz, music encoding, stereo, and a bitrate of up to 80 Kbps."
            },
            {
                "MusicHighQuality": "4: A sample rate of 48 kHz, music encoding, mono, and a bitrate of up to 96 Kbps."
            },
            {
                "MusicHighQualityStereo": "5: A sample rate of 48 kHz, music encoding, stereo, and a bitrate of up to 128 Kbps."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiorecordingposition",
        "name": "AudioRecordingPosition",
        "description": "Recording content. Set in startAudioRecordingWithConfig.\n",
        "parameters": [
            {
                "PositionMixedRecordingAndPlayback": "0: (Default) Records the mixed audio of the local and all remote users."
            },
            {
                "PositionRecording": "1: Only records the audio of the local user."
            },
            {
                "PositionMixedPlayback": "2: Only records the audio of all remote users."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiorecordingqualitytype",
        "name": "AudioRecordingQuality",
        "description": "Recording quality.\n",
        "parameters": [
            {
                "Low": "0: Low quality. The sample rate is 32 kHz, and the file size is around 1.2 MB for 10 minutes\n                        of recording."
            },
            {
                "Medium": "1: Medium quality. The sample rate is 32 kHz, and the file size is around 2 MB for 10 minutes\n                        of recording."
            },
            {
                "High": "2: High quality. The sample rate is 32 kHz, and the file size is around 3.75 MB for 10 minutes\n                        of recording."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioreverbpreset",
        "name": "AudioReverbPreset",
        "description": "Voice reverb presets.\n",
        "parameters": [
            {
                "Off": "Turn off voice reverb, that is, to use the original voice."
            },
            {
                "FX_KTV": "The reverb style typical of a KTV venue (enhanced)."
            },
            {
                "FX_VOCAL_CONCERT": "The reverb style typical of a concert hall (enhanced)."
            },
            {
                "FX_UNCLE": "A middle-aged man's voice."
            },
            {
                "FX_SISTER": "The reverb style typical of a young woman's voice."
            },
            {
                "FX_STUDIO": "The reverb style typical of a recording studio (enhanced)."
            },
            {
                "FX_POPULAR": "The reverb style typical of popular music (enhanced)."
            },
            {
                "FX_RNB": "The reverb style typical of R&B music (enhanced)."
            },
            {
                "FX_PHONOGRAPH": "The voice effect typical of a vintage phonograph."
            },
            {
                "VIRTUAL_STEREO": "The reverberation of the virtual stereo. The virtual stereo is an effect that renders the monophonic audio as the stereo audio, so that all users in the channel can hear the stereo voice effect."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioreverbtype",
        "name": "AudioReverbType",
        "description": "Audio reverberation types.\n",
        "parameters": [
            {
                "DryLevel": "0: The level of the dry signal (dB). The value is between -20 and 10."
            },
            {
                "WetLevel": "1: The level of the early reflection signal (wet signal) (dB). The value is between -20 and 10."
            },
            {
                "RoomSize": "2: The room size of the reflection. The value is between 0 and 100."
            },
            {
                "WetDelay": "3: The length of the initial delay of the wet signal (ms). The value is between 0 and 200."
            },
            {
                "Strength": "4: The reverberation strength. The value is between 0 and 100."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioroutetype",
        "name": "AudioOutputRouting",
        "description": "The type of the audio route.\n",
        "parameters": [
            {
                "Default": "-1: The default audio route."
            },
            {
                "Headset": "0: The headset."
            },
            {
                "Earpiece": "1: The earpiece."
            },
            {
                "HeadsetNoMic": "2: The headset with no microphone."
            },
            {
                "Speakerphone": "3: The built-in speaker on a mobile device."
            },
            {
                "Loudspeaker": "4: The external speaker."
            },
            {
                "HeadsetBluetooth": "5: The bluetooth headset."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiosampleratetype",
        "name": "AudioSampleRateType",
        "description": "The audio sampling rate of the stream to be pushed to the CDN.\n",
        "parameters": [
            {
                "Type32000": "32000: 32 kHz"
            },
            {
                "Type44100": "44100: 44.1 kHz"
            },
            {
                "Type48000": "48000: (Default) 48 kHz"
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioscenariotype",
        "name": "AudioScenario",
        "description": "Audio application scenarios.\n",
        "parameters": [
            {
                "Default": "0: The default audio scenario."
            },
            {
                "ChatRoomEntertainment": "1: Entertainment scenario where users need to frequently switch the user role."
            },
            {
                "Education": "2: Education scenario where users want smoothness and stability."
            },
            {
                "GameStreaming": "3: High-quality audio chatroom scenario where hosts mainly play music."
            },
            {
                "ShowRoom": "4: Showroom scenario where a single host wants high-quality audio."
            },
            {
                "ChatRoomGaming": "5: Gaming scenario for group chat that only contains the human voice."
            },
            {
                "IOT": "6: IoT (Internet of Things) scenario where users use IoT devices with low power consumption."
            },
            {
                "MEETING": "8: Meeting scenario that mainly contains the human voice.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiosessionoperationrestriction",
        "name": "AudioSessionOperationRestriction",
        "description": "The operational permission of the SDK on the audio session.\n",
        "parameters": [
            {
                "None": "No restriction, the SDK has full control of the audio session operations."
            },
            {
                "SetCategory": "The SDK does not change the audio session category."
            },
            {
                "ConfigureSession": "The SDK does not change any setting of the audio session (category, mode, categoryOptions)."
            },
            {
                "DeactivateSession": "The SDK keeps the audio session active when leaving a channel."
            },
            {
                "All": "The SDK does not configure the audio session anymore."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_backgroundblurdegree",
        "name": "VirtualBackgroundBlurDegree",
        "description": "The degree of blurring applied to the custom background image.\n",
        "parameters": [
            {
                "Low": "1: The degree of blurring applied to the custom background image is low. The user can almost see the background clearly."
            },
            {
                "Medium": "The degree of blurring applied to the custom background image is medium. It is difficult for the user to recognize details in the background."
            },
            {
                "High": "(Default) The degree of blurring applied to the custom background image is high. The user can barely see any distinguishing features in the background."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_backgroundsourcetype",
        "name": "VirtualBackgroundSourceType",
        "description": "The type of the custom background image.\n",
        "parameters": [
            {
                "Color": "1: (Default) The background image is a solid color."
            },
            {
                "Img": "The background image is a file in PNG or JPG format."
            },
            {
                "Blur": "The background image is the blurred background."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_cameradirection",
        "name": "CameraDirection",
        "description": "The camera direction.\n",
        "parameters": [
            {
                "Rear": "The rear camera."
            },
            {
                "Front": "The front camera."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_capturebrightnessleveltype",
        "name": "CaptureBrightnessLevelType",
        "description": "The brightness level of the video image captured by the local camera.\n",
        "parameters": [
            {
                "Invalid": "-1: The SDK does not detect the brightness level of the video image. Wait a few seconds to get the brightness level from captureBrightnessLevel in the next callback."
            },
            {
                "Normal": "0: The brightness level of the video image is normal."
            },
            {
                "Bright": "1: The brightness level of the video image is too bright."
            },
            {
                "Dark": "2: The brightness level of the video image is too dark."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_captureroutputpreference",
        "name": "CameraCaptureOutputPreference",
        "description": "Camera capture preference.\n",
        "parameters": [
            {
                "Auto": "0: (Default) Automatically adjust the camera capture preference. The SDK adjusts the camera output parameters according to the system performance and network conditions to balance CPU consumption and video preview quality."
            },
            {
                "Performance": "1: Prioritizes the system performance. The SDK chooses the dimension and frame rate of the local camera capture closest to those set by setVideoEncoderConfiguration. In this case, the local preview quality depends on the encoder."
            },
            {
                "Preview": "2: Prioritizes the local preview quality. The SDK chooses higher camera output parameters to improve the local video preview quality. This option requires extra CPU and RAM usage for video pre-processing."
            },
            {
                "Manual": "3: Allows you to customize the width and height of the video image captured by the local camera.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_channelmediarelayerror",
        "name": "ChannelMediaRelayError",
        "description": "The error code of the channel media replay.\n",
        "parameters": [
            {
                "None": "0: No error."
            },
            {
                "ServerErrorResponse": "1: An error occurs in the server response."
            },
            {
                "ServerNoResponse": "2: No server response.\n      You can call leaveChannel to leave the channel.\n      This error can also occur if your project has not enabled co-host token authentication. Contact support@agora.io to enable the co-host token authentication service before starting a channel media relay.\n  "
            },
            {
                "NoResourceAvailable": "3: The SDK fails to access the service, probably due to limited resources of the server."
            },
            {
                "FailedJoinSourceChannel": "4: Fails to send the relay request."
            },
            {
                "FailedJoinDestinationChannel": "5: Fails to accept the relay request."
            },
            {
                "FailedPacketReceivedFromSource": "6: The server fails to receive the media stream."
            },
            {
                "FailedPacketSentToDestination": "7: The server fails to send the media stream."
            },
            {
                "ServerConnectionLost": "8: The SDK disconnects from the server due to poor network connections. You can call the leaveChannel method to leave the channel."
            },
            {
                "InternalError": "9: An internal error occurs in the server."
            },
            {
                "SourceTokenExpired": "10: The token of the source channel has expired."
            },
            {
                "DestinationTokenExpired": "11: The token of the destination channel has expired."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_channelmediarelayevent",
        "name": "ChannelMediaRelayEvent",
        "description": "The event code of channel media relay.\n",
        "parameters": [
            {
                "Disconnect": "0: The user disconnects from the server due to a poor network connection."
            },
            {
                "Connected": "1: The user is connected to the server."
            },
            {
                "JoinedSourceChannel": "2: The user joins the source channel."
            },
            {
                "JoinedDestinationChannel": "3: The user joins the destination channel."
            },
            {
                "SentToDestinationChannel": "4: The SDK starts relaying the media stream to the destination channel."
            },
            {
                "ReceivedVideoPacketFromSource": "5: The server receives the audio stream from the source channel."
            },
            {
                "ReceivedAudioPacketFromSource": "6: The server receives the audio stream from the source channel."
            },
            {
                "UpdateDestinationChannel": "7: The destination channel is updated."
            },
            {
                "UpdateDestinationChannelRefused": "8: The destination channel update fails due to internal reasons."
            },
            {
                "UpdateDestinationChannelNotChange": "9: The destination channel does not change, which means that the destination channel fails to be updated."
            },
            {
                "UpdateDestinationChannelIsNil": "10: The destination channel name is null."
            },
            {
                "VideoProfileUpdate": "11: The video profile is sent to the server."
            },
            {
                "PauseSendPacketToDestChannelSuccess": "12: The SDK successfully pauses relaying the media stream to destination channels."
            },
            {
                "PauseSendPacketToDestChannelFailed": "13: The SDK fails to pause relaying the media stream to destination channels."
            },
            {
                "ResumeSendPacketToDestChannelSuccess": "14: The SDK successfully resumes relaying the media stream to destination channels."
            },
            {
                "ResumeSendPacketToDestChannelFailed": "15: The SDK fails to resume relaying the media stream to destination channels."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_channelmediarelaystate",
        "name": "ChannelMediaRelayState",
        "description": "The state code of the channel media relay.\n",
        "parameters": [
            {
                "Idle": "0: The initial state. After you successfully stop the channel media relay by calling stopChannelMediaRelay, the channelMediaRelayStateChanged callback returns this state."
            },
            {
                "Connecting": "1: The SDK tries to relay the media stream to the destination channel."
            },
            {
                "Running": "2: The SDK successfully relays the media stream to the destination channel."
            },
            {
                "Failure": "3: An error occurs. See code in channelMediaRelayStateChanged for the error code."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_channelprofiletype",
        "name": "ChannelProfile",
        "description": "The channel profile.\n",
        "parameters": [
            {
                "Communication": "0: (Default) The communication profile. This profile applies to scenarios such as an audio call or video call, where all users can publish and subscribe to streams."
            },
            {
                "LiveBroadcasting": "1: Live streaming. In this profile, you can set the role of users as the host or audience by calling setClientRole. A host both publishes and subscribes to streams, while an audience subscribes to streams only. This profile applies to scenarios such as a chat room or interactive video streaming."
            },
            {
                "Game": "2: Gaming. Agora does not recommend using this setting."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_clientroletype",
        "name": "ClientRole",
        "description": "The user role in the interactive live streaming.\n",
        "parameters": [
            {
                "Broadcaster": "1: Host. A host can both send and receive streams."
            },
            {
                "Audience": "2: (Default) Audience. An audience member can only receive streams."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_cloudproxytype",
        "name": "CloudProxyType",
        "description": "The cloud proxy type.\n",
        "parameters": [
            {
                "None": "0: Do not use cloud proxy."
            },
            {
                "UDP": "1: Use cloud proxy with the UDP protocol."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_connectionchangedreasontype",
        "name": "ConnectionChangedReason",
        "description": "Reasons causing the change of the connection state.\n",
        "parameters": [
            {
                "Connecting": "0: The SDK is connecting to the Agora edge server."
            },
            {
                "JoinSuccess": "1: The SDK has joined the channel successfully."
            },
            {
                "Interrupted": "2: The connection between the SDK and the Agora edge server is interrupted."
            },
            {
                "BannedByServer": "3: The connection between the SDK and the Agora edge server is banned by the Agora edge server. This error occurs when the user is kicked out of the channel by the server."
            },
            {
                "JoinFailed": "4: The SDK fails to join the channel. When the SDK fails to join the channel for more than 20 minutes, this error occurs and the SDK stops reconnecting to the channel."
            },
            {
                "LeaveChannel": "5: The SDK has left the channel."
            },
            {
                "InvalidAppId": "6: The connection failed because the App ID is not valid. Please rejoin the channel with a valid App ID."
            },
            {
                "InvalidChannelName": "7: The connection failed since channel name is not valid. Please rejoin the channel with a valid channel name."
            },
            {
                "InvalidToken": "8: The connection failed because the token is not valid. Typical reasons include:\n      The App Certificate for the project is enabled in Agora Console, but you do not use a token when joining the channel. If you enable the App Certificate, you must use a token to join the channel.\n      The uid specified when calling joinChannel to join the channel is inconsistent with the uid passed in when generating the token.\n  "
            },
            {
                "TokenExpired": "9: The connection failed since token is expired."
            },
            {
                "RejectedByServer": "10: The connection is rejected by server. Typical reasons include:\n      The user is already in the channel and still calls a method, for example, joinChannel, to join the channel. Stop calling this method to clear this error.\n      The user tries to join the channel when conducting  a pre-call test. The user needs to call the channel after the call test ends.\n  \n  "
            },
            {
                "SettingProxyServer": "11: The connection state changed to reconnecting because the SDK has set a proxy server."
            },
            {
                "RenewToken": "12: The connection state changed because the token is renewed."
            },
            {
                "ClientIpAddressChanged": "13: The IP address of the client has changed, possibly because the network type, IP address, or port has been changed."
            },
            {
                "KeepAliveTimeout": "14: Timeout for the keep-alive of the connection between the SDK and the Agora edge server. The connection state changes to Reconnecting."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_connectionstatetype",
        "name": "ConnectionStateType",
        "description": "Connection states.\n",
        "parameters": [
            {
                "Disconnected": "1: The SDK is disconnected from the Agora edge server. The state indicates the SDK is in one of the following phases:\n      The initial state before calling the joinChannel method.\n      The app calls the leaveChannel method.\n  \n  "
            },
            {
                "Connecting": "2: The SDK is connecting to the Agora edge server. This state indicates that the SDK is establishing a connection with the specified channel after the app calls joinChannel.\n      If the SDK successfully joins the channel, it triggers the connectionStateChanged callback and the connection state switches to Connected.\n      After the connection is established, the SDK also initializes the media and triggers joinChannelSuccess when everything is ready.\n  \n  "
            },
            {
                "Connected": "3: The SDK is connected to the Agora edge server. This state also indicates that the user has joined a channel and can now publish or subscribe to a media stream in the channel. If the connection to the Agora edge server is lost because, for example, the network is down or switched, the SDK automatically tries to reconnect and triggers connectionStateChanged that indicates the connection state switches to Reconnecting."
            },
            {
                "Reconnecting": "4: The SDK keeps reconnecting to the Agora edge server. The SDK keeps rejoining the channel after being disconnected from a joined channel because of network issues.\n      If the SDK cannot rejoin the channel within 10 seconds, it triggers connectionLost, stays in the Reconnecting state, and keeps rejoining the channel.\n      If the SDK fails to rejoin the channel 20 minutes after being disconnected from the Agora edge server, the SDK triggers the connectionStateChanged callback, switches to the Failed state, and stops rejoining the channel.\n  "
            },
            {
                "Failed": "5: The SDK fails to connect to the Agora edge server or join the channel. This state indicates that the SDK stops trying to rejoin the channel. You must call leaveChannel to leave the channel.\n      You can call joinChannel to rejoin the channel.\n      If the SDK is banned from joining the channel by the Agora edge server through the RESTful API, the SDK triggers the connectionStateChanged callback.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_degradationpreference",
        "name": "DegradationPreference",
        "description": "Video degradation preferences when the bandwidth is a constraint.\n",
        "parameters": [
            {
                "MaintainQuality": "0: (Default) Prefers to reduce the video frame rate while maintaining video quality during video encoding under limited bandwidth. This degradation preference is suitable for scenarios where video quality is prioritized.\n  In the COMMUNICATION channel profile, the resolution of the video sent may change, so remote users need to handle this issue. See videoSizeChanged."
            },
            {
                "MaintainFramerate": "1: Prefers to reduce the video quality while maintaining the video frame rate during video encoding under limited bandwidth. This degradation preference is suitable for scenarios where smoothness is prioritized and video quality is allowed to be reduced."
            },
            {
                "MaintainBalanced": "2: Reduces the video frame rate and video quality simultaneously during video encoding under limited bandwidth. MaintainBalanced has a lower reduction than MaintainQuality and MaintainFramerate, and this preference is suitable for scenarios where both smoothness and video quality are a priority.\n                        The resolution of the video sent may change, so remote users need to handle this issue. See videoSizeChanged.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_encryptionmode",
        "name": "EncryptionMode",
        "description": "The built-in encryption mode.\nAgora recommends using AES128GCM2 or AES256GCM2 encrypted mode. These two modes support the use of salt for higher security.",
        "parameters": [
            {
                "AES128XTS": ""
            },
            {
                "AES128ECB": "2: 128-bit AES encryption, ECB mode."
            },
            {
                "AES256XTS": "3: 256-bit AES encryption, XTS mode."
            },
            {
                "SM4128ECB": "4: 128-bit SM4 encryption, ECB mode."
            },
            {
                "AES128GCM": "5: 128-bit AES encryption, GCM mode."
            },
            {
                "AES256GCM": "6: 256-bit AES encryption, GCM mode."
            },
            {
                "AES128GCM2": ""
            },
            {
                "AES256GCM2": "8: 256-bit AES encryption, GCM mode. This encryption mode requires the setting of salt (encryptionKdfSalt)."
            },
            {
                "": "Enumerator boundary."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_experiencepoorreason",
        "name": "ExperiencePoorReason",
        "description": "Reasons why the QoE of the local user when receiving a remote audio stream is poor.\n",
        "parameters": [
            {
                "None": "0: No reason, indicating a good QoE of the local user."
            },
            {
                "RemoteNetworkQualityPoor": "1: The remote user's network quality is poor."
            },
            {
                "LocalNetworkQualityPoor": "2: The local user's network quality is poor."
            },
            {
                "WirelessSignalPoor": "4: The local user's Wi-Fi or mobile network signal is weak."
            },
            {
                "WifiBluetoothCoexist": "8: The local user enables both Wi-Fi and bluetooth, and their signals interfere with each other. As a result, audio transmission quality is undermined."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_experiencequalitytype",
        "name": "ExperienceQualityType",
        "description": "The Quality of Experience (QoE) of the local user when receiving a remote audio stream.\n",
        "parameters": [
            {
                "Good": "0: The QoE of the local user is good."
            },
            {
                "Bad": "1: The QoE of the local user is poor."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_framerate",
        "name": "VideoFrameRate",
        "description": "Video frame rate.\n",
        "parameters": [
            {
                "Fps1": "1: 1 fps"
            },
            {
                "Fps7": "7: 7 fps"
            },
            {
                "Fps10": "10: 10 fps"
            },
            {
                "Fps15": "15: 15 fps"
            },
            {
                "Fps24": "24: 24 fps"
            },
            {
                "Fps30": "30: 30 fps"
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_injectstreamstatus",
        "name": "InjectStreamStatus",
        "description": "States of importing an external video stream in the interactive live streaming.\n",
        "parameters": [
            {
                "StartSuccess": "0: The external video stream is imported successfully."
            },
            {
                "StartAlreadyExists": "1: The external video stream already exists."
            },
            {
                "StartUnauthorized": "2: The external video stream to be imported is unauthorized."
            },
            {
                "StartTimedout": "3: A timeout occurs when importing the external video stream."
            },
            {
                "StartFailed": "4: The SDK fails to import the external video stream."
            },
            {
                "StopSuccess": "5: The SDK successfully stops importing the external video stream."
            },
            {
                "StopNotFound": "6: The external video stream to be stopped importing is not found."
            },
            {
                "StopUnauthorized": "7: The external video stream to be stopped importing is unauthorized."
            },
            {
                "StopTimedout": "8: A timeout occurs when stopping importing the external video stream."
            },
            {
                "StopFailed": "9: The SDK fails to stop importing the external video stream."
            },
            {
                "Broken": "10: The external video stream is corrupted."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_lastmileproberesultstate",
        "name": "LastmileProbeResultState",
        "description": "The status of the last-mile network tests.\n",
        "parameters": [
            {
                "Complete": "1: The last-mile network probe test is complete."
            },
            {
                "IncompleteNoBwe": "2: The last-mile network probe test is incomplete because the bandwidth estimation is not available due to limited test resources."
            },
            {
                "Unavailable": "3: The last-mile network probe test is not carried out, probably due to poor network conditions."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_lighteningcontrastlevel",
        "name": "LighteningContrastLevel",
        "description": "The contrast level.\n",
        "parameters": [
            {
                "Low": "Low contrast level."
            },
            {
                "Normal": "(Default) Normal contrast level."
            },
            {
                "High": "High contrast level."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_localaudiostreamerror",
        "name": "AudioLocalError",
        "description": "Local audio state error codes.\n",
        "parameters": [
            {
                "Ok": "0: The local audio is normal."
            },
            {
                "Failure": "1: No specified reason for the local audio failure."
            },
            {
                "DeviceNoPermission": "2: No permission to use the local audio device."
            },
            {
                "DeviceBusy": "3: The microphone is in use."
            },
            {
                "RecordFailure": "4: The local audio capturing fails. Check whether the capturing device is working properly."
            },
            {
                "EncodeFailure": "5: The local audio encoding fails."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_localaudiostreamstate",
        "name": "AudioLocalState",
        "description": "Local audio states.\n",
        "parameters": [
            {
                "Stopped": "0: The local audio is in the initial state."
            },
            {
                "Recording": "1: The capturing device starts successfully."
            },
            {
                "Encoding": "2: The first audio frame encodes successfully."
            },
            {
                "Failed": "3: The local audio fails to start."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_localvideostreamerror",
        "name": "LocalVideoStreamError",
        "description": "Local video state error codes.\n",
        "parameters": [
            {
                "OK": "0: The local video is normal."
            },
            {
                "Failure": "1: No specified reason for the local video failure."
            },
            {
                "DeviceNoPermission": "2: No permission to use the local video capturing device."
            },
            {
                "DeviceBusy": "3: The local video capturing device is in use."
            },
            {
                "CaptureFailure": "4: The local video capture fails. Check whether the capturing device is working properly."
            },
            {
                "EncodeFailure": "5: The local video encoding fails."
            },
            {
                "CaptureInBackground": "6: The local video capturing device not available due to app did enter background."
            },
            {
                "CaptureMultipleForegroundApps": "7: The local video capturing device not available because the app is running in a multi-app layout (generally on the pad)."
            },
            {
                "DeviceNotFound": "8: Fails to find a local video capture device.\n                    "
            },
            {
                "LocalVideoStreamErrorDeviceInvalidId": "10: (macOS and Windows only) The SDK cannot find the video device in the video device list. Check whether the ID of the video device is valid."
            },
            {
                "ScreenCaptureWindowMinmized": "startScreenCaptureByWindowId11: When calling to share the window, the shared window is in a minimized state."
            },
            {
                "ScreenCaptureWindowClosed": "12: The error code indicates that a window shared by the window ID has been closed, or a full-screen window shared by the window ID has exited full-screen mode. After exiting full-screen mode, remote users cannot see the shared window. To prevent remote users from seeing a black screen, Agora recommends that you immediately stop screen sharing.\n      Common scenarios for reporting this error code:\n When the local user closes the shared window, the SDK reports this error code.\n     The local user shows some slides in full-screen mode first, and then shares the windows of the slides. After the user exits full-screen mode, the SDK reports this error code.\n     The local user watches web video or reads web document in full-screen mode first, and then shares the window of the web video or document. After the user exits full-screen mode, the SDK reports this error code.\n      \n  "
            },
            {
                "LocalVideoStreamErrorScreenCaptureWindowOccluded": "13: (Windows only) The window being shared is overlapped by another window, so the overlapped area is blacked out by the SDK during window sharing."
            },
            {
                "LocalVideoStreamErrorScreenCaptureWindowNotSupported": "20: (Windows only) The SDK does not support sharing this type of window."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_localvideostreamstate",
        "name": "LocalVideoStreamState",
        "description": "Local video state types\n",
        "parameters": [
            {
                "Stopped": "0: The local video is in the initial state."
            },
            {
                "Capturing": "1: The local video capturing device starts successfully. "
            },
            {
                "Encoding": "2: The first video frame is successfully encoded."
            },
            {
                "Failed": "3: Fails to start the local video."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_logfiltertype",
        "name": "LogFilter",
        "description": "The output log level of the SDK.\n",
        "parameters": [
            {
                "Off": "0: Do not output any log information."
            },
            {
                "Debug": "0x080f: Output all log information. Set your log filter as DEBUG if you want to get the most complete log file."
            },
            {
                "Info": "0x000f: Output CRITICAL, ERROR, WARNING, and INFO level log information. We recommend setting your log filter as this level."
            },
            {
                "Warning": "0x000e: Output CRITICAL, ERROR, and WARNING level log information."
            },
            {
                "Error": "0x000c: Output CRITICAL and ERROR level log information."
            },
            {
                "Critical": "0x0008: Output CRITICAL level log information."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_loglevel",
        "name": "LogLevel",
        "description": "The output log level of the SDK.\n",
        "parameters": [
            {
                "None": "0: Do not output any log information."
            },
            {
                "Info": "0x0001: (Default) Output FATAL, ERROR,\n                        WARN, and INFO level log information. We\n                        recommend setting your log filter as this level."
            },
            {
                "Warn": "0x0002: Output FATAL, ERROR, and WARN level\n                        log information."
            },
            {
                "Error": "0x0004: Output FATAL and ERROR level log information."
            },
            {
                "Fatal": "0x0008: Output FATAL level log information."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_mediadevicestatetype",
        "name": "MediaDeviceStateType",
        "description": "Media device states.\n",
        "parameters": [
            {
                "MediaDeviceStateIdle": "0: The device is ready for use."
            },
            {
                "MediaDeviceStateActive": "1: The device is in use."
            },
            {
                "MediaDeviceStateDisabled": "2: The device is disabled."
            },
            {
                "MediaDeviceStateNotPresent": "4: The device is not found."
            },
            {
                "MediaDeviceStateUnplugged": "8: The device is unplugged."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_mediadevicetype",
        "name": "MediaDeviceType",
        "description": "Media device types.\n",
        "parameters": [
            {
                "UnknownAudioDevice": "-1: Unknown device type."
            },
            {
                "AudioPlayoutDevice": "0: Audio playback device."
            },
            {
                "AudioRecordingDevice": "1: Audio capturing device."
            },
            {
                "VideoRenderDevice": "2: Video renderer."
            },
            {
                "VideoCaptureDevice": "3: Video capturer."
            },
            {
                "AudioApplicationPlayoutDevice": "4: Application audio playback device."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_networktype",
        "name": "NetworkType",
        "description": "Network type.\n",
        "parameters": [
            {
                "Unknown": "-1: The network type is unknown."
            },
            {
                "Disconnected": "0: The SDK disconnects from the network."
            },
            {
                "LAN": "1: The network type is LAN."
            },
            {
                "WIFI": "2: The network type is Wi-Fi (including hotspots)."
            },
            {
                "Mobile2G": "3: The network type is mobile 2G."
            },
            {
                "Mobile3G": "4: The network type is mobile 3G."
            },
            {
                "Mobile4G": "5: The network type is mobile 4G."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_orientationmode",
        "name": "VideoOutputOrientationMode",
        "description": "Video output orientation modes.\n",
        "parameters": [
            {
                "Adaptative": "0: (Default) The output video always follows the orientation of the captured video. The receiver takes the rotational information passed on from the video encoder. This mode applies to scenarios where video orientation can be adjusted on the receiver.\n      \n If the captured video is in landscape mode, the output video is in landscape mode.\n If the captured video is in portrait mode, the output video is in portrait mode.\n      \n  "
            },
            {
                "FixedLandscape": "1: In this mode, the SDK always outputs videos in landscape (horizontal) mode. If the captured video is in portrait mode, the video encoder crops it to fit the output. Applies to situations where the receiving end cannot process the rotational information. For example, CDN live streaming."
            },
            {
                "FixedPortrait": "2: In this mode, the SDK always outputs video in portrait (portrait) mode. If the captured video is in landscape mode, the video encoder crops it to fit the output. Applies to situations where the receiving end cannot process the rotational information. For example, CDN live streaming."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_prioritytype",
        "name": "UserPriority",
        "description": "The priority of the remote user.\n",
        "parameters": [
            {
                "High": "The user's priority is high."
            },
            {
                "Normal": "(Default) The user's priority is normal."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_qualityadaptindication",
        "name": "VideoQualityAdaptIndication",
        "description": "Quality change of the local video in terms of target frame rate and target bit rate since last count.\n",
        "parameters": [
            {
                "AdaptNone": "0: The local video quality stays the same."
            },
            {
                "AdaptUpBandwidth": "1: The local video quality improves because the network bandwidth increases."
            },
            {
                "AdaptDownBandwidth": "2: The local video quality deteriorates because the network bandwidth decreases."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_qualitytype",
        "name": "NetworkQuality",
        "description": "Network quality types.\n",
        "parameters": [
            {
                "Unknown": "0: The network quality is unknown."
            },
            {
                "Excellent": "1: The network quality is excellent."
            },
            {
                "Good": "2: The network quality is quite good, but the bitrate may be slightly lower than excellent."
            },
            {
                "Poor": "3: Users can feel the communication slightly impaired."
            },
            {
                "Bad": "4: Users cannot communicate smoothly."
            },
            {
                "VBad": "5: The quality is so bad that users can barely communicate."
            },
            {
                "Down": "6: The network is down and users cannot communicate at all."
            },
            {
                "Unsupported": "7: Users cannot detect the network quality. (Not in use.)"
            },
            {
                "Detecting": "8: Detecting the network quality."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_remoteaudiostate",
        "name": "AudioRemoteState",
        "description": "Remote audio states.\n",
        "parameters": [
            {
                "Stopped": "0: The local audio is in the initial state. The SDK reports this state in the case of LocalMuted, RemoteMuted or RemoteOffline."
            },
            {
                "Starting": "1: The first remote audio packet is received."
            },
            {
                "Decoding": "2: The remote audio stream is decoded and plays normally. The SDK reports this state in the case of NetworkRecovery, LocalUnmuted or RemoteUnmuted."
            },
            {
                "Frozen": "3: The remote audio is frozen. The SDK reports this state in the case of NetworkCongestion."
            },
            {
                "Failed": "4: The remote audio fails to start. The SDK reports this state in the case of Internal."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_remoteaudiostatereason",
        "name": "AudioRemoteStateReason",
        "description": "The reason for the remote audio state change.\n",
        "parameters": [
            {
                "Internal": "0: The SDK reports this reason when the audio state changes."
            },
            {
                "NetworkCongestion": "1: Network congestion."
            },
            {
                "NetworkRecovery": "2: Network recovery."
            },
            {
                "LocalMuted": "3: The local user stops receiving the remote audio stream or disables the audio module."
            },
            {
                "LocalUnmuted": "4: The local user resumes receiving the remote audio stream or enables the audio module."
            },
            {
                "RemoteMuted": "5: The remote user stops sending the audio stream or disables the audio module."
            },
            {
                "RemoteUnmuted": "6: The remote user resumes sending the audio stream or enables the audio module."
            },
            {
                "RemoteOffline": "7: The remote user leaves the channel."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_remotevideostate",
        "name": "VideoRemoteState",
        "description": "The state of the remote video.\n",
        "parameters": [
            {
                "Stopped": "0: The remote video is in the initial state. The SDK reports this state in the case of LocalMuted, RemoteMuted or RemoteOffline."
            },
            {
                "Starting": "1: The first remote video packet is received."
            },
            {
                "Decoding": "2: The remote video stream is decoded and plays normally. The SDK reports this state in the case of NetworkRecovery, LocalUnmuted,RemoteUnmuted, or AudioFallbackRecovery."
            },
            {
                "Frozen": "3: The remote video is frozen. The SDK reports this state in the case of NetworkCongestion or AudioFallback."
            },
            {
                "Failed": "4: The remote video fails to start. The SDK reports this state in the case of Internal."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_remotevideostatereason",
        "name": "VideoRemoteStateReason",
        "description": "The reason for the remote video state change.\n",
        "parameters": [
            {
                "Internal": "0: The SDK reports this reason when the video state changes."
            },
            {
                "NetworkCongestion": "1: Network congestion."
            },
            {
                "NetworkRecovery": "2: Network recovery."
            },
            {
                "LocalMuted": "3: The local user stops receiving the remote\n  video stream or disables the video module."
            },
            {
                "LocalUnmuted": "4: The local user resumes receiving the remote video stream or enables the video module."
            },
            {
                "RemoteMuted": "5: The remote user stops sending the video stream or disables the video module."
            },
            {
                "RemoteUnmuted": "6: The remote user resumes sending the video stream or enables the video module."
            },
            {
                "RemoteOffline": "7: The remote user leaves the channel."
            },
            {
                "AudioFallback": "8: The remote audio-and-video stream falls back to the audio-only stream due to poor network conditions."
            },
            {
                "AudioFallbackRecovery": "9: The remote audio-only stream switches back to the audio-and-video stream after the network conditions improve."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_remotevideostreamtype",
        "name": "VideoStreamType",
        "description": "The type of video streams.\n",
        "parameters": [
            {
                "High": "0: High-quality video stream."
            },
            {
                "Low": "1: Low-quality video stream."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_rendermodetype",
        "name": "VideoRenderMode",
        "description": "Video display modes.\n",
        "parameters": [
            {
                "Hidden": "1: Uniformly scale the video until one of its dimension fits the boundary (zoomed to fit). Hidden mode. One dimension of the video may have clipped contents."
            },
            {
                "Fit": "2: Uniformly scale the video until one of its dimension fits the boundary (zoomed to fit). Fit mode. Areas that are not filled due to disparity in the aspect ratio are filled with black."
            },
            {
                "Adaptive": "\n \n     Deprecated:\n     3: This mode is deprecated.\n \n      "
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_rtmpstreamingevent",
        "name": "RtmpStreamingEvent",
        "description": "Events during the RTMP or RTMPS streaming.\n",
        "parameters": [
            {
                "FailedLoadImage": "An error occurs when you add a background image or a watermark image to the RTMP or RTMPS stream."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_rtmpstreampublisherror",
        "name": "RtmpStreamingErrorCode",
        "description": "Error codes of the RTMP or RTMPS streaming.\n",
        "parameters": [
            {
                "OK": "The RTMP or RTMPS streaming publishes successfully."
            },
            {
                "InvalidParameters": "Invalid argument used. Please check the parameter setting. For example, if you do not call setLiveTranscoding to set the transcoding parameters before calling addPublishStreamUrl, the SDK returns this error."
            },
            {
                "EncryptedStreamNotAllowed": "Check whether you set the parameters in the setLiveTranscoding method properly."
            },
            {
                "ConnectionTimeout": "The RTMP or RTMPS streaming is encrypted and cannot be published. Call addPublishStreamUrl to re-publish the stream."
            },
            {
                "InternalServerError": "An error occurs in Agora's streaming server. Call the addPublishStreamUrl method to publish the streaming again."
            },
            {
                "RtmpServerError": "An error occurs in the CDN server."
            },
            {
                "TooOften": "The RTMP or RTMPS streaming publishes too frequently."
            },
            {
                "ReachLimit": "The host has published more than 10 URLs. Delete the unnecessary URLs before adding new ones."
            },
            {
                "NotAuthorized": "The host manipulates other hosts' streams. For example, the host updates or stops other hosts' streams. Check your app logic."
            },
            {
                "StreamNotFound": "Agora's server fails to find the RTMP or RTMPS streaming."
            },
            {
                "FormatNotSupported": "The URL format is incorrect. Check whether the URL format is correct."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_rtmpstreampublishstate",
        "name": "RtmpStreamingState",
        "description": "States of the RTMP or RTMPS streaming.\n",
        "parameters": [
            {
                "Idle": "The RTMP or RTMPS streaming has not started or has ended. This state is also triggered after you remove an RTMP or RTMPS stream from the CDN by calling removePublishStreamUrl."
            },
            {
                "Connecting": "The SDK is connecting to Agora's streaming server and the CDN server. This state is triggered after you call the addPublishStreamUrl method."
            },
            {
                "Running": "The RTMP or RTMPS streaming publishes. The SDK successfully publishes the RTMP or RTMPS streaming and returns this state."
            },
            {
                "Recovering": "The RTMP or RTMPS streaming is recovering. When exceptions occur to the CDN, or the streaming is interrupted, the SDK tries to resume RTMP or RTMPS streaming and returns this state.\n      \n If the SDK successfully resumes the streaming, Running(2) returns.\n If the streaming does not resume within 60 seconds or server errors occur, Failure(4) returns. You can also reconnect to the server by calling the removePublishStreamUrl and addPublishStreamUrl methods.\n      \n  "
            },
            {
                "Failure": "The RTMP or RTMPS streaming fails. See the error code for the detailed error information. You can also call the addPublishStreamUrl method to publish the RTMP or RTMPS stream again."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_streamfallbackoptions",
        "name": "StreamFallbackOptions",
        "description": "Stream fallback options.\n",
        "parameters": [
            {
                "Disabled": "0: No fallback behavior for the local/remote video stream when the uplink/downlink network conditions are poor. The quality of the stream is not guaranteed."
            },
            {
                "VideoStreamLow": "1: Under poor downlink network conditions, the remote video stream, to which you subscribe, falls back to the low-quality (low resolution and low bitrate) video stream. This option is only valid for setRemoteSubscribeFallbackOption and is invalid for setLocalPublishFallbackOption."
            },
            {
                "AudioOnly": "2: Under poor uplink network conditions, the published video stream falls back to audio only. Under poor downlink network conditions, the remote video stream, to which you subscribe, first falls back to the low-quality (low resolution and low bitrate) video stream; and then to an audio-only stream if the network conditions worsen."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_streampublishstate",
        "name": "StreamPublishState",
        "description": "The publishing state.\n",
        "parameters": [
            {
                "Idle": "0: The initial publishing state after joining the channel."
            },
            {
                "NoPublished": "1: Fails to publish the local stream. Possible reasons:\n The local user calls muteLocalAudioStream(true) or muteLocalVideoStream(true) to stop sending the local media stream.\n The local user calls disableAudio or disableVideo to disable the local audio or video module.\n The local user calls enableLocalAudio(false) or enableLocalVideo(false) to disable the local audio or video capture.\n     The role of the local user is audience.\n \n  "
            },
            {
                "Publishing": "2: Publishing."
            },
            {
                "Published": "3: Publishes successfully."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_streamsubscribestate",
        "name": "StreamSubscribeState",
        "description": "The subscribing state.\n",
        "parameters": [
            {
                "Idle": "0: The initial subscribing state after joining the channel."
            },
            {
                "NoSubscribed": "1: Fails to subscribe to the remote stream. Possible reasons:\n     The remote user:\nCalls muteLocalAudioStream(true) or muteLocalVideoStream(true) to stop sending local media stream.\nCalls disableAudio or disableVideo to disable the local audio or video module.\n    Calls enableLocalAudio(false) or enableLocalVideo(false) to disable the local audio or video capture.\n    The role of the remote user is audience.\n\n     The local user calls the following methods to stop receiving remote streams:\n    Calls muteRemoteAudioStream(true), muteAllRemoteAudioStreams(true) or setDefaultMuteAllRemoteAudioStreams(true) to stop receiving the remote audio streams.\n    Calls muteRemoteVideoStream(true), muteAllRemoteVideoStreams(true) or setDefaultMuteAllRemoteVideoStreams(true) to stop receiving the remote video streams.\n\n \n  "
            },
            {
                "Subscribing": "2: Subscribing."
            },
            {
                "Subscribed": "3: Subscribes to and receives the remote stream successfully."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_superresolutionstatereason",
        "name": "SuperResolutionStateReason",
        "description": "The reason why super resolution is not successfully enabled.\nSince\n                    v3.5.1",
        "parameters": [
            {
                "Success": "0: Super resolution is successfully enabled."
            },
            {
                "StreamOverLimitation": "1: The original resolution of the remote video is beyond the range where super resolution can be applied."
            },
            {
                "UserCountOverLimitation": "2: Super resolution is already being used to boost another remote user’s video."
            },
            {
                "DeviceNotSupported": "3: The device does not support using super resolution."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_uploaderrorreason",
        "name": "UploadErrorReason",
        "description": "The reason for the upload failure.\n",
        "parameters": [
            {
                "Success": "0: Successfully upload the log files."
            },
            {
                "NetError": "1: Network error. Check the network connection and call uploadLogFile again to upload the log file."
            },
            {
                "ServerError": "2: An error occurs in the Agora server. Try uploading the log files later."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_userofflinereasontype",
        "name": "UserOfflineReason",
        "description": "Reasons for a user being offline.\n",
        "parameters": [
            {
                "Quit": "0: The user quits the call."
            },
            {
                "Dropped": "1: The SDK times out and the user drops offline because no data packet is received within a certain period of time.\n      If the user quits the call and the message is not passed to the SDK (due to an unreliable channel), the SDK assumes the user dropped offline."
            },
            {
                "BecomeAudience": "2: The user switches the client role from the host to the audience."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videocodecprofiletype",
        "name": "VideoCodecProfileType",
        "description": "Video codec profile types.\n",
        "parameters": [
            {
                "BaseLine": "66: Baseline video codec profile. Generally used for video calls on mobile phones."
            },
            {
                "Main": "77: Main video codec profile. Generally used in mainstream electronics such as MP4 players, portable video players, PSP, and iPads."
            },
            {
                "High": "100: (Default) High video codec profile. Generally used in high-resolution live streaming or television."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videocodectype",
        "name": "VideoCodecType",
        "description": "Video codec types.\n",
        "parameters": [
            {
                "VP8": "Standard VP8."
            },
            {
                "H264": "Standard H.264."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videocontenthint",
        "name": "VideoContentHint",
        "description": "The content hint for screen sharing.\n",
        "parameters": [
            {
                "None": "(Default) No content hint."
            },
            {
                "Motion": "Motion-intensive content. Choose this option if you prefer smoothness or when you are sharing a video clip, movie, or video game."
            },
            {
                "Details": "Motionless content. Choose this option if you prefer sharpness or when you are sharing a\n                        picture, PowerPoint slides, or texts."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videomirrormodetype",
        "name": "VideoMirrorMode",
        "description": "Video mirror mode.\n",
        "parameters": [
            {
                "Auto": "0: (Default) The SDK determines the mirror mode."
            },
            {
                "Enabled": "1: Enable mirror mode."
            },
            {
                "Disabled": "2: Disable mirror mode."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_virtualbackgroundsourcestatereason",
        "name": "VirtualBackgroundSourceStateReason",
        "description": "The reason why virtual background is not successfully enabled.\nSince\n                    v3.5.0",
        "parameters": [
            {
                "Success": "0: The virtual background is successfully enabled."
            },
            {
                "ImageNotExist": "1: The custom background image does not exist. Please check the value of source in VirtualBackgroundSource."
            },
            {
                "ColorFormatNotSupported": "2: The color format of the custom background image is invalid. Please check the value of color in VirtualBackgroundSource."
            },
            {
                "DeviceNotSupported": "3: The device does not support using the virtual background."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_voicebeautifierpreset",
        "name": "VoiceBeautifierPreset",
        "description": "The options for SDK preset voice beautifier effects.\n",
        "parameters": [
            {
                "VoiceBeautifierOff": "Turn off voice beautifier effects and use the original voice."
            },
            {
                "ChatBeautifierMagnetic": "A more magnetic voice.\n      Agora recommends using this enumerator to process a male-sounding voice; otherwise, you may experience vocal distortion."
            },
            {
                "ChatBeautifierFresh": "A fresher voice.\n      Agora recommends using this enumerator to process a female-sounding voice; otherwise, you may experience vocal distortion.\n  "
            },
            {
                "ChatBeautifierVitality": "A more vital voice.\n      Agora recommends using this enumerator to process a female-sounding voice; otherwise, you may experience vocal distortion.\n  "
            },
            {
                "SingingBeautifier": "Singing beautifier effect.\n      \n If you call setVoiceBeautifierPreset(SingingBeautifier), you can beautify a male-sounding voice and add a reverberation effect that sounds like singing in a small room. Agora recommends using this enumerator to process a male-sounding voice; otherwise, you might experience vocal distortion.\n If you call setVoiceBeautifierParameters(SingingBeautifier, param1, param2), you can beautify a male- or female-sounding voice and add a reverberation effect.\n      \n  "
            },
            {
                "TimbreTransformationVigorous": "A more vigorous voice."
            },
            {
                "TimbreTransformationDeep": "A deep voice."
            },
            {
                "TimbreTransformationMellow": "A mellower voice."
            },
            {
                "TimbreTransformationFalsetto": "Falsetto."
            },
            {
                "TimbreTransformationFull": "A fuller voice."
            },
            {
                "TimbreTransformationClear": "A clearer voice."
            },
            {
                "TimbreTransformationResounding": "A more resounding voice."
            },
            {
                "TimbreTransformationRinging": "A more ringing voice."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_voicechangerpreset",
        "name": "AudioVoiceChanger",
        "description": "Local voice changer options.\n",
        "parameters": [
            {
                "Off": "The original voice (no local voice change)."
            },
            {
                "OldMan": "The voice of an old man."
            },
            {
                "BabyBoy": "The voice of a little boy."
            },
            {
                "BabyGirl": "The voice of a little girl."
            },
            {
                "ZhuBaJie": "The voice of Zhu Bajie, a character in Journey to the West who has a voice like that of a growling bear."
            },
            {
                "Ethereal": "The ethereal voice."
            },
            {
                "Hulk": "The voice of Hulk."
            },
            {
                "BEAUTY_VIGOROUS": "A more vigorous voice."
            },
            {
                "BEAUTY_DEEP": "A deeper voice."
            },
            {
                "BEAUTY_MELLOW": "A mellower voice."
            },
            {
                "BEAUTY_FALSETTO": "Falsetto."
            },
            {
                "BEAUTY_FULL": "A fuller voice."
            },
            {
                "BEAUTY_CLEAR": "A clearer voice."
            },
            {
                "BEAUTY_RESOUNDING": "A more resounding voice."
            },
            {
                "BEAUTY_RINGING": "A more ringing voice."
            },
            {
                "BEAUTY_SPACIAL": "A more spatially resonant voice."
            },
            {
                "GENERAL_BEAUTY_VOICE_MALE_MAGNETIC": "(For male only) A more magnetic voice. Do not use it when the speaker is a female; otherwise, voice distortion occurs."
            },
            {
                "GENERAL_BEAUTY_VOICE_FEMALE_FRESH": "(For female only) A fresher voice. Do not use it when the speaker is a male; otherwise, voice distortion occurs."
            },
            {
                "GENERAL_BEAUTY_VOICE_FEMALE_VITALITY": "(For female only) A more vital voice. Do not use it when the speaker is a male; otherwise, voice distortion occurs."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_voiceconversionpreset",
        "name": "VoiceConversionPreset",
        "description": "The options for SDK preset voice conversion effects.\n",
        "parameters": [
            {
                "Off": "Turn off voice conversion effects and use the original voice."
            },
            {
                "Neutral": "A gender-neutral voice. To avoid audio distortion, ensure that you use this enumerator to process a female-sounding voice."
            },
            {
                "Sweet": "A sweet voice. To avoid audio distortion, ensure that you use this enumerator to process a female-sounding voice."
            },
            {
                "Solid": "A steady voice. To avoid audio distortion, ensure that you use this enumerator to process a male-sounding voice."
            },
            {
                "Bass": "A deep voice. To avoid audio distortion, ensure that you use this enumerator to process a male-sounding voice."
            }
        ],
        "returns": ""
    }
]
